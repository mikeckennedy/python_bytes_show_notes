WEBVTT

00:00:00.000 --> 00:00:12.200
Hello, everybody. Thanks for joining the stream. Hello, and welcome to Python Bytes, where


00:00:12.200 --> 00:00:18.240
we belittle, no, where we deliver news and headlines directly to your earbuds. This is


00:00:18.240 --> 00:00:23.840
episode 233, recorded May 12, 2021. And I'm Brian Okken.


00:00:23.840 --> 00:00:26.160
I'm Michael Kennedy.


00:00:26.160 --> 00:00:28.200
And I'm Eileen Mangami.


00:00:28.200 --> 00:00:35.200
Well, welcome, Merlene. For people who don't know you, can you introduce who you are?


00:00:35.200 --> 00:00:47.200
Sure. So I am a Pythonista, of course. And I am based in Harare, Zimbabwe. I am also


00:00:47.200 --> 00:00:52.200
really involved with the Python community. So I'm currently the vice chair of the PSA


00:00:52.200 --> 00:01:02.960
board of directors. The board I think for about like coming up on four years now


00:01:02.960 --> 00:01:08.080
which is really exciting and it's been really like a very cool experience for


00:01:08.080 --> 00:01:14.520
me. I'm also a software engineer. I work right now with the RAPIDS team at


00:01:14.520 --> 00:01:19.600
NVIDIA and and have just been doing software engineering with them. I will


00:01:19.600 --> 00:01:21.440
I'll talk a bit about that later.


00:01:21.440 --> 00:01:25.280
But yeah, I'm trying to think what else.


00:01:25.280 --> 00:01:27.600
I'm also a very avid reader


00:01:27.600 --> 00:01:30.920
and just like doing other things besides software.


00:01:30.920 --> 00:01:34.720
So yeah, that's pretty much me.


00:01:34.720 --> 00:01:35.760
- Cool.


00:01:35.760 --> 00:01:36.600
- That's awesome.


00:01:36.600 --> 00:01:38.400
You're doing a bunch of cool stuff.


00:01:38.400 --> 00:01:40.680
So I think Rapid seems like a really neat project


00:01:40.680 --> 00:01:42.400
to work on as well.


00:01:42.400 --> 00:01:45.080
And of course the Python community side is great.


00:01:45.080 --> 00:01:47.420
So super happy to have you here.


00:01:48.360 --> 00:01:52.760
- Brian, yeah, Brian, you know, having a good readme


00:01:52.760 --> 00:01:55.320
is really important to a project, wouldn't you say?


00:01:55.320 --> 00:01:57.440
- Yeah, definitely.


00:01:57.440 --> 00:02:01.080
And I, for some reason, I don't know,


00:02:01.080 --> 00:02:02.600
readmes are not difficult to write,


00:02:02.600 --> 00:02:06.280
but I freeze up, it's a blank page syndrome, I think.


00:02:06.280 --> 00:02:08.560
Often I've gone through and just like copied


00:02:08.560 --> 00:02:11.800
from some other projects, what's in their readme?


00:02:11.800 --> 00:02:15.400
But I don't think that that's like the best way


00:02:15.400 --> 00:02:18.260
to go about it, really, 'cause sometimes you forget stuff.


00:02:18.260 --> 00:02:22.520
So this was a, we have a recommendation from Johnny Metz.


00:02:22.520 --> 00:02:25.240
It's a tool called readme.so.


00:02:25.240 --> 00:02:29.060
And this is like totally fun.


00:02:29.060 --> 00:02:33.280
It's just this interactive thing where you get to,


00:02:33.280 --> 00:02:34.180
you get to add stuff.


00:02:34.180 --> 00:02:35.580
So we've got the title.


00:02:35.580 --> 00:02:37.340
You can, there's on the left hand side,


00:02:37.340 --> 00:02:39.660
there's a bunch of sections where you can select


00:02:39.660 --> 00:02:42.620
what you want to go into the readme.


00:02:42.620 --> 00:02:46.220
And then it shows a preview on the right,


00:02:46.220 --> 00:02:49.420
but you can also see the raw markdown.


00:02:49.420 --> 00:02:51.000
And then in the middle, there's an editor,


00:02:51.000 --> 00:02:53.440
so you can actually just edit the whole thing here.


00:02:53.440 --> 00:02:55.640
But really, I don't know if I really would.


00:02:55.640 --> 00:02:58.320
Project, project title.


00:02:58.320 --> 00:03:02.160
What I'd probably do is go through and pick out,


00:03:02.160 --> 00:03:04.240
to look at what sort of things I'd want.


00:03:04.240 --> 00:03:06.120
So I'd probably maybe some acknowledgments,


00:03:06.120 --> 00:03:08.920
if I took the, if I got some help from somebody,


00:03:08.920 --> 00:03:13.080
maybe an API reference, if it's a library,


00:03:14.640 --> 00:03:20.640
how to contribute. Oh, badges, definitely want badges. And then,


00:03:20.640 --> 00:03:24.160
you know, maybe like how to run tests if you want to contribute.


00:03:24.160 --> 00:03:29.520
If there's other cool projects using it, I'd want to use by all


00:03:29.520 --> 00:03:32.960
these sorts of things. And then you can, the editor only selects


00:03:32.960 --> 00:03:37.260
it only shows you the ones that one at a time, which is nice. But


00:03:37.260 --> 00:03:41.280
then you've got this, this whole generated really nice looking


00:03:41.280 --> 00:03:45.400
Readme with tables and everything built in.


00:03:45.400 --> 00:03:47.400
And you can either just copy it or download it


00:03:47.400 --> 00:03:48.560
and just run with it.


00:03:48.560 --> 00:03:51.360
So I think this is really great.


00:03:51.360 --> 00:03:53.400
I'll probably use this in the future.


00:03:53.400 --> 00:03:54.320
- I really love this.


00:03:54.320 --> 00:03:58.260
And I'm surprised about the psychological benefit


00:03:58.260 --> 00:04:01.940
of just showing the little section with the one heading.


00:04:01.940 --> 00:04:03.840
So for example, acknowledgements,


00:04:03.840 --> 00:04:07.040
you just have #acknowledgements and the few things,


00:04:07.040 --> 00:04:08.560
even though you're editing the whole Readme,


00:04:08.560 --> 00:04:09.960
it seems so much more like,


00:04:09.960 --> 00:04:11.480
"Oh, I'm gonna just work on that section."


00:04:11.480 --> 00:04:12.540
It's really cool.


00:04:12.540 --> 00:04:14.500
Marlene, what do you think?


00:04:14.500 --> 00:04:15.880
- It's really, really cool.


00:04:15.880 --> 00:04:16.720
I like it.


00:04:16.720 --> 00:04:18.400
I think I'm gonna try it out.


00:04:18.400 --> 00:04:23.400
I have put no if it at all in this,


00:04:23.400 --> 00:04:27.640
so I think it's something I need to put more if it into,


00:04:27.640 --> 00:04:30.280
and this looks like a really good way to do that.


00:04:30.280 --> 00:04:32.840
- Yeah.


00:04:32.840 --> 00:04:34.840
- I think that it would also be great to just,


00:04:34.840 --> 00:04:36.240
like if you have an existing readme


00:04:36.240 --> 00:04:37.520
and you wanna add some new sections,


00:04:37.520 --> 00:04:39.400
you're not quite sure how it should look,


00:04:39.400 --> 00:04:42.720
using this as a jumping point of just to grab sections


00:04:42.720 --> 00:04:44.680
of a readme to add to an existing one too.


00:04:44.680 --> 00:04:45.680
This would be great.


00:04:45.680 --> 00:04:49.680
- Yeah, this is really, really cool.


00:04:49.680 --> 00:04:54.200
How do you, how do you, can you start with a new one?


00:04:54.200 --> 00:04:56.920
Like, can I, well, sorry, let me take it back.


00:04:56.920 --> 00:04:58.380
Can I start with an existing one?


00:04:58.380 --> 00:05:01.200
Can I somehow upload an existing one?


00:05:01.200 --> 00:05:03.080
I don't see. - I don't think so.


00:05:03.080 --> 00:05:05.840
- Wait, I can go to raw, hold on.


00:05:05.840 --> 00:05:08.400
- Oh, you could probably just drop it into raw.


00:05:08.400 --> 00:05:11.120
- Maybe, yes, you can drop it into the raw, that's it.


00:05:11.120 --> 00:05:12.080
Okay, perfect.


00:05:12.080 --> 00:05:14.200
You go to raw, which it doesn't hide the sections,


00:05:14.200 --> 00:05:15.520
it's just pure markdown,


00:05:15.520 --> 00:05:16.440
and then you just throw it in there.


00:05:16.440 --> 00:05:17.360
Okay.


00:05:17.360 --> 00:05:18.200
So--


00:05:18.200 --> 00:05:19.200
- But you can edit there.


00:05:19.200 --> 00:05:20.800
- No, no, but you can flip it back, I think,


00:05:20.800 --> 00:05:22.360
probably once you edit it there.


00:05:22.360 --> 00:05:23.200
I'm guessing.


00:05:23.200 --> 00:05:24.020
- I don't think you can edit,


00:05:24.020 --> 00:05:28.500
so you can only edit in the editor part, so.


00:05:28.500 --> 00:05:30.320
- Yeah, it still looks really, really cool.


00:05:30.320 --> 00:05:32.800
I've heard of platform as a service.


00:05:32.800 --> 00:05:35.560
I've heard of infrastructure of a service.


00:05:35.560 --> 00:05:37.120
I've heard of database as a service,


00:05:37.120 --> 00:05:38.760
But I guess now we have readme as a service.


00:05:38.760 --> 00:05:39.600
I don't know, you just go to the website.


00:05:39.600 --> 00:05:40.440
- Readme is good.


00:05:40.440 --> 00:05:41.720
(laughing)


00:05:41.720 --> 00:05:42.560
- Exactly.


00:05:42.560 --> 00:05:43.520
- That's pretty cool.


00:05:43.520 --> 00:05:45.400
- Yeah, I'm pretty excited about this.


00:05:45.400 --> 00:05:49.120
Actually, I might play around with this for my next project.


00:05:49.120 --> 00:05:52.440
I've got some stuff that may end up on PyPI soon


00:05:52.440 --> 00:05:54.520
and it'd be cool to do it.


00:05:54.520 --> 00:05:56.420
All right, so I've got the next item.


00:05:56.420 --> 00:06:03.080
And it's a bit of a skateboarding dog type of thing.


00:06:03.080 --> 00:06:06.480
It's not directly, it's not something I think a lot of us


00:06:06.480 --> 00:06:11.120
take advantage of, but it's something that is pretty interesting as we kind of look at


00:06:11.120 --> 00:06:19.120
how Python is finding its way into the larger computing space. Yeah, and oh, Sam Morley out


00:06:19.120 --> 00:06:22.960
there on the live stream before we move on says, "It'd be really cool if you could point this at a


00:06:22.960 --> 00:06:29.520
GitHub repo and edit your repo directly, the readme directly on your repo." Yes, absolutely. That's


00:06:29.520 --> 00:06:30.480
- That's fantastic.


00:06:30.480 --> 00:06:33.480
Yeah, it's a really good idea.


00:06:33.480 --> 00:06:34.360
Really good idea.


00:06:34.360 --> 00:06:36.560
All right, back to my skateboarding dog.


00:06:36.560 --> 00:06:39.920
So there's a company called Cerebras,


00:06:39.920 --> 00:06:44.920
and this was sent over to us by Galen Swint,


00:06:44.920 --> 00:06:47.120
who is a PhD researcher


00:06:47.120 --> 00:06:50.220
who does high performance computing and stuff.


00:06:50.220 --> 00:06:54.000
So in that world, I think this may be a real thing.


00:06:54.000 --> 00:06:56.440
You look through the article here


00:06:56.440 --> 00:06:57.840
that talks about this announcement,


00:06:57.840 --> 00:07:00.160
And it's like, well, there's like these 12 customers


00:07:00.160 --> 00:07:03.640
or 15 customers of this chip.


00:07:03.640 --> 00:07:04.960
But for those of you watching,


00:07:04.960 --> 00:07:06.680
there's, or you check out the article,


00:07:06.680 --> 00:07:08.740
there's a woman holding a chip.


00:07:08.740 --> 00:07:10.120
And normally we think of computer chips


00:07:10.120 --> 00:07:11.320
as little tiny things.


00:07:11.320 --> 00:07:15.120
This is a 12 inch by 12 inch computer chip,


00:07:15.120 --> 00:07:19.200
or if you wanna go metric, 30 centimeters by 30 centimeters.


00:07:19.200 --> 00:07:22.280
It is a big, big computer chip.


00:07:22.280 --> 00:07:27.460
And the idea is we've had small little chips come along


00:07:27.460 --> 00:07:29.300
to do special types of processing.


00:07:29.300 --> 00:07:31.660
We've had GPUs come along and do,


00:07:31.660 --> 00:07:36.180
be adapted, I guess, for things like machine learning,


00:07:36.180 --> 00:07:38.940
training machine learning models and so on.


00:07:38.940 --> 00:07:43.560
And this thing just takes that idea to an entire new level.


00:07:43.560 --> 00:07:46.360
So for example, I'm always going on and on


00:07:46.360 --> 00:07:49.680
and raving about my Mac mini, my M1,


00:07:49.680 --> 00:07:52.420
where it's a cheap little computer


00:07:52.420 --> 00:07:54.460
relative to Apple stuff, I guess,


00:07:54.460 --> 00:07:56.300
but it's super fast.


00:07:56.300 --> 00:08:00.000
but it has four performance cores and four efficiency cores.


00:08:00.000 --> 00:08:01.040
That's it.


00:08:01.040 --> 00:08:02.840
Your GPU, if you've got a really high end one,


00:08:02.840 --> 00:08:04.880
might have 4,000 cores.


00:08:04.880 --> 00:08:09.880
This insane little chip here has 850,000 AI cores


00:08:09.880 --> 00:08:11.400
on one chip.


00:08:11.400 --> 00:08:13.720
Is that insane?


00:08:13.720 --> 00:08:15.220
What do you do think?


00:08:15.220 --> 00:08:18.440
- I'm curious how they, I mean,


00:08:18.440 --> 00:08:21.840
this is some major advances in wafer technology


00:08:21.840 --> 00:08:24.020
'cause how do you get that big of a chip


00:08:24.020 --> 00:08:25.880
with no defects in it?


00:08:25.880 --> 00:08:29.360
Yeah, they have apparently 100% efficiency.


00:08:29.360 --> 00:08:33.800
Well, first of all, one of the ways you do it is you use the TSMC foundry,


00:08:33.800 --> 00:08:39.360
who seems to be taking over all these small high efficiency type of things.


00:08:39.360 --> 00:08:43.460
And so they had a previous one that they've more than doubled the core count


00:08:43.460 --> 00:08:48.600
for. And another way to kind of appreciate like how much is going on in this chip.


00:08:48.600 --> 00:08:52.840
If you look, you know, go back to my, my M1,


00:08:53.740 --> 00:08:58.740
It has 0.001.6, 0.0016 trillion transistors.


00:08:58.740 --> 00:09:04.980
This has 2.6 trillion.


00:09:04.980 --> 00:09:06.340
Or is that another way?


00:09:06.340 --> 00:09:11.340
26, 2,600 billion, no, a million,


00:09:11.340 --> 00:09:15.140
yeah, billion transistors versus 1.6 billion.


00:09:15.140 --> 00:09:19.460
Like it's 2,000 times more on this chip.


00:09:19.460 --> 00:09:20.660
So super, super cool.


00:09:20.660 --> 00:09:21.620
And now you may be wondering,


00:09:21.620 --> 00:09:22.940
all right, all this is interesting,


00:09:22.940 --> 00:09:28.780
chips are neat, what is the Python angle? Like why would I bother putting this on


00:09:28.780 --> 00:09:31.420
here? Because you know we don't really talk about chips that much except for


00:09:31.420 --> 00:09:35.420
when I go on and on about my M1. Here's the deal, if you scroll down in this


00:09:35.420 --> 00:09:40.400
article a little bit, you'll see user programmed this insane machine


00:09:40.400 --> 00:09:45.660
transparently in machine learning frameworks such as specifically TensorFlow


00:09:45.660 --> 00:09:53.340
and PyTorch. Isn't that crazy? So it comes with... Sorry, Marlene, what was that?


00:09:53.340 --> 00:09:56.060
No, I was just saying that's really interesting.


00:09:56.060 --> 00:10:00.300
Isn't it? Yeah, I was just thinking about you as I'm going through this because you're working on


00:10:00.300 --> 00:10:04.940
the Rapids project, which is not the same thing, obviously, but it's kind of in that space, right?


00:10:04.940 --> 00:10:07.420
Yeah, it is.


00:10:07.420 --> 00:10:08.540
Have you heard of this before?


00:10:08.540 --> 00:10:15.100
No, I haven't heard of this. This is, yeah, this is really big and I have not heard of it.


00:10:15.100 --> 00:10:20.100
I would recommend reading a bit more about it off the top.


00:10:20.100 --> 00:10:21.100
Yeah, for sure.


00:10:21.100 --> 00:10:23.100
So there's a lot of interesting things.


00:10:23.100 --> 00:10:27.100
And one of the -- I can't remember where exactly they spoke about it,


00:10:27.100 --> 00:10:33.100
but they basically say what you do is you program in TensorFlow and PyTorch as normal,


00:10:33.100 --> 00:10:37.100
and then they have this custom compiler that rewrites,


00:10:37.100 --> 00:10:44.100
that extracts this execution graph to actually scale out to the 850,000 cores.


00:10:44.100 --> 00:10:50.100
So the developers don't have to think about how they program against something like this.


00:10:50.100 --> 00:10:56.100
I don't want to spend too much time on this because there's something, my next item is super amazing, I want to take the time to dive into it.


00:10:56.100 --> 00:11:00.100
But there's another thing that's really interesting.


00:11:00.100 --> 00:11:06.100
As you look at it, this thing takes an insane amount of power.


00:11:06.100 --> 00:11:12.740
Oh, for this one chip, you're gonna need a four kilowatt power supply with up to a peak


00:11:12.740 --> 00:11:18.500
power of 23 kilowatts.


00:11:18.500 --> 00:11:21.960
When you plug in an electric car at one of the high speed home chargers, that's seven


00:11:21.960 --> 00:11:24.340
kilowatts just to give you a sense.


00:11:24.340 --> 00:11:27.700
This is like insane amounts for one chip, right?


00:11:27.700 --> 00:11:28.700
You could think of it as a supercomputer.


00:11:28.700 --> 00:11:30.140
Like it's one chip.


00:11:30.140 --> 00:11:31.140
So anyway.


00:11:31.140 --> 00:11:36.100
Our entire lab doesn't draw that much.


00:11:36.100 --> 00:11:40.100
So the reason I said it's a skateboarding dog thing is I don't think most of us


00:11:40.100 --> 00:11:43.940
will be able to ever even interact with one of these, much less buy one.


00:11:43.940 --> 00:11:47.060
They're going to be shipping in the later part of this year,


00:11:47.060 --> 00:11:50.980
and the price is something like $3 million US dollars plus.


00:11:50.980 --> 00:11:53.540
So this is certainly super computer level,


00:11:53.540 --> 00:11:58.180
but I do think it opens the door for really interesting stuff going on


00:11:58.180 --> 00:12:00.020
in the high-performance Python space.


00:12:00.020 --> 00:12:05.020
So yeah, I'm glad that Galen sent it over.


00:12:05.020 --> 00:12:07.900
- Well, I'm totally gonna put 25 bucks into Dogecoin


00:12:07.900 --> 00:12:10.240
so that I can afford this later this year.


00:12:10.240 --> 00:12:11.740
- Oh, well, speaking of which.


00:12:11.740 --> 00:12:12.860
(laughing)


00:12:12.860 --> 00:12:13.700
Exactly.


00:12:13.700 --> 00:12:16.340
But what about, yeah, definitely.


00:12:16.340 --> 00:12:18.900
I think maybe you get this and you create an AI


00:12:18.900 --> 00:12:21.060
that can more intelligently mine Dogecoin


00:12:21.060 --> 00:12:23.420
and then you take over the world.


00:12:23.420 --> 00:12:25.060
Just an investment.


00:12:25.060 --> 00:12:25.900
- Yeah.


00:12:25.900 --> 00:12:26.720
- It's an investment.


00:12:26.720 --> 00:12:28.700
All right, so speaking of large-scale


00:12:28.700 --> 00:12:35.060
performance computing. Marlene, take it away. Sure, I have the next item which is


00:12:35.060 --> 00:12:41.580
Rapids and I wanted to speak about this because I'm working on it and it's been


00:12:41.580 --> 00:12:48.500
what I've been working on for I think yeah well it's been about a year since I


00:12:48.500 --> 00:12:54.980
have been with NVIDIA working as a software engineer there and working


00:12:54.980 --> 00:12:59.940
specifically on the Rapids project. And so Rapids I think is really interesting


00:12:59.940 --> 00:13:06.380
because the goal of Rapids similarly, like the last thing Michael just


00:13:06.380 --> 00:13:13.000
showed us, is to speed up data science but this is what GPUs. So I think it's


00:13:13.000 --> 00:13:20.300
really, it's been really cool to to work on the Rapids project and I think it's


00:13:20.300 --> 00:13:25.040
really interesting as well because it's open source. It's also there's a lot of


00:13:25.040 --> 00:13:31.080
Python involved so it's well it's not entirely it's not mostly Python actually


00:13:31.080 --> 00:13:37.720
there's a lot of C++ and Cuda code in there as well but I am not you know


00:13:37.720 --> 00:13:43.100
personally I'm not I'm not my aim is not to learn Cuda it's to try and avoid that


00:13:43.100 --> 00:13:48.880
as much as possible and it was a avoid as much C++ as possible though that's a


00:13:48.880 --> 00:13:56.500
bit more reasonable. But one of the goals of the Rapids project is to allow people who


00:13:56.500 --> 00:14:03.900
are Pythonistas to work primarily with GPUs and to get those speedups without having to


00:14:03.900 --> 00:14:12.780
know any Cuda code or to know any C++. And so I have been working primarily on the Python


00:14:12.780 --> 00:14:21.660
side of things and have really been enjoying it. I work specifically on with the QDF DataFrame


00:14:21.660 --> 00:14:31.260
library and QDF is basically a, it mirrors, it's a GPU DataFrame library that mirrors pandas.


00:14:31.260 --> 00:14:37.420
So if you have a data set and you'd like to do computations on your data set or do different


00:14:37.420 --> 00:14:43.820
operations on your dataset. If you can do that with pandas, you should be able, hopefully,


00:14:43.820 --> 00:14:51.340
to do the same thing with QDF. But the good thing is that it will probably be faster. I


00:14:51.340 --> 00:14:58.940
actually can't definitively say that it will be faster because I remember when I first joined


00:14:58.940 --> 00:15:05.980
the project as well, I was, I really, I'm very enthusiastic and I really enjoy sort of sharing


00:15:05.980 --> 00:15:12.620
when I'm learning something new. And I remember I was like going around and speaking and saying that,


00:15:12.620 --> 00:15:18.780
you know, Kudieff is so much better than Pandas because it's just so much faster. And then my


00:15:18.780 --> 00:15:25.420
manager was just like, you need to stop saying that because it's not true all of the time.


00:15:25.420 --> 00:15:32.540
It's true most like some of the time. So for smaller data sets, it's probably better to stick


00:15:32.540 --> 00:15:40.460
with pandas because there's always this overhead right like as you scale things out and stuff


00:15:40.460 --> 00:15:44.780
there's probably like well how do we convert this over and get it onto the gpu and if if that


00:15:44.780 --> 00:15:50.060
process takes you know half the time what just doing the computation you might as well just do


00:15:50.060 --> 00:15:55.980
the computation right exactly like if you're already if you're mainly doing right i agree


00:15:55.980 --> 00:16:01.500
like if you're working with smaller data sets and you are fine with that and that works for you and


00:16:01.500 --> 00:16:05.300
and your time is not being wasted a lot,


00:16:05.300 --> 00:16:08.480
then I would say, please go ahead and stick with Pandas.


00:16:08.480 --> 00:16:13.380
But if you are working on larger datasets,


00:16:13.380 --> 00:16:16.140
and the larger your datasets get,


00:16:16.140 --> 00:16:18.460
the more the difference is gonna be


00:16:18.460 --> 00:16:19.620
in terms of your speedup.


00:16:19.620 --> 00:16:21.700
So with very large datasets,


00:16:21.700 --> 00:16:24.660
QDF is gonna take a much shorter time


00:16:24.660 --> 00:16:27.260
to do computations and things like that.


00:16:27.260 --> 00:16:29.380
- Yeah, you actually put a really interesting example


00:16:29.380 --> 00:16:31.200
in the show notes here, right?


00:16:31.200 --> 00:16:33.800
showing how many zeros of that,


00:16:33.800 --> 00:16:38.720
a hundred million items or something like that?


00:16:38.720 --> 00:16:39.880
- Yeah, it's a hundred million.


00:16:39.880 --> 00:16:43.360
I just kind of like randomly chose a number


00:16:43.360 --> 00:16:44.520
to try and make it like,


00:16:44.520 --> 00:16:47.280
I didn't also want to take a number that was too big


00:16:47.280 --> 00:16:52.280
because I didn't want to spend like a long time doing it.


00:16:52.280 --> 00:16:54.520
And I know like for a lot of data scientists,


00:16:54.520 --> 00:16:57.040
like I think increasingly people are working


00:16:57.040 --> 00:16:59.640
with larger and larger datasets,


00:16:59.640 --> 00:17:02.000
just depending which field you're in.


00:17:02.000 --> 00:17:05.480
But for the example, I put it on the show notes


00:17:05.480 --> 00:17:07.760
and it's on the screen right now.


00:17:07.760 --> 00:17:10.760
But if you take a pandas sort of data frame


00:17:10.760 --> 00:17:12.680
and try and calculate the mean,


00:17:12.680 --> 00:17:15.840
and you take the same QDF dataset


00:17:15.840 --> 00:17:17.360
and try and calculate the mean,


00:17:17.360 --> 00:17:20.640
it will take, I think, I'm trying to look at the notes.


00:17:20.640 --> 00:17:25.040
It's 105 milliseconds for pandas,


00:17:25.040 --> 00:17:29.240
and it's like 1.83 milliseconds for QDF,


00:17:29.240 --> 00:17:30.240
- That's awesome.


00:17:30.240 --> 00:17:32.880
- And that's like a smaller scale,


00:17:32.880 --> 00:17:35.640
I would say, data set compared to some people.


00:17:35.640 --> 00:17:38.400
- 100 million, no big deal, yeah.


00:17:38.400 --> 00:17:41.920
- It's just 100 million, so it's not a lot.


00:17:41.920 --> 00:17:44.920
I mean, it depends, but yeah,


00:17:44.920 --> 00:17:46.960
I think it's definitely significant


00:17:46.960 --> 00:17:48.560
once you get to a certain threshold,


00:17:48.560 --> 00:17:50.120
which is pretty cool.


00:17:50.120 --> 00:17:52.360
- Yeah, yeah, over on the RapidSight,


00:17:52.360 --> 00:17:56.280
it's RapidSight AI, it says it scales out on multiple GPUs,


00:17:56.280 --> 00:17:59.160
So seamlessly scale from a GPU workstation


00:17:59.160 --> 00:18:02.740
to multi GPU servers and multi node clusters,


00:18:02.740 --> 00:18:04.040
working with Dask as well.


00:18:04.040 --> 00:18:04.880
So that's, you know,


00:18:04.880 --> 00:18:07.000
Dask is also kind of about scaling pandas


00:18:07.000 --> 00:18:07.960
and combining those.


00:18:07.960 --> 00:18:08.920
That's pretty awesome.


00:18:08.920 --> 00:18:09.760
So.


00:18:09.760 --> 00:18:14.040
- I actually saw that you have a Dask course out.


00:18:14.040 --> 00:18:15.560
Like I recently saw it.


00:18:15.560 --> 00:18:17.120
Definitely gonna take that.


00:18:17.120 --> 00:18:17.960
- Yeah, take that one.


00:18:17.960 --> 00:18:20.400
- 'Cause I'm gonna be diving to Dask a bit later.


00:18:20.400 --> 00:18:21.240
- Awesome.


00:18:21.240 --> 00:18:22.060
Yeah, yeah.


00:18:22.060 --> 00:18:25.480
We put that together with Matthew Rocklin


00:18:25.480 --> 00:18:27.920
and team over at Coiled.


00:18:27.920 --> 00:18:28.920
Yeah, and that's actually free.


00:18:28.920 --> 00:18:30.800
So people can just drop in and take that course.


00:18:30.800 --> 00:18:32.920
I think maybe I even put it in the show notes at the end.


00:18:32.920 --> 00:18:35.440
I think it was just announced, let's see.


00:18:35.440 --> 00:18:38.440
No, that was last week.


00:18:38.440 --> 00:18:39.480
But yeah, this is super cool.


00:18:39.480 --> 00:18:44.200
And this one is certainly within normal person's reach.


00:18:44.200 --> 00:18:46.800
You get a GPU and you're good to go, right?


00:18:46.800 --> 00:18:49.440
- Yeah, I think, yeah.


00:18:49.440 --> 00:18:53.960
I mean, I'm just using it on my laptop with the GPU.


00:18:53.960 --> 00:18:55.840
You can also use it online.


00:18:55.840 --> 00:19:00.840
So there's also a Colab notebook on the rapid site,


00:19:00.840 --> 00:19:03.560
I think, that you can click in


00:19:03.560 --> 00:19:05.680
and you can kind of experiment.


00:19:05.680 --> 00:19:07.320
If you just wanted to do it online,


00:19:07.320 --> 00:19:11.080
or I think you can use any sort of online GPU


00:19:11.080 --> 00:19:13.040
that you have access to.


00:19:13.040 --> 00:19:16.400
So it's very, I think it's trying to make it more accessible


00:19:16.400 --> 00:19:19.140
which is great.


00:19:19.140 --> 00:19:20.400
- Yeah, that's super cool.


00:19:20.400 --> 00:19:21.640
Yeah, very neat.


00:19:21.640 --> 00:19:23.480
Well, like I said, I think this is a cool project


00:19:23.480 --> 00:19:24.320
to be working on.


00:19:24.320 --> 00:19:26.720
So thanks for sharing that with us.


00:19:26.720 --> 00:19:28.280
- No problem.


00:19:28.280 --> 00:19:30.180
- Brian, is it time for the next one?


00:19:30.180 --> 00:19:33.080
- Is it time for the next one?


00:19:33.080 --> 00:19:34.960
Oh yes.


00:19:34.960 --> 00:19:36.760
But I'm like working on sharing.


00:19:36.760 --> 00:19:38.120
So here we go sharing.


00:19:38.120 --> 00:19:41.240
Screen sharing stuff.


00:19:41.240 --> 00:19:46.000
Actually, so this was a recommended by a listener,


00:19:46.000 --> 00:19:48.520
Ira Horeca, I think.


00:19:48.520 --> 00:19:52.360
So mentioned this in, it's kind of a rabbit hole.


00:19:52.360 --> 00:19:55.160
I spent a whole bunch of time playing with all this stuff last night.


00:19:55.160 --> 00:19:58.560
So he recommended Datefinder.


00:19:58.560 --> 00:20:02.960
So this is a Python utility, and it kind of is amazing.


00:20:02.960 --> 00:20:04.860
So it's a combination of a couple of things.


00:20:04.860 --> 00:20:09.820
But so he pointed us to a Comcode video,


00:20:09.820 --> 00:20:13.120
which I'm totally a fan of Comcode stuff


00:20:13.120 --> 00:20:15.820
because they kind of go through some of the Python libraries


00:20:15.820 --> 00:20:18.000
and some of the other, a lot of other things,


00:20:18.000 --> 00:20:21.260
but just have kind of a quick demo of what it does.


00:20:21.320 --> 00:20:22.880
and I really appreciate that.


00:20:22.880 --> 00:20:24.880
It actually, the demo here is better than


00:20:24.880 --> 00:20:28.600
the read me and the DateFinder read me.


00:20:28.600 --> 00:20:31.320
Maybe I guess a pull request is necessary.


00:20:31.320 --> 00:20:35.760
But anyway, what DateFinder does is it takes,


00:20:35.760 --> 00:20:38.120
I'm going to scroll down a little bit.


00:20:38.120 --> 00:20:44.040
DateFinder parses dates, it refines them.


00:20:44.040 --> 00:20:48.980
You give it a string or a bunch of list of strings or something,


00:20:48.980 --> 00:20:51.740
and it can find where the dates are in there.


00:20:51.740 --> 00:20:56.520
So if you've got a sentence or a paragraph or an entire page


00:20:56.520 --> 00:20:58.680
that has a whole bunch of dates in it,


00:20:58.680 --> 00:21:04.720
it'll find all of them and then return you a list of dates that it found.


00:21:04.720 --> 00:21:06.500
It actually does a whole bunch of things,


00:21:06.500 --> 00:21:10.240
but that's the default or the one that we're talking about, find dates.


00:21:10.240 --> 00:21:16.220
There's a bunch of other less documented features of Date Finder,


00:21:16.220 --> 00:21:18.700
but this is the one that is demonstrated here,


00:21:18.700 --> 00:21:19.900
and it's pretty cool.


00:21:19.900 --> 00:21:21.360
So what it does, it finds those dates


00:21:21.360 --> 00:21:25.400
and then it converts them to date times.


00:21:25.400 --> 00:21:27.180
So find dates, it'll find them and convert them


00:21:27.180 --> 00:21:28.120
to date times.


00:21:28.120 --> 00:21:29.940
And it does that by passing them off


00:21:29.940 --> 00:21:31.600
to the DateUtil library.


00:21:31.600 --> 00:21:34.380
So this is just kind of a really cool demo.


00:21:34.380 --> 00:21:37.260
The list, the little video is a good demo


00:21:37.260 --> 00:21:41.700
of showing how to do this.


00:21:41.700 --> 00:21:43.940
I also really kind of liked this way to play


00:21:43.940 --> 00:21:46.220
so that the video shows this way to play with things


00:21:46.220 --> 00:21:52.900
of it just had a list of strings and then used a comprehension


00:21:52.900 --> 00:21:55.060
to convert that to call a function


00:21:55.060 --> 00:21:56.220
on a whole bunch of strings.


00:21:56.220 --> 00:21:58.380
And I thought this was just kind of a clever way


00:21:58.380 --> 00:22:01.220
to just play with a function that translates things.


00:22:01.220 --> 00:22:02.980
This is a neat thing to do.


00:22:02.980 --> 00:22:03.980
I would have probably--


00:22:03.980 --> 00:22:04.860
It's usually so hard.


00:22:04.860 --> 00:22:07.840
Yeah, it's super hard normally because it's so picky, right?


00:22:07.840 --> 00:22:13.820
You've got to go to the date time parsing language almost


00:22:13.820 --> 00:22:14.340
lookup.


00:22:14.340 --> 00:22:17.740
So if I put %DDDD, that might mean the year.


00:22:17.740 --> 00:22:20.460
But if it's capital D, it might mean something different.


00:22:20.460 --> 00:22:23.540
So you might say month, day, comma, year.


00:22:23.540 --> 00:22:25.900
But there's an example here with month, day, year


00:22:25.900 --> 00:22:28.900
without the commas, like March 12, 2010.


00:22:28.900 --> 00:22:30.860
But if they forget the comma, it won't parse.


00:22:30.860 --> 00:22:33.060
And all those things are really annoying about working


00:22:33.060 --> 00:22:35.700
with converting strings to dates.


00:22:35.700 --> 00:22:37.860
And this looks like it just doesn't care.


00:22:37.860 --> 00:22:39.220
It's nice.


00:22:39.220 --> 00:22:43.020
Yeah, and then it's kind of a nice, clean interface to it


00:22:43.020 --> 00:22:44.180
as well.


00:22:44.180 --> 00:22:46.900
and a limited documentation.


00:22:46.900 --> 00:22:49.220
It's just a focus tool, which is nice.


00:22:49.220 --> 00:22:53.100
It's interesting that this is just a focus tool that apparently a lot of people


00:22:53.100 --> 00:22:55.220
need because according to GitHub,


00:22:55.220 --> 00:22:58.460
there's 662 projects using this.


00:22:58.460 --> 00:23:01.580
It's used all over the place.


00:23:01.580 --> 00:23:04.540
Behind the scenes though,


00:23:04.540 --> 00:23:07.740
it's taking the dates that it found,


00:23:07.740 --> 00:23:11.220
the strings, and passing those to dateUtil.


00:23:11.220 --> 00:23:14.220
If you want to avoid the finding part,


00:23:14.220 --> 00:23:17.140
this actually is also a good library to look at for


00:23:17.140 --> 00:23:22.780
the usage of how to use DateUtil to easily convert dates.


00:23:22.780 --> 00:23:26.460
DateUtil is an amazing tool as well.


00:23:26.460 --> 00:23:31.220
DateUtil, I told you this was a rabbit hole.


00:23:31.220 --> 00:23:35.340
One of the cool things about it is it doesn't just parse dates,


00:23:35.340 --> 00:23:37.220
but you can do relative dates.


00:23:37.220 --> 00:23:40.660
You can say today plus three weeks or something,


00:23:40.660 --> 00:23:42.900
and it'll figure that out.


00:23:42.900 --> 00:23:45.340
And then you can, or you can take two days,


00:23:45.340 --> 00:23:48.580
two dates and do date math with it really well.


00:23:48.580 --> 00:23:51.780
And also, DateUtil has an amazing time zone support,


00:23:51.780 --> 00:23:53.020
probably the best in Python.


00:23:53.020 --> 00:23:56.100
So this is pretty, pretty kind of cool.


00:23:56.100 --> 00:23:58.940
Also, I think I was looking through the test code.


00:23:58.940 --> 00:24:02.980
The test code for DateUtil has,


00:24:02.980 --> 00:24:05.980
it's kind of a neat mix of unit tests and Py tests.


00:24:05.980 --> 00:24:09.300
Both of them are good examples of how to do both.


00:24:09.300 --> 00:24:12.120
And I like some of the newer stuff is using pytest


00:24:12.120 --> 00:24:14.220
with parameterization, but it's good.


00:24:14.220 --> 00:24:18.580
- I like this a lot.


00:24:18.580 --> 00:24:20.700
Marlene, what do you think?


00:24:20.700 --> 00:24:21.580
- Yeah, I like it.


00:24:21.580 --> 00:24:25.900
I think it's, I'm not actually working with dates


00:24:25.900 --> 00:24:29.820
quite often, so I'm trying to think of use cases for myself


00:24:29.820 --> 00:24:33.080
other than like maybe converting time zones,


00:24:33.080 --> 00:24:34.520
which is like a nightmare.


00:24:34.520 --> 00:24:37.540
- Oh, you can say that again.


00:24:37.540 --> 00:24:38.460
Oh my gosh.


00:24:38.460 --> 00:24:40.100
(laughs)


00:24:40.100 --> 00:24:40.940
- Maybe he said that,


00:24:40.940 --> 00:24:43.220
but it looks like it would be really useful


00:24:43.220 --> 00:24:46.780
for people that are, yeah, that are using it.


00:24:46.780 --> 00:24:50.420
- Yeah, I'm showing up some of the examples


00:24:50.420 --> 00:24:52.020
from DateUtil of how to use it,


00:24:52.020 --> 00:24:56.660
and I imagine this is one of the reasons


00:24:56.660 --> 00:24:58.180
why DateFinder is so used,


00:24:58.180 --> 00:25:00.260
because this is non-trivial,


00:25:00.260 --> 00:25:02.020
you'll even to use DateUtil, so.


00:25:02.020 --> 00:25:05.560
- Yeah, that's cool.


00:25:07.500 --> 00:25:09.300
- Cool, cool, all right, well, I got the next one.


00:25:09.300 --> 00:25:12.380
And this one doesn't exactly come to us from Anthony Shaw,


00:25:12.380 --> 00:25:15.780
but I was talking to Anthony about something else


00:25:15.780 --> 00:25:18.180
and he's like, "Oh, have you heard of this?


00:25:18.180 --> 00:25:20.680
"Have you heard of Cinder?"


00:25:20.680 --> 00:25:23.060
And Cinder is pretty awesome.


00:25:23.060 --> 00:25:27.840
So Anthony's doing interesting work around Python


00:25:27.840 --> 00:25:30.060
and performance at the CPython level,


00:25:30.060 --> 00:25:33.500
especially now, I think he's giving a talk on Pigeon


00:25:33.500 --> 00:25:36.100
or Piston, Piston, I believe it is.


00:25:36.100 --> 00:25:40.340
I'm not 100% sure I might be remembering which one's wrong at PyCon, which is, you know,


00:25:40.340 --> 00:25:42.500
we're going to talk more about that in just a second as well.


00:25:42.500 --> 00:25:50.340
But Sender is a really interesting fork of CPython from Instagram.


00:25:50.340 --> 00:25:53.460
So it's under the Facebook Incubator Project.


00:25:53.460 --> 00:25:57.780
And I think we've mentioned it before, I definitely have talked about it before


00:25:57.780 --> 00:26:01.460
other presentations, that Instagram has done really interesting things like


00:26:01.460 --> 00:26:03.060
disable the garbage collector.


00:26:03.940 --> 00:26:10.340
just turn it off 100% and they got less memory usage, not more memory usage by just allowing


00:26:10.340 --> 00:26:16.180
the cycles to leak, which is insane. But this is like, speaking of insane, this takes it to a whole


00:26:16.180 --> 00:26:21.220
another level. So this is, they've been doing all these low-level things inside of CPython. It's


00:26:21.220 --> 00:26:27.300
based on 3.8. Hopefully some of these ideas can be brought forward and shared with everyone,


00:26:27.300 --> 00:26:33.700
because there's a lot going on. So let me just cruise down here. I'll just read the little intro


00:26:33.700 --> 00:26:39.140
part because it's jam-packed and I'll go into some of the details. So it says this


00:26:39.140 --> 00:26:45.380
is the internal performance-oriented production version of CPython 3.8 and it contains a number


00:26:45.380 --> 00:26:49.220
of performance optimizations. I feel like performance is some sort of theme of this


00:26:49.220 --> 00:26:57.140
this episode. It includes bytecode inline caching, eager evaluations of co-routines, a JIT, just-in-time


00:26:57.140 --> 00:27:02.420
compiler, an experimental bytecode compiler that uses type annotations in


00:27:02.420 --> 00:27:07.980
some incredibly interesting ways to emit type specialized bytecode


00:27:07.980 --> 00:27:13.900
that performs better. So just to give you an example, one of the reasons that math


00:27:13.900 --> 00:27:22.100
in the pure Python layer is slower than say C++ or C# is C++ and C#


00:27:22.100 --> 00:27:26.420
work with just the value. So if you have the value 7, you might have 2 or 4 bytes


00:27:26.420 --> 00:27:32.420
that represent the value 7. In Python you have a pi object pointer which is like


00:27:32.420 --> 00:27:38.180
28 bytes pointing out to a thing on the heap that represents the number 7 and


00:27:38.180 --> 00:27:42.660
it's a whole lot more work to interact with that and set the reference count on


00:27:42.660 --> 00:27:47.140
that and so on instead of just working with the value 7. So one of the


00:27:47.140 --> 00:27:53.740
things they do is they actually have typed the they use Python type


00:27:53.740 --> 00:27:58.860
annotations to understand, oh, this is an integer, this is a long, and so on type of thing,


00:27:58.860 --> 00:28:05.340
and actually convert those to the machine-oriented numbers, right? So just the value four instead of


00:28:05.340 --> 00:28:09.500
a pointer. And then it will use what's called boxing. If something else that's outside of this


00:28:09.500 --> 00:28:16.860
world needs it, it'll up-level that to like a pi long object pointer type thing and hand it off. So


00:28:16.860 --> 00:28:21.100
there's all sorts of stuff like that going on. Interestingly, the first question is, is this


00:28:21.100 --> 00:28:21.940
Is this supported?


00:28:21.940 --> 00:28:23.600
No, it's not supported.


00:28:23.600 --> 00:28:25.860
(laughing)


00:28:25.860 --> 00:28:29.340
But there's some interesting things going on here.


00:28:29.340 --> 00:28:34.340
And all of this has to be taken with an understanding


00:28:34.340 --> 00:28:37.340
that it's in a very specific context


00:28:37.340 --> 00:28:39.420
and that may or may not be useful for you.


00:28:39.420 --> 00:28:42.340
Brian had pointed out some articles and ideas


00:28:42.340 --> 00:28:46.300
around that you're not Instagram, you're not Facebook,


00:28:46.300 --> 00:28:47.920
you're not Netflix and so on.


00:28:47.920 --> 00:28:51.640
Most of the time, people are building much smaller software


00:28:51.640 --> 00:28:52.960
with different constraints.


00:28:52.960 --> 00:28:55.920
So they start out by saying, look,


00:28:55.920 --> 00:28:59.440
Instagram uses a multi-process web server architecture


00:28:59.440 --> 00:29:03.120
where the parent process starts, performs initialization,


00:29:03.120 --> 00:29:07.240
and then forks 10 worker processes to handle requests.


00:29:07.240 --> 00:29:08.400
This is super common.


00:29:08.400 --> 00:29:10.400
Like, for example, TalkBython training literally


00:29:10.400 --> 00:29:11.440
does exactly this.


00:29:11.440 --> 00:29:13.040
It uses microWSGI.


00:29:13.040 --> 00:29:15.080
It starts up, and it creates 10 worker processes


00:29:15.080 --> 00:29:17.720
to handle people wanting to take courses and stuff.


00:29:17.720 --> 00:29:23.060
So it's not uncommon in the web, but it's not how all Python code runs.


00:29:23.060 --> 00:29:29.340
And so the first optimization they did is they created what are called immortal instances.


00:29:29.340 --> 00:29:34.700
The reason they were so focused on the garbage collector and all those sorts of things was


00:29:34.700 --> 00:29:40.180
when you fork these processes, initially there's a bunch of memory that can be shared, and


00:29:40.180 --> 00:29:45.960
that helps with cache locality, that helps with overall memory usage, all sorts of things.


00:29:45.960 --> 00:29:50.400
But as soon as something is changed about one of those items, it has to copy a whole


00:29:50.400 --> 00:29:52.100
page of memory.


00:29:52.100 --> 00:29:58.680
And they realized that when an object's reference count is modified in one of the processes,


00:29:58.680 --> 00:30:05.360
it has to copy, replicate, and sort of fork off a bunch of the memory that used to be


00:30:05.360 --> 00:30:07.240
shared across all those processes.


00:30:07.240 --> 00:30:12.160
So they created what they call "immortal instances" that cannot be, that don't participate in


00:30:12.160 --> 00:30:15.820
reference counting or garbage collection.


00:30:15.820 --> 00:30:17.780
And that prohibits their reference count number


00:30:17.780 --> 00:30:19.100
to change so they can be shared.


00:30:19.100 --> 00:30:21.340
So they can mark a whole bunch of the startup stuff


00:30:21.340 --> 00:30:24.820
as just don't even look at this or change it


00:30:24.820 --> 00:30:27.220
and don't do reference counting on it.


00:30:27.220 --> 00:30:29.640
So in their world, it got things faster.


00:30:29.640 --> 00:30:33.460
But they said it's something a little bit slower


00:30:33.460 --> 00:30:34.780
in straight line code.


00:30:34.780 --> 00:30:36.700
But in this sort of forked world, it's better.


00:30:36.700 --> 00:30:41.120
The next one is Shadow Bytecode, which is an inline caching


00:30:41.120 --> 00:30:42.740
implementation.


00:30:42.740 --> 00:30:47.740
And it goes through, applies in certain optimization cases


00:30:47.740 --> 00:30:50.840
for generic Python opcodes,


00:30:50.840 --> 00:30:53.360
and it'll observe those for functions


00:30:53.360 --> 00:30:54.700
that take a lot of time,


00:30:54.700 --> 00:30:59.700
and dynamically replace those with specialized opcodes


00:30:59.700 --> 00:31:01.740
that it thinks are going to be better.


00:31:01.740 --> 00:31:03.300
Another thing it does that's pretty interesting


00:31:03.300 --> 00:31:06.700
is it will eagerly evaluate coroutines.


00:31:06.700 --> 00:31:08.920
So if I say, this is an async method,


00:31:08.920 --> 00:31:12.520
and then in that method I call await some function call,


00:31:12.520 --> 00:31:15.680
normal Python is going to create a coroutine.


00:31:15.680 --> 00:31:18.100
It's gonna schedule it on the asyncio event loop


00:31:18.100 --> 00:31:19.080
and it's gonna get to it.


00:31:19.080 --> 00:31:20.800
And that's a lot of overhead,


00:31:20.800 --> 00:31:23.280
but maybe that function says inside,


00:31:23.280 --> 00:31:25.180
the first thing is, if this case,


00:31:25.180 --> 00:31:27.280
just return the cached answer,


00:31:27.280 --> 00:31:29.640
otherwise go to the database,


00:31:29.640 --> 00:31:31.720
await the response and so on.


00:31:31.720 --> 00:31:33.440
And what they realized is,


00:31:33.440 --> 00:31:35.640
if it's going to go through that first case,


00:31:35.640 --> 00:31:37.640
it's not actually awaiting something.


00:31:37.640 --> 00:31:42.380
So they'll actually execute the awaited thing


00:31:42.380 --> 00:31:46.880
until it actually needs to become async so it'll like look sort of effectively


00:31:46.880 --> 00:31:50.920
look inside the function and say is the path we're going on this time gonna be


00:31:50.920 --> 00:31:55.820
async or not and if the answer is no it will run it without async which means it


00:31:55.820 --> 00:32:00.980
skips all that context switching and all that stuff which is pretty crazy it also


00:32:00.980 --> 00:32:09.080
has the cinder JIT which is a method in time JIT compiler think C# Java maybe


00:32:09.080 --> 00:32:17.640
be even JavaScript v8. So it's enabled for every function that is called.


00:32:17.640 --> 00:32:21.640
Actually it's not, sorry. If it is, it'll make it slow. So you can basically say


00:32:21.640 --> 00:32:27.760
which functions should be optimized. But they say it supports almost everything


00:32:27.760 --> 00:32:32.920
that Python can do, and it has a 1.5 to 4 times speed up of the Python


00:32:32.920 --> 00:32:38.800
benchmarks, which is pretty interesting. They also have this thing called strict


00:32:38.800 --> 00:32:44.720
modules which is actually a static analyzer capable of validating top-level


00:32:44.720 --> 00:32:48.040
code to see if a module has side effects and can treat it differently if it


00:32:48.040 --> 00:32:55.400
doesn't. So you can have an immutable strict module type that is sort of a


00:32:55.400 --> 00:33:00.720
replacement for Python's regular module that behaves and loads differently and


00:33:00.720 --> 00:33:05.320
so on. And then the thing I talked about the numbers more broadly is under this


00:33:05.320 --> 00:33:09.200
category of static Python. It's an experimental bytecode compiler that


00:33:09.200 --> 00:33:15.840
makes use of type annotations to emit better things. And check this out, it can


00:33:15.840 --> 00:33:22.800
deliver performance similar to mypyc or Cython. And this thing will go up


00:33:22.800 --> 00:33:27.360
to seven times faster than regular Python for the Richards benchmarks. And I


00:33:27.360 --> 00:33:30.960
don't know if the 4x improvement before is like in addition to this so you get


00:33:30.960 --> 00:33:32.780
get 28 or do you just get seven?


00:33:32.780 --> 00:33:34.080
I don't really know.


00:33:34.080 --> 00:33:36.200
But there's a lot of things going on here


00:33:36.200 --> 00:33:39.800
and a lot of different ideas about how this works.


00:33:39.800 --> 00:33:42.380
So I'm just scratching the surface on the details,


00:33:42.380 --> 00:33:45.280
but I feel like I've gone on and on about it.


00:33:45.280 --> 00:33:46.180
What do you think?


00:33:46.180 --> 00:33:49.320
- That's really interesting.


00:33:49.320 --> 00:33:53.440
I saw, I think, is there a talk about it at Python?


00:33:53.440 --> 00:33:55.040
- It is coming up, yes.


00:33:55.040 --> 00:33:57.480
They're going to give a talk on this at Python.


00:33:57.480 --> 00:34:00.360
- Yeah, it was one of the talks I was looking forward


00:34:00.360 --> 00:34:01.920
to listening to.


00:34:01.920 --> 00:34:05.860
Yeah, just because I think it's super interesting


00:34:05.860 --> 00:34:07.860
to be able to kind of play around with


00:34:07.860 --> 00:34:12.320
that they were able to kind of make their own version


00:34:12.320 --> 00:34:14.780
of Python and it might, I don't know,


00:34:14.780 --> 00:34:18.420
like I think that there's, like you mentioned,


00:34:18.420 --> 00:34:23.420
Anthony and I also know Victor, I think,


00:34:23.420 --> 00:34:26.720
and someone else were also working on like sub-interpreters


00:34:26.720 --> 00:34:29.360
and different things to make Python faster.


00:34:29.360 --> 00:34:33.600
So I'm really curious to see if the core devs or people


00:34:33.600 --> 00:34:36.520
will also be listening to this talk


00:34:36.520 --> 00:34:41.240
and maybe take some ideas from it.


00:34:41.240 --> 00:34:43.560
It would be really cool to kind of see.


00:34:43.560 --> 00:34:46.720
And I mean, it's always good to get speed ups,


00:34:46.720 --> 00:34:48.440
even if they, I don't know.


00:34:48.440 --> 00:34:51.720
I don't know if it will help like general,


00:34:51.720 --> 00:34:53.960
like normal Python users,


00:34:53.960 --> 00:34:57.400
but I think it's always good to look into.


00:34:57.400 --> 00:34:58.800
- Yeah, yeah, I agree.


00:34:58.800 --> 00:35:03.120
I think some things here are absolutely transferable


00:35:03.120 --> 00:35:05.280
to regular general purpose CPython.


00:35:05.280 --> 00:35:06.520
And some of them might not be.


00:35:06.520 --> 00:35:10.200
For example, the immortal instances,


00:35:10.200 --> 00:35:12.320
that might be a thing that just--


00:35:12.320 --> 00:35:15.680
they do that, and it makes sense for their large-scale farm


00:35:15.680 --> 00:35:17.040
of servers.


00:35:17.040 --> 00:35:20.200
But the JIT that takes the type information


00:35:20.200 --> 00:35:24.080
and does math many, many times faster,


00:35:24.080 --> 00:35:25.560
everybody would want that.


00:35:25.560 --> 00:35:28.120
We all work with numbers at some level or another.


00:35:28.120 --> 00:35:29.600
Brian?


00:35:29.600 --> 00:35:31.920
- Well, one of the things I love about the,


00:35:31.920 --> 00:35:34.320
I mean, this kind of applies to all of these


00:35:34.320 --> 00:35:36.000
sort of speed up projects.


00:35:36.000 --> 00:35:37.600
One of the things I love about Python


00:35:37.600 --> 00:35:39.280
is that just the generalness of it.


00:35:39.280 --> 00:35:42.560
You can throw it, data structures can hold anything.


00:35:42.560 --> 00:35:47.560
So it's, but there are times where you really are using


00:35:47.560 --> 00:35:51.660
a huge array of floats or a huge array of integers


00:35:51.660 --> 00:35:55.440
or a huge array of like a fixed data size.


00:35:56.720 --> 00:36:00.240
Those are times where I don't need it to be generic.


00:36:00.240 --> 00:36:02.580
I just need it to be fast.


00:36:02.580 --> 00:36:05.940
So having something, that's the part where I think


00:36:05.940 --> 00:36:09.280
it'd be interesting to pull into regular Python.


00:36:09.280 --> 00:36:13.440
But don't we get that with some of the data science stuff


00:36:13.440 --> 00:36:17.100
anyway, some of the number?


00:36:17.100 --> 00:36:18.160
- With NumPy and stuff?


00:36:18.160 --> 00:36:22.400
Yeah, you do, but you can't do generic programming with it.


00:36:22.400 --> 00:36:25.880
You do sort of matrix math type of things.


00:36:25.880 --> 00:36:27.920
And this one, like the answer used to be,


00:36:27.920 --> 00:36:30.320
okay, well, this function is slow.


00:36:30.320 --> 00:36:33.240
This serialization deserialization section might be slow.


00:36:33.240 --> 00:36:35.440
So rewrite that in Cython, for example.


00:36:35.440 --> 00:36:37.600
And what's really cool about this


00:36:37.600 --> 00:36:41.320
is you can write regular Python


00:36:41.320 --> 00:36:43.820
and just put type annotations on it.


00:36:43.820 --> 00:36:46.320
And then it goes as fast as Cython.


00:36:46.320 --> 00:36:49.640
And you don't even have to do like a separate compiler,


00:36:49.640 --> 00:36:50.880
I believe in this world, right?


00:36:50.880 --> 00:36:53.020
'Cause they have, the JIT just knows that.


00:36:53.020 --> 00:36:55.080
And then we'll, like, as you run it,


00:36:55.080 --> 00:36:56.780
it'll just compile and run it.


00:36:56.780 --> 00:36:59.480
So, which is, I think it just sort of makes


00:36:59.480 --> 00:37:03.720
some of those ideas closer and more automatic


00:37:03.720 --> 00:37:05.280
for most people.


00:37:05.280 --> 00:37:10.040
- I kind of think, I foresee a future where we have


00:37:10.040 --> 00:37:12.980
sort of some types that affect runtime.


00:37:12.980 --> 00:37:14.640
There's like this tension in the,


00:37:14.640 --> 00:37:18.020
that I sense in the Python core people


00:37:18.020 --> 00:37:22.040
of whether or not types should be just an afterthought


00:37:22.040 --> 00:37:24.780
or whether they should be really part of the runtime.


00:37:24.780 --> 00:37:29.620
And I think there are some cases


00:37:29.620 --> 00:37:31.000
where having them be part of the runtime


00:37:31.000 --> 00:37:32.560
might be a good thing.


00:37:32.560 --> 00:37:34.000
- Yeah, and this is interesting


00:37:34.000 --> 00:37:39.000
because what they do is they define these static modules


00:37:39.000 --> 00:37:42.440
and then in there, they can treat them differently.


00:37:42.440 --> 00:37:43.280
Sorry, Marlene, go ahead.


00:37:43.280 --> 00:37:45.360
I spoke over you.


00:37:45.360 --> 00:37:47.080
- Oh, no problem.


00:37:47.080 --> 00:37:48.600
I was just saying that I always see,


00:37:48.600 --> 00:37:51.160
like I feel like I always see on Twitter


00:37:51.160 --> 00:37:57.000
people kind of like ranting about how they don't like that direction that Python is going


00:37:57.000 --> 00:38:03.960
in, like this idea of putting in like annotations and things like that. I've seen some people


00:38:03.960 --> 00:38:09.800
that are not super big fans of that. I'm not really sure why. I generally would like to


00:38:09.800 --> 00:38:16.840
understand like, I think most people, or not most people, but I think some people would


00:38:16.840 --> 00:38:21.520
prefer Python to maybe remain as it is, but I do think that there's like, just having


00:38:21.520 --> 00:38:24.840
it be a bit faster in a couple of cases would be helpful.


00:38:24.840 --> 00:38:25.840
So I don't know.


00:38:25.840 --> 00:38:28.840
I don't know if it's in that direction.


00:38:28.840 --> 00:38:29.840
I'm with you.


00:38:29.840 --> 00:38:34.120
And one of the things they point out in this readme announcing the project is that you


00:38:34.120 --> 00:38:36.160
can still do gradual typing.


00:38:36.160 --> 00:38:40.640
So you can, in some places, have no types.


00:38:40.640 --> 00:38:42.640
In some places have some types.


00:38:42.640 --> 00:38:45.200
And the thing can convert and just deal with that automatically.


00:38:45.200 --> 00:38:49.600
And I think that's the reason that the types are really


00:38:49.600 --> 00:38:51.720
welcome in Python, is because you can use them if you want,


00:38:51.720 --> 00:38:53.080
but you don't have to.


00:38:53.080 --> 00:38:55.440
As opposed to places like TypeScript, which said, well,


00:38:55.440 --> 00:38:57.800
JavaScript doesn't have types, so we're going to add this


00:38:57.800 --> 00:38:59.240
very strict type system.


00:38:59.240 --> 00:39:01.480
And if you don't fit it exactly, we're going to not


00:39:01.480 --> 00:39:04.800
compile and complain, and it's going to be really not good.


00:39:04.800 --> 00:39:08.600
This feels like it continues that forgiving nature of


00:39:08.600 --> 00:39:10.560
Python to let you opt into it.


00:39:10.560 --> 00:39:12.040
But if you do, it can go faster.


00:39:12.040 --> 00:39:17.040
- That's the direction I'd like to see.


00:39:17.040 --> 00:39:20.820
I'd like to see, I personally would like to see


00:39:20.820 --> 00:39:24.280
types be really a full-fledged feature of Python.


00:39:24.280 --> 00:39:28.700
- I love that they're optional, but if they're there,


00:39:28.700 --> 00:39:30.100
let's see how much we can do


00:39:30.100 --> 00:39:32.000
and improve things with them, right?


00:39:32.000 --> 00:39:32.840
- Yep.


00:39:32.840 --> 00:39:34.160
- 100%.


00:39:34.160 --> 00:39:35.000
- Yeah.


00:39:35.000 --> 00:39:36.360
All right, Marlene, you got the last one.


00:39:36.360 --> 00:39:38.360
I got it on screen for you.


00:39:38.360 --> 00:39:43.360
Okay, yes, the last one for today is PyCon US,


00:39:43.360 --> 00:39:45.800
which I'm very excited about.


00:39:45.800 --> 00:39:49.560
It started today, which is really great.


00:39:49.560 --> 00:39:51.840
Are both of you attending?


00:39:51.840 --> 00:39:53.440
I don't know if you're attending.


00:39:53.440 --> 00:39:55.880
- Yes, absolutely.


00:39:55.880 --> 00:39:56.720
Right? - Okay.


00:39:56.720 --> 00:39:59.520
- Yes. - Brian, are you attending?


00:39:59.520 --> 00:40:00.340
Yay.


00:40:00.340 --> 00:40:04.360
Yeah, I think it's such a great event


00:40:04.360 --> 00:40:06.720
in terms of the fact that I know it's PyCon US,


00:40:06.720 --> 00:40:11.720
but it is at the moment, it's the largest Python gathering


00:40:11.720 --> 00:40:14.380
or largest PyCon on earth, I think.


00:40:14.380 --> 00:40:18.840
Which is very cool because it means that you can meet people


00:40:18.840 --> 00:40:20.200
from all around the world.


00:40:20.200 --> 00:40:24.480
Like I remember, I'm really sad that it's not in person


00:40:24.480 --> 00:40:27.680
because like last year, like I remember, not last year,


00:40:27.680 --> 00:40:29.520
but the year before that,


00:40:29.520 --> 00:40:31.320
that's where I actually met you, Michael,


00:40:31.320 --> 00:40:32.140
for the first time.


00:40:32.140 --> 00:40:33.820
I think we were literally,


00:40:34.920 --> 00:40:37.800
I think we were like at a table with like you


00:40:37.800 --> 00:40:40.440
and Anthony Shaw and like Lucas Longa


00:40:40.440 --> 00:40:43.220
and it was like, and I was just randomly there.


00:40:43.220 --> 00:40:46.120
But it was such a cool discussion


00:40:46.120 --> 00:40:51.040
and I really love the idea of being able to


00:40:51.040 --> 00:40:55.120
be in a room with people that are like contributing to Python


00:40:55.120 --> 00:40:56.760
- That's my favorite part of PyCon.


00:40:56.760 --> 00:40:59.200
Yeah, it was so nice to meet you as well.


00:40:59.200 --> 00:41:02.800
That is actually my favorite part of PyCon is the,


00:41:02.800 --> 00:41:08.360
just you happen to end up at a table or out for a beer or coffee with this group of people


00:41:08.360 --> 00:41:12.800
and you're like, wow, I got these connections and this experience that just I wouldn't.


00:41:12.800 --> 00:41:15.080
So I'm very much looking forward to coming back in person.


00:41:15.080 --> 00:41:18.280
But there's a bunch of great talks coming up.


00:41:18.280 --> 00:41:19.380
Exactly.


00:41:19.380 --> 00:41:25.680
So this year, it's also really, although it's online, the online platform is very cool.


00:41:25.680 --> 00:41:28.680
And there's still lots of great talks to watch.


00:41:28.680 --> 00:41:33.440
In the show notes I put down a list of the talks that I'm excited to watch, but I also


00:41:33.440 --> 00:41:39.120
want to just put in a word for the things that I will be doing at PyCon US this year.


00:41:39.120 --> 00:41:43.280
The first thing I'm going to be doing is I'm going to be hosting the diversity and inclusion


00:41:43.280 --> 00:41:50.480
work group discussion, along with four other really amazing women that are part of the


00:41:50.480 --> 00:41:52.360
diversity and inclusion work group.


00:41:52.360 --> 00:41:59.200
I do want to comment here because we got some comments about it, some feedback.


00:41:59.200 --> 00:42:04.520
I posted a picture of our group that's going to be having this discussion or


00:42:04.520 --> 00:42:06.200
hosting this panel and it's all women.


00:42:06.200 --> 00:42:08.560
And someone was just like, why is it all women?


00:42:08.560 --> 00:42:09.840
How is this diversity?


00:42:09.840 --> 00:42:13.240
So I do want to throw it out there.


00:42:13.240 --> 00:42:18.360
I just want to throw it out there that we did try, like the work group itself has


00:42:18.400 --> 00:42:24.080
a lot of, it has a good balance of men and women in it, but then when I asked people


00:42:24.080 --> 00:42:27.840
if they want to come on the panel, it was only like women that volunteered.


00:42:27.840 --> 00:42:31.520
So it's not my fault, and I am aware of that.


00:42:31.520 --> 00:42:36.520
That's just a general feedback there.


00:42:36.520 --> 00:42:41.000
But I think the panel will be really exciting.


00:42:41.000 --> 00:42:49.000
It's going to be on Saturday on the main stage at 12 p.m. EST, I think.


00:42:49.000 --> 00:42:56.600
And yeah, if you are going to be there, I really would encourage you to attend.


00:42:56.600 --> 00:42:59.200
There's going to be question and answer.


00:42:59.200 --> 00:43:01.040
And I just think it's such an important thing.


00:43:01.040 --> 00:43:07.600
I know that sometimes diversity can seem like a really tiring thing to talk about, especially


00:43:07.600 --> 00:43:08.600
like recently.


00:43:08.600 --> 00:43:13.800
I feel like sometimes people use it as like this buzzword and it can and people gonna be like


00:43:13.800 --> 00:43:16.900
Oh my gosh and just turn off when they hear hear the word diversity


00:43:16.900 --> 00:43:20.200
but I really do think it's important and


00:43:20.200 --> 00:43:27.760
Particularly now as Python is growing in popularity. I think a few years ago. It was okay for


00:43:27.760 --> 00:43:34.200
Like the nucleus of Python to be based in the United States or based in Europe


00:43:34.520 --> 00:43:37.180
But it's growing so quickly.


00:43:37.180 --> 00:43:42.380
Python for I don't know how many years now has been the most popular language in the world.


00:43:42.380 --> 00:43:46.620
And I know even for me, I'm in Zimbabwe right now,


00:43:46.620 --> 00:43:50.140
and it's one of the most popular languages here where I live.


00:43:50.140 --> 00:43:53.180
And so just providing the group,


00:43:53.180 --> 00:43:58.420
like our main purpose is to figure out how we can support the PSF


00:43:58.420 --> 00:44:02.860
to try and serve Pythonistas from around the world better


00:44:02.860 --> 00:44:05.820
and to connect the community better


00:44:05.820 --> 00:44:07.340
and to have better representation


00:44:07.340 --> 00:44:08.260
and different things like that.


00:44:08.260 --> 00:44:10.300
So very excited about that one.


00:44:10.300 --> 00:44:12.300
- Yeah, that's awesome.


00:44:12.300 --> 00:44:14.140
And thanks for your work here.


00:44:14.140 --> 00:44:18.660
I definitely agree that we're stronger together, right?


00:44:18.660 --> 00:44:22.060
And one thing I would really like to see,


00:44:22.060 --> 00:44:23.140
and I think we're getting there,


00:44:23.140 --> 00:44:26.940
is when people look at Python and programming in general,


00:44:26.940 --> 00:44:29.660
but like the area we control is generally the Python space,


00:44:29.660 --> 00:44:31.100
we have influence over that.


00:44:31.100 --> 00:44:35.220
When people look at that world, I would like them to say,


00:44:35.220 --> 00:44:37.300
I can see myself being part of that.


00:44:37.300 --> 00:44:39.460
I can see that I could belong there, right?


00:44:39.460 --> 00:44:44.460
And if that's not the case, then how do we make that the case?


00:44:44.460 --> 00:44:47.500
- Exactly, absolutely.


00:44:47.500 --> 00:44:50.020
I think exactly that.


00:44:50.020 --> 00:44:52.300
And I would love to see that happening


00:44:52.300 --> 00:44:53.360
in the next few years.


00:44:53.360 --> 00:44:56.580
I would love to see, one of my things is


00:44:56.580 --> 00:44:59.900
I'd love to see more women core developers


00:44:59.900 --> 00:45:02.580
and more like global core developers as well,


00:45:02.580 --> 00:45:04.780
and also people on the board and different things.


00:45:04.780 --> 00:45:06.820
And those are all goals that we are working towards.


00:45:06.820 --> 00:45:10.460
And obviously we don't know like the perfect way


00:45:10.460 --> 00:45:13.260
to achieve something or the perfect way to do things,


00:45:13.260 --> 00:45:16.460
but it's something that I think is really great


00:45:16.460 --> 00:45:18.100
and exciting to work on.


00:45:18.100 --> 00:45:21.500
So please attend if you are listening to this.


00:45:21.500 --> 00:45:25.300
And let me know if you like came from this podcast,


00:45:25.300 --> 00:45:27.340
it would be fantastic to see you there.


00:45:27.340 --> 00:45:28.340
Maybe just comment.


00:45:28.340 --> 00:45:37.460
And then, oh, another thing that I am doing for PyCon this year as well is I will be -- one,


00:45:37.460 --> 00:45:41.700
I will be in the -- so there's like a lounge area.


00:45:41.700 --> 00:45:44.300
Well, there's like a PSF booth.


00:45:44.300 --> 00:45:48.340
And if you would like to just -- if you're going to be there in the morning on Saturday


00:45:48.340 --> 00:45:52.860
or on Friday, I will be hanging out in the PSF booth.


00:45:52.860 --> 00:45:57.580
And so, yeah, if you just want to talk about Python or the PSF or anything, I will be there.


00:45:57.580 --> 00:46:02.460
And I'll also be hosting the EMEA meeting.


00:46:02.460 --> 00:46:05.900
So if you're in Europe, the Middle East or Africa,


00:46:05.900 --> 00:46:08.660
there's a members meeting on Saturday.


00:46:08.660 --> 00:46:12.420
I think it's at 10 a.m. Central African time.


00:46:12.420 --> 00:46:14.820
I'm not sure what time that is in other places.


00:46:14.820 --> 00:46:16.580
But I know that 10 a.m.


00:46:16.580 --> 00:46:17.420
- It's on the schedule, right?


00:46:17.420 --> 00:46:18.780
It's on the schedule.


00:46:18.780 --> 00:46:22.460
- Yeah, we can use the date time thing, I don't know.


00:46:22.460 --> 00:46:23.420
- Exactly.


00:46:23.420 --> 00:46:25.980
Pull up the record, throw it into date time finder.


00:46:25.980 --> 00:46:33.420
Exactly, please do that. So I will be hosting that and that's going to be in the morning and


00:46:33.420 --> 00:46:39.180
if you would like, even if you're not a member, you can watch it on the PSF YouTube channel. It's


00:46:39.180 --> 00:46:45.500
going to be streaming there or you could join, there's a meetup link that I put in the


00:46:45.500 --> 00:46:51.500
show notes so people could join that way as well. So yeah, Python is going to be really exciting and


00:46:51.500 --> 00:46:52.900
and I'm really looking forward to it.


00:46:52.900 --> 00:46:56.100
So just encouraging people to come along for sure.


00:46:56.100 --> 00:46:58.740
- Fantastic.


00:46:58.740 --> 00:47:00.460
Yeah, it should be fun.


00:47:00.460 --> 00:47:05.060
And even though it is super sad that it's not in person,


00:47:05.060 --> 00:47:06.700
it's not in Pittsburgh this year,


00:47:06.700 --> 00:47:13.180
it's more, I think in some ways it's more accessible


00:47:13.180 --> 00:47:14.540
to people around the world, right?


00:47:14.540 --> 00:47:16.140
They don't have to travel there.


00:47:16.140 --> 00:47:18.820
They can just log in and attend it.


00:47:18.820 --> 00:47:20.660
And that's so much less expensive


00:47:20.660 --> 00:47:24.540
Then I flew to the US and I paid $1,000 for a hotel.


00:47:24.540 --> 00:47:27.060
So there's a little silver lining.


00:47:27.060 --> 00:47:30.420
You know, out there in the live stream, Sam Morley,


00:47:30.420 --> 00:47:32.700
it really says, "I really wish I could go to PyCon


00:47:32.700 --> 00:47:33.980
in person."


00:47:33.980 --> 00:47:37.580
Adam Parkin out there says, "Me too, maybe in 2020."


00:47:37.580 --> 00:47:38.800
I think so.


00:47:38.800 --> 00:47:40.620
Finally, Sam is also thinks it's great


00:47:40.620 --> 00:47:44.700
that we're having this diversity conversation


00:47:44.700 --> 00:47:46.660
and paying attention to it.


00:47:46.660 --> 00:47:49.100
- One of the things I've noticed in 2020


00:47:49.100 --> 00:47:53.700
is all the regional, actually last year also though,


00:47:53.700 --> 00:47:58.100
but the 2020 and 2021,


00:47:58.100 --> 00:48:02.320
we've got all these PyCons going on all over the world.


00:48:02.320 --> 00:48:06.040
I used to think of like PyCon US as the PyCon


00:48:06.040 --> 00:48:07.940
and everything else is regional.


00:48:07.940 --> 00:48:12.680
Now I think of PyCon US as a regional conference also.


00:48:12.680 --> 00:48:15.340
It's the regional one that's close to the people


00:48:15.340 --> 00:48:16.800
that are in the US.


00:48:16.800 --> 00:48:18.940
It isn't necessarily better.


00:48:18.940 --> 00:48:22.220
It's, I love it, it's great.


00:48:22.220 --> 00:48:25.360
Anybody from, that's hosting it, yes, it's better, but no.


00:48:25.360 --> 00:48:32.220
I like all of them and I was excited to get to participate


00:48:32.220 --> 00:48:35.460
and watch videos from all over the world this year.


00:48:35.460 --> 00:48:36.980
That was pretty neat.


00:48:36.980 --> 00:48:38.860
But yeah, I'm on board with,


00:48:38.860 --> 00:48:42.180
I wanna get back to regional stuff.


00:48:42.180 --> 00:48:44.220
I'd like to see people in person.


00:48:44.220 --> 00:48:45.060
I can't wait.


00:48:45.060 --> 00:48:47.660
- Yeah, I will say for sure,


00:48:47.660 --> 00:48:51.740
Like, even if people are feeling adventurous,


00:48:51.740 --> 00:48:53.420
there is a regional conference,


00:48:53.420 --> 00:48:54.920
I didn't mention it before,


00:48:54.920 --> 00:48:57.780
that I am also part of the organizing team for,


00:48:57.780 --> 00:48:59.900
which is PyCon Africa.


00:48:59.900 --> 00:49:03.780
So if you would like to travel to another PyCon


00:49:03.780 --> 00:49:05.420
in a different part of the world,


00:49:05.420 --> 00:49:06.980
when we are able to travel


00:49:06.980 --> 00:49:11.980
and the world gets back to some form of re-travel,


00:49:11.980 --> 00:49:17.260
definitely recommend also hopping over to PyCon Africa.


00:49:17.260 --> 00:49:21.860
I think, like you said, I think Python US is fantastic.


00:49:21.860 --> 00:49:28.660
And one of the unique things about that is that it's a conference that has been there for so long,


00:49:28.660 --> 00:49:30.460
so a lot of people are going to be there.


00:49:30.460 --> 00:49:36.340
But there 100% are a lot of great conferences like Python Africa,


00:49:36.340 --> 00:49:39.620
which you should attend if you can.


00:49:39.620 --> 00:49:42.620
I think they're really just as exciting.


00:49:42.620 --> 00:49:45.700
And there's so many cool things that you get to experience.


00:49:45.700 --> 00:49:49.380
I think for me, it's like whenever I go to the US,


00:49:49.380 --> 00:49:52.860
like last year, I'd never been to Ohio before.


00:49:52.860 --> 00:49:57.860
And like, I would never have a reason


00:49:57.860 --> 00:50:00.260
that I would think to myself,


00:50:00.260 --> 00:50:03.420
let me go to America to go to Ohio.


00:50:03.420 --> 00:50:08.020
But I feel like it was such a good experience for me


00:50:08.020 --> 00:50:11.420
and I really liked it and I was really surprised by that.


00:50:11.420 --> 00:50:14.620
And so I think it's the same way,


00:50:14.620 --> 00:50:16.140
like Pythons are a great way as well


00:50:16.140 --> 00:50:18.300
to like experience new places.


00:50:18.300 --> 00:50:21.820
So yeah, definitely recommend that.


00:50:21.820 --> 00:50:24.700
- Absolutely.


00:50:24.700 --> 00:50:29.100
- Well, that wraps up our six.


00:50:29.100 --> 00:50:33.020
Anybody got any extra information to share?


00:50:33.020 --> 00:50:34.900
- I've got a couple.


00:50:34.900 --> 00:50:36.900
Marlene, anything else you wanna throw out there


00:50:36.900 --> 00:50:37.940
to tell people about?


00:50:37.940 --> 00:50:42.780
- Nothing else for me other than the fact


00:50:42.780 --> 00:50:45.320
that if you do want to reach out to me,


00:50:45.320 --> 00:50:48.100
you can reach out to me on Twitter.


00:50:48.100 --> 00:50:50.580
I'm Marlene_Zaw there.


00:50:50.580 --> 00:50:55.580
I'm also Marlene_Zaw on GitHub, I think,


00:50:55.580 --> 00:50:57.860
and on my website.


00:50:57.860 --> 00:51:00.740
My website is MarleneMangami.com.


00:51:00.740 --> 00:51:03.540
So if you would like to reach out to me there,


00:51:03.540 --> 00:51:04.520
feel free to.


00:51:04.520 --> 00:51:08.600
I'm always happy to like chat about Python or anything.


00:51:08.600 --> 00:51:09.500
- Nice.


00:51:09.500 --> 00:51:10.340
- Cool.


00:51:10.340 --> 00:51:11.300
- All right.


00:51:11.300 --> 00:51:12.180
So I got a couple.


00:51:12.180 --> 00:51:15.460
One made me really excited, this tweet from GitHub.


00:51:15.460 --> 00:51:18.100
It says, "Is your fork behind?


00:51:18.100 --> 00:51:21.220
"You can now sync your parent repo


00:51:21.220 --> 00:51:22.700
"with just a single click."


00:51:22.700 --> 00:51:23.760
So check this out.


00:51:23.760 --> 00:51:26.660
If you go to your fork now,


00:51:26.660 --> 00:51:29.020
next to contribute for your PRs and stuff,


00:51:29.020 --> 00:51:32.020
there is now a fetch upstream button,


00:51:32.020 --> 00:51:33.900
and all you have to do is click it,


00:51:33.900 --> 00:51:37.740
and then automatically your fork will become in sync


00:51:37.740 --> 00:51:39.640
with whatever you forked it from.


00:51:39.640 --> 00:51:42.480
You just have to go and go check it out,


00:51:42.480 --> 00:51:45.200
add an upstream origin, and then pull from that,


00:51:45.200 --> 00:51:48.240
and then merge that in wherever you want it to go to.


00:51:48.240 --> 00:51:50.080
Over here, you just click this button,


00:51:50.080 --> 00:51:52.280
and boom, it's good to go.


00:51:52.280 --> 00:51:54.080
So I think this will just lower the bar


00:51:54.080 --> 00:51:55.720
for people forking something,


00:51:55.720 --> 00:51:57.200
they wanna get the current one,


00:51:57.200 --> 00:51:59.640
and then make a change to see if they could contribute back.


00:51:59.640 --> 00:52:03.280
Here's one fewer steps in that process.


00:52:03.280 --> 00:52:05.400
- Do you have any idea if it stays in sync,


00:52:05.400 --> 00:52:06.760
or if it's, you have to--


00:52:06.760 --> 00:52:09.400
- No, it's a one-time type of thing, I believe.


00:52:09.400 --> 00:52:11.280
It says there's this many changes, we'll pull over,


00:52:11.280 --> 00:52:14.220
and it basically just automatically does the process


00:52:14.220 --> 00:52:15.720
at that time.


00:52:15.720 --> 00:52:17.440
But still pretty nice.


00:52:17.440 --> 00:52:19.120
Pretty nice.


00:52:19.120 --> 00:52:20.880
Next one, I'll clean up here.


00:52:20.880 --> 00:52:23.900
Flask 2.0 is out.


00:52:23.900 --> 00:52:28.900
And that one was sent in to us from Adam Parkin


00:52:28.900 --> 00:52:32.420
that, hey, heads up, this is now actually live.


00:52:32.420 --> 00:52:33.780
So very, very cool.


00:52:33.780 --> 00:52:35.680
And--


00:52:35.680 --> 00:52:38.880
- Yeah, actually everything from Palettes has been updated.


00:52:38.880 --> 00:52:39.800
So--


00:52:39.800 --> 00:52:41.800
>>Victor: Yeah.


00:52:41.800 --> 00:52:44.560
I happen to have spoken--


00:52:44.560 --> 00:52:46.440
done a podcast recording with David Lord, who


00:52:46.440 --> 00:52:49.280
runs Palettes, and Phil Jones, who does core


00:52:49.280 --> 00:52:52.000
and contributes back to Palettes as well,


00:52:52.000 --> 00:52:56.000
about all the stuff coming in Flask 2.0,


00:52:56.000 --> 00:52:58.680
all the exciting stuff, and their future plans as well.


00:52:58.680 --> 00:53:01.240
So yeah, you can watch the live stream of that


00:53:01.240 --> 00:53:03.360
or wait a day or two until the episode is out


00:53:03.360 --> 00:53:05.840
and just listen at Talk Python as well.


00:53:05.840 --> 00:53:06.920
But yeah, very, very cool.


00:53:06.920 --> 00:53:08.840
Yeah.


00:53:08.840 --> 00:53:11.000
And then Adam also at the live stream again says,


00:53:11.000 --> 00:53:12.680
this is super sweet, always find it a headache


00:53:12.680 --> 00:53:14.000
to sync with upstream.


00:53:14.000 --> 00:53:15.080
Yeah, about the GitHub thing.


00:53:15.080 --> 00:53:15.980
That's cool.


00:53:15.980 --> 00:53:19.080
- Cool.


00:53:19.080 --> 00:53:20.840
- All right, should we?


00:53:20.840 --> 00:53:22.240
- I've got a-- - You got a joke?


00:53:22.240 --> 00:53:24.720
- Well, I got a couple of things I wanted to mention.


00:53:24.720 --> 00:53:25.760
- Go for it. - Sorry.


00:53:25.760 --> 00:53:30.400
I had Brett Cannon on last week on testing code


00:53:30.400 --> 00:53:32.320
and huge feedback from everybody


00:53:32.320 --> 00:53:33.360
that it was a great episode.


00:53:33.360 --> 00:53:35.380
We talked about packaging.


00:53:35.380 --> 00:53:37.680
I'll have Ryan Howard on this week


00:53:37.680 --> 00:53:40.400
talking about Playwright, so that'll be fun.


00:53:40.400 --> 00:53:44.800
And I wanted to mention a thank you to the 71 Patreon patrons


00:53:44.800 --> 00:53:46.320
that we have on Patreon.


00:53:46.320 --> 00:53:48.200
So thank you for supporting the show.


00:53:48.200 --> 00:53:49.520
Thanks.


00:53:49.520 --> 00:53:50.720
Yeah, thank you, everyone.


00:53:50.720 --> 00:53:52.160
How about a joke?


00:53:52.160 --> 00:53:52.880
A joke, yes.


00:53:52.880 --> 00:53:57.480
Sorry for almost skipping over your extras.


00:53:57.480 --> 00:53:58.440
No worries.


00:53:58.440 --> 00:53:59.400
You ready?


00:53:59.400 --> 00:54:00.000
Yeah.


00:54:00.000 --> 00:54:04.720
So this one, I talked about that crazy giant ship thing.


00:54:04.720 --> 00:54:06.400
And we've got Marlene doing Rapid.


00:54:06.400 --> 00:54:09.360
So I thought maybe some kind of machine learning joke.


00:54:09.360 --> 00:54:14.100
Here's a bunch of robots in school


00:54:14.100 --> 00:54:17.080
and they go like little Android looking things,


00:54:17.080 --> 00:54:20.060
small ones 'cause they're students, they're kids.


00:54:20.060 --> 00:54:21.900
And they're in machine learning class


00:54:21.900 --> 00:54:24.020
and there's a big box of dirty data.


00:54:24.020 --> 00:54:27.180
Like a bunch of bits that are like kind of gray


00:54:27.180 --> 00:54:29.580
and just have dirt on them.


00:54:29.580 --> 00:54:33.380
And the teacher says, "Robbie, stop misbehaving


00:54:33.380 --> 00:54:35.480
or I will send you back to data cleaning."


00:54:35.480 --> 00:54:37.880
[LAUGHTER]


00:54:37.880 --> 00:54:39.720
Oh, wow.


00:54:39.720 --> 00:54:40.560
Yeah.


00:54:40.560 --> 00:54:42.640
That's where they're spending half the day anyway.


00:54:42.640 --> 00:54:44.800
Yeah, they actually spend most of their time there.


00:54:44.800 --> 00:54:46.240
That's right.


00:54:46.240 --> 00:54:48.120
I don't know who is drawing them.


00:54:48.120 --> 00:54:50.200
One of the robots is looking the wrong way.


00:54:50.200 --> 00:54:51.920
I was like, why is it drawn like that?


00:54:51.920 --> 00:54:53.920
I don't understand.


00:54:53.920 --> 00:54:58.560
I don't fully get the joke either, but there it is.


00:54:58.560 --> 00:55:01.320
Hey, a more concrete, really quick close-out question


00:55:01.320 --> 00:55:03.080
I see in the live stream here is,


00:55:03.080 --> 00:55:08.680
Is there a difference between KudF and Pandas in terms of utilization?


00:55:08.680 --> 00:55:10.880
I don't know.


00:55:10.880 --> 00:55:15.160
In terms of how you actually use them?


00:55:15.160 --> 00:55:18.720
Well, I don't think so.


00:55:18.720 --> 00:55:26.000
For the most part, when you're using KudF, the way it's built is to mirror Pandas, so


00:55:26.000 --> 00:55:28.920
the APIs are really similar.


00:55:28.920 --> 00:55:34.300
So ideally, the methods that you would use when you're using pandas are exactly the same


00:55:34.300 --> 00:55:36.940
methods that you would use when you're using cuDF.


00:55:36.940 --> 00:55:41.720
The only difference is like when you're creating a pandas data frame, for example, you would


00:55:41.720 --> 00:55:44.660
use pd.dataframe, for example.


00:55:44.660 --> 00:55:49.060
But then with cuDF, you would say cuDF.dataframe.


00:55:49.060 --> 00:55:54.180
If you make it like into a variable or something like that, then the methods that you're going


00:55:54.180 --> 00:55:57.220
to call are going to be probably identical.


00:55:57.220 --> 00:55:59.840
So it's really, I think it's really,


00:55:59.840 --> 00:56:01.200
it's really easy to try.


00:56:01.200 --> 00:56:02.380
- Yeah, that's awesome.


00:56:02.380 --> 00:56:04.480
Yeah, and Dask has similar stuff as well, right?


00:56:04.480 --> 00:56:06.880
You create a Dask data frame instead of a Pandas data frame,


00:56:06.880 --> 00:56:08.400
but the API looks quite similar.


00:56:08.400 --> 00:56:11.800
They're not always 100% compatible,


00:56:11.800 --> 00:56:14.320
but most of the mainstream things, right?


00:56:14.320 --> 00:56:18.960
- Definitely, so it is, yeah, it's built definitely


00:56:18.960 --> 00:56:22.960
to make it as easy as possible to switch between the two,


00:56:22.960 --> 00:56:24.840
so it's very similar, yeah.


00:56:24.840 --> 00:56:25.780
- Cool.


00:56:25.780 --> 00:56:26.980
Ryan, is that it?


00:56:26.980 --> 00:56:27.820
Are we done?


00:56:27.820 --> 00:56:28.660
- Yeah.


00:56:28.660 --> 00:56:32.020
So thanks a lot, everybody, for showing up.


00:56:32.020 --> 00:56:33.860
- Yeah, thanks.


00:56:33.860 --> 00:56:34.700
- Thank you, Phil. - Thanks, Ryan.


00:56:34.700 --> 00:56:35.540
Thank you, Marlene.


00:56:35.540 --> 00:56:36.380
It's really great to have you here.


00:56:36.380 --> 00:56:37.700
- Bye, Phil.


00:56:37.700 --> 00:56:38.580
- No problem.


00:56:38.580 --> 00:56:39.780
Thanks for having me.


00:56:39.780 --> 00:56:49.780
[BLANK_AUDIO]

