WEBVTT

00:00:02.000 --> 00:00:02.480
Hello, everyone.

00:00:03.800 --> 00:00:04.220
Hey, Brian.

00:00:05.420 --> 00:00:06.640
Oh, hey, let me switch around.

00:00:06.720 --> 00:00:10.320
I just realized we put that on backwards.

00:00:10.480 --> 00:00:10.840
There we go.

00:00:11.440 --> 00:00:19.480
Because it's an even, even episode, which for those of you who maybe have listened for a while might know that changes the order just a little bit.

00:00:20.360 --> 00:00:21.360
All right, well, I'm super excited.

00:00:21.580 --> 00:00:26.280
All of y'all are here on YouTube in whatever fashion, live or historical or whatever.

00:00:27.640 --> 00:00:30.400
But I think it's time to start the real show, What do you think, Brian?

00:00:30.740 --> 00:00:32.000
I think that's a great idea.

00:00:36.300 --> 00:00:41.820
Hello and welcome to Python Bytes, where we deliver Python news and headlines directly to your earbuds.

00:00:42.280 --> 00:00:49.460
This is episode 436, recorded June 16th, 2025.

00:00:50.520 --> 00:00:51.100
I'm Michael Kennedy.

00:00:51.800 --> 00:00:52.600
And I'm Brian Okken.

00:00:53.780 --> 00:00:57.300
And this episode is brought to you by PropelAuth.

00:00:57.320 --> 00:01:01.860
we want to say thank you, thank you to Propel Auth for sponsoring the show.

00:01:02.340 --> 00:01:09.480
I'm going to tell you more about them later, but TLDR, if you have to do authentication in your app, that can be a huge hassle.

00:01:09.700 --> 00:01:12.640
It's not the core business of your app. Give them a look.

00:01:12.960 --> 00:01:16.080
They'll solve that problem for you and let you go back to building whatever you're supposed to be building.

00:01:17.620 --> 00:01:23.440
Speaking of supposed to, you're supposed to be following us on some form of social, I would say, don't you think, Brian?

00:01:23.620 --> 00:01:29.060
So we got our social media links out on the top of the show notes, so check that out there.

00:01:29.540 --> 00:01:33.600
We do our live streaming if you want to be part of the show while we record it.

00:01:34.680 --> 00:01:43.000
We flip the switch and make it go live around 10 a.m. on Mondays Pacific time, and all the older versions are there as well.

00:01:43.380 --> 00:02:12.740
And finally, if you want a really nice detailed email summary with extra information and background details on what we talk about, become a friend of the show, sign up for a mailing list. We're not here to spam you or to resell you for sure. Just to send you notes about things like what we covered in the show, maybe a very rare announcement of like a new course or some event or something like that. But we'd appreciate if you signed up there as well.

00:02:12.980 --> 00:02:22.160
And Brian, I've always, always been impressed with the ability to do multi-threaded programming.

00:02:22.560 --> 00:02:26.800
I've enjoyed it on other languages and platforms where it was sort of full featured.

00:02:26.950 --> 00:02:31.300
So that's why I was so excited when FreeThreadedPython came out.

00:02:32.320 --> 00:02:34.840
But it only partly came out, didn't it, in 3.13?

00:02:35.210 --> 00:02:36.880
Like partially or with a caveat.

00:02:37.620 --> 00:02:38.060
Yeah.

00:02:38.370 --> 00:02:39.700
So let's see.

00:02:39.920 --> 00:02:40.260
Add to state.

00:02:41.540 --> 00:02:42.180
Here we go.

00:02:42.580 --> 00:02:45.120
So and what was that?

00:02:45.280 --> 00:02:46.260
PEP 703.

00:02:47.770 --> 00:02:52.260
So anyway, there was – I can't remember the PEP for when we had.

00:02:52.820 --> 00:02:55.640
free-threaded as an option that you could turn on.

00:02:56.160 --> 00:02:59.740
But then now there was an announcement, exciting news.

00:02:59.820 --> 00:03:02.540
I saw this on the socials.

00:03:02.960 --> 00:03:06.480
It was on Mastodon from Hugo von Kaminade.

00:03:07.480 --> 00:03:19.460
Exciting news, PEP779, which was the criteria for supported status for free-threaded Python, has been accepted, which means free-threaded Python is now a supported build.

00:03:20.060 --> 00:03:33.800
What that means is they will drop the experimental label for, and so for 3.14 beta 3 due on Tuesday, it will no longer be experimental.

00:03:33.930 --> 00:03:39.720
So really what that means is we're ready to kind of support it.

00:03:39.870 --> 00:03:42.220
Actually, I wasn't sure really exactly what this meant.

00:03:42.740 --> 00:03:46.660
So hop over to Hugo linked to a discussion.

00:03:48.400 --> 00:03:50.680
And I might have the wrong link there.

00:03:51.380 --> 00:04:03.840
So this discussion, here we go, was talking about the steering council approving 779, which was the criteria, with the effect of removing experimental.

00:04:05.020 --> 00:04:08.260
And then there's a lot of details of what all this means for phase two.

00:04:08.460 --> 00:04:23.860
There's a lot of stuff that has to happen in phase two, which is like making sure that the API, ABI compatibility requirements for experimental projects, some performance and memory guardrails.

00:04:23.930 --> 00:04:24.880
We've talked about those before.

00:04:26.200 --> 00:04:26.980
I do like this.

00:04:27.180 --> 00:04:32.720
There's a section on what documentation needs to be there before we completely jump in with both feet.

00:04:32.790 --> 00:04:36.080
We need to make sure documentation is clearly written and maintained.

00:04:36.740 --> 00:04:40.980
There's some high-level concurrency primitives and some benchmark requirements that are needed.

00:04:42.320 --> 00:04:57.700
If you pop down to the end, it says, we're confident that the project is on the right path, and we appreciate the continued dedication from everyone working to make the free-threading ready for a broader adoption across the Python community.

00:04:59.080 --> 00:05:05.940
So there's a lot of work to do, and I wasn't quite sure exactly how much work there is left to do, So, you know, I asked some people.

00:05:07.100 --> 00:05:11.760
So I got a response of like, hey, does this mean that we're going to be the default?

00:05:12.040 --> 00:05:14.040
And I knew the answer that it's not going to be for a while.

00:05:14.110 --> 00:05:19.380
But I wanted to have somebody more core than me answer that.

00:05:20.040 --> 00:05:27.120
And Thomas Wooter says, basically, it's going to be a few years before it's really the default.

00:05:27.460 --> 00:05:29.860
And really, how do we say default?

00:05:32.700 --> 00:05:39.480
it can't happen before 3.16 because of the stable ABI support requirement.

00:05:40.220 --> 00:05:41.220
And it may take longer.

00:05:42.720 --> 00:05:45.100
And really default is a squishy concept.

00:05:45.540 --> 00:05:47.020
So good answer from Thomas, thanks.

00:05:47.900 --> 00:05:48.780
But this is encouraging.

00:05:49.560 --> 00:05:53.080
I'm excited to move forward with the free threading path.

00:05:54.259 --> 00:05:55.200
I'm as well.

00:05:55.660 --> 00:06:05.160
You've got to go slow with this kind of thing because it's such a change, especially at the lower level C API and integration like you're talking about.

00:06:05.800 --> 00:06:05.960
Yeah.

00:06:06.820 --> 00:06:06.940
Yeah.

00:06:07.560 --> 00:06:08.600
But I'm very excited for it.

00:06:08.600 --> 00:06:12.420
I think it opens up a lot of very interesting opportunities.

00:06:12.600 --> 00:06:24.800
Like right now, if I write Python code and I don't go do something explicit like multiprocessing, I can get 10% of my computing resources, which is pretty darn low.

00:06:25.640 --> 00:06:34.960
So the ability to just, let's say, run this in parallel and actually get it to run normal without the constraints of serializing over to

00:06:34.960 --> 00:06:35.840
multiple processes.

00:06:36.440 --> 00:06:37.060
It's really cool.

00:06:37.460 --> 00:06:40.180
And that's kind of where some of the documentation needs are there.

00:06:40.380 --> 00:06:42.860
And maybe those are already there, but I just don't know where they are.

00:06:43.020 --> 00:06:46.720
But the thoughts of, okay, I'd like to have my project.

00:06:47.320 --> 00:06:52.280
Let's say I want my project to be supported on support free threading.

00:06:53.260 --> 00:06:53.940
What does that mean?

00:06:54.120 --> 00:06:55.380
What do I need to look out for?

00:06:56.800 --> 00:07:01.040
I mean, I obviously need to check all my dependencies to make sure that they're tested on that.

00:07:01.260 --> 00:07:03.080
But what do I need to test?

00:07:03.400 --> 00:07:04.700
And things like that.

00:07:04.720 --> 00:07:07.060
I think those are good things to document.

00:07:07.360 --> 00:07:08.160
Yeah, yeah.

00:07:08.580 --> 00:07:11.160
I suspect if you're doing pure Python, it's pretty straightforward.

00:07:13.319 --> 00:07:17.800
There's always the concern that whatever you're doing needs to be thread safe, right?

00:07:18.940 --> 00:07:22.540
And I think people put Python aside in programming in general.

00:07:23.300 --> 00:07:33.420
they don't think enough about the thread safety aspects or even error handling sort of consistency type of stuff.

00:07:33.680 --> 00:07:38.600
Like I took three steps, there was an error, but the fourth step was required to put it back into a consistent state.

00:07:39.220 --> 00:07:40.180
I caught the error, it's fine.

00:07:40.280 --> 00:07:41.840
Like, no, it's not fine, it's really broken.

00:07:42.620 --> 00:07:44.960
So there's a lot of situations like that.

00:07:45.120 --> 00:07:49.300
I think you might need to consider, you know, if you're doing multi-line

00:07:49.300 --> 00:07:50.880
types of Python

00:07:50.880 --> 00:07:53.120
things, you might need a lock statement.

00:07:55.120 --> 00:07:55.640
we'll

00:07:55.640 --> 00:07:56.680
see what shakes out

00:07:56.880 --> 00:08:10.240
we also really like Python to be super easy for people to come on board people are building web scrapers in 10 lines of code or something and we don't want to get rid of that easiness

00:08:12.080 --> 00:08:19.840
yeah I totally 100% agree with that I do think that the complexity lies down in the libraries less than in your application

00:08:21.240 --> 00:08:22.280
because in your application

00:08:22.280 --> 00:08:25.660
you can decide I'm not doing threading, so problem solved.

00:08:26.040 --> 00:08:37.000
But as a library developer, you can't necessarily decide, not without just saying it doesn't work, you can't decide whether your library is being used in a multi-thread situation.

00:08:37.219 --> 00:08:37.820
So I think the

00:08:37.820 --> 00:08:42.140
simple use case of throwing together a script there.

00:08:42.400 --> 00:08:42.560
Yeah,

00:08:43.210 --> 00:08:43.320
yeah.

00:08:44.480 --> 00:08:48.420
Kashawn out there says, do we need to use locks in Python now, the three-threaded version?

00:08:49.220 --> 00:08:53.420
I think yes, maybe, but only if you're doing a multi-threaded code.

00:08:54.080 --> 00:08:54.200
Right.

00:08:55.580 --> 00:09:03.020
But you might need that anyway before because of the multi-line consistencies, right?

00:09:03.100 --> 00:09:04.420
Even though every line might run

00:09:04.420 --> 00:09:05.880
on

00:09:05.880 --> 00:09:09.900
its own, like this block of five, you're not guaranteed that it's going to run as a block.

00:09:10.100 --> 00:09:18.460
Anyway, way more details than we necessarily need to go into, but it's going to be interesting, and I imagine these conversations are coming back with this being the default thing.

00:09:18.700 --> 00:09:22.580
And if you want to try it out, uv makes it super simple.

00:09:23.360 --> 00:09:25.500
UV, create a virtual environment with like Python.

00:09:26.040 --> 00:09:30.820
Just say, I think probably 3.13.5T would do it, although I haven't tried.

00:09:32.300 --> 00:09:32.580
Have not

00:09:32.580 --> 00:09:32.760
tried.

00:09:32.860 --> 00:09:36.860
Well, yeah, but basically, definitely 3.14T, hopefully.

00:09:37.280 --> 00:09:39.700
Yeah, clearly we should have tried this before.

00:09:39.900 --> 00:09:41.700
So we'll get back to you on that one.

00:09:42.080 --> 00:09:42.260
Yeah,

00:09:42.500 --> 00:09:42.700
exactly.

00:09:42.820 --> 00:09:43.680
We'll figure it out.

00:09:43.780 --> 00:09:44.300
We'll figure it out.

00:09:45.120 --> 00:09:46.600
Speaking of figuring out, what am I going to figure out here?

00:09:46.780 --> 00:09:53.860
So let's talk about – actually, I have one other sort of async and threaded thing to talk about later.

00:09:54.340 --> 00:09:55.300
Let's talk about that first.

00:09:55.940 --> 00:09:57.080
Let's change the order here.

00:09:57.110 --> 00:09:57.400
Look at that.

00:09:57.410 --> 00:09:57.520
Boom.

00:09:57.660 --> 00:09:58.240
We can do it live.

00:09:58.620 --> 00:10:01.200
So I want to talk about PyLeak, P

00:10:01.200 --> 00:10:01.820
-Y-L

00:10:01.820 --> 00:10:04.540
-E-A-K, for like a memory leak.

00:10:05.220 --> 00:10:12.040
But instead of checking for memory leaks, what it looks for is async I.O. tasks, threads, and event loop leaks.

00:10:13.300 --> 00:10:13.700
Okay.

00:10:13.760 --> 00:10:14.220
So

00:10:14.220 --> 00:10:34.680
if I run, if I call a function that's asynchronous, and I think it is synchronous, but I call it without assigning it to a variable or awaiting or anything like that, that just creates the coroutine, and the unexecuted coroutine just chills there until it gets cleaned up, and it doesn't actually run that operation, right?

00:10:37.020 --> 00:10:37.700
Not good.

00:10:38.000 --> 00:10:39.200
So that's what this library is about.

00:10:39.500 --> 00:10:41.740
It's about detecting those types of things.

00:10:41.820 --> 00:10:43.920
So let's go look at some examples.

00:10:45.600 --> 00:10:49.240
So you can do context managers.

00:10:49.390 --> 00:10:52.400
You can say async with no task leaks.

00:10:53.280 --> 00:11:12.840
And then if you somewhere within the execution of that context block, if you do that and you somehow call an async function, but you don't await it, like for example here, they say async io.createTask given a sleep, That will come up as an error.

00:11:12.960 --> 00:11:14.680
It can either be a warning or an exception.

00:11:14.900 --> 00:11:18.300
If you want it to break the build in a test, you can say treat as errors.

00:11:19.960 --> 00:11:23.880
And it'll say, look, you called this function and you didn't wait for it.

00:11:24.739 --> 00:11:25.139
And

00:11:25.139 --> 00:11:30.000
tying this back to what you were just talking about, Brian, you can say with no thread leaks.

00:11:31.480 --> 00:11:43.580
And if you create a thread and start it, but you don't hang on to it as a variable, then it'll tell you, like, hey, you're no longer in control of this thread.

00:11:44.320 --> 00:11:47.000
This could be a problem, right?

00:11:47.720 --> 00:11:54.120
So basically, I imagine it's probably the thread kept running on the other side of that context manager.

00:11:54.290 --> 00:11:55.000
I'm not entirely sure.

00:11:55.440 --> 00:11:58.040
You can also do that for event loop blocking, right?

00:11:59.870 --> 00:12:02.680
And the event loop is the asyncio event loop, right?

00:12:02.760 --> 00:12:03.800
So this

00:12:03.800 --> 00:12:04.940
one's actually really interesting.

00:12:06.000 --> 00:12:14.520
if you're doing blocking work in an asyncio event loop, that itself should be asyncio aware, right?

00:12:14.820 --> 00:12:26.300
If I'm calling an HTTP endpoint for some kind of external service, I should probably be using HTTPX's async client, not

00:12:26.300 --> 00:12:28.800
request get, which means

00:12:28.800 --> 00:12:37.700
basically it says like I'm doing an IO thing, but it's blocking because I'm not using the AIO native version of it, right?

00:12:38.620 --> 00:12:51.980
And so the example here is like if you call time.sleep when you're checking for no blocking, that's an error because you should be using AIO.sleep, which you await and allows other work to happen at the same time, right?

00:12:52.660 --> 00:13:03.160
So basically it clogs up the entire AIO processing across all of the multi-concurrent contexts.

00:13:03.380 --> 00:13:07.560
They're not threads, but the stuff that can run side by side, it blocks it.

00:13:07.560 --> 00:13:08.660
So this will detect that.

00:13:10.580 --> 00:13:11.160
That's really cool.

00:13:11.700 --> 00:13:12.780
Yeah, this is a really neat library.

00:13:12.940 --> 00:13:13.660
There's a bunch more stuff.

00:13:13.690 --> 00:13:14.900
You can do this as decorators.

00:13:15.580 --> 00:13:17.300
You can get detailed stack traces.

00:13:17.680 --> 00:13:21.940
It'll show you details about what has happened here.

00:13:22.960 --> 00:13:32.660
There's a leak task called task 2 on line 9 of this example, and it shows you the code of what happened and so on.

00:13:33.560 --> 00:13:35.880
Yeah, lots of different things going on here.

00:13:35.880 --> 00:13:37.900
I don't want to go into too much detail.

00:13:38.120 --> 00:13:42.100
I've kind of gone on and on about it, but it's not just a single thing.

00:13:42.280 --> 00:13:44.400
This is a pretty comprehensive library, and I like it.

00:13:44.470 --> 00:13:45.060
I like it a lot.

00:13:46.640 --> 00:13:55.760
I reached out to the rough folks and said it would be really great if you could detect when there's an async function that's called that wasn't awaited.

00:13:56.480 --> 00:13:58.100
And they said, that really sounds great.

00:13:59.000 --> 00:14:01.820
We have or are considering it, but it's really hard to do.

00:14:02.960 --> 00:14:11.480
And so maybe you could just throw this in here as one more thing and set the error version and then run pytest and see what happens.

00:14:12.440 --> 00:14:15.760
Yeah, so I'm just curious how you would use this.

00:14:16.280 --> 00:14:32.140
I would expect, especially as you're building up an application, especially if it's maybe all the time, but maybe your first time doing an async application just to make sure that you're doing things right, putting some of these around, decorators around some of your methods within your code.

00:14:34.360 --> 00:14:40.380
Once you have things production ready, would you take this stuff out or would you leave it in place just to...

00:14:40.460 --> 00:14:44.120
I think I might put it in a unit test but take it out of production.

00:14:44.880 --> 00:14:45.260
Okay.

00:14:46.060 --> 00:14:46.940
That's probably what I would do.

00:14:47.480 --> 00:15:00.860
You know, the area where this really helps is it's helpful when you're creating a new project, but when you're creating a new project, you're in the mindset of, I'm going to call a function, oh, it's async, and you're actively working on that code, unless you're vibe coding, then all bets are off.

00:15:01.000 --> 00:15:08.980
But if you're legitimately working on it, then you're like in the flow, and your editor ideally gives you a little warning about those kinds of things.

00:15:09.480 --> 00:15:16.400
However, what this really helps is if you're converting from a synchronous situation to an async one.

00:15:16.860 --> 00:15:17.000
Like,

00:15:17.060 --> 00:15:17.520
for example,

00:15:17.620 --> 00:15:44.940
when I converted the Talk Python code from synchronous pyramid to async court, which is basically async flask, there was a few places I messed up because there's so much code and all these functions are called and you look at the code and it looks fine, but if you convert that function from sync to async but you forget to find every place you're using it and add in a wait, then that's when this happens.

00:15:45.420 --> 00:15:49.960
So does it work

00:15:49.960 --> 00:15:50.440
anyway?

00:15:50.610 --> 00:15:52.440
It's just slower or what happens?

00:15:53.820 --> 00:16:04.300
So for the thread one, it may work anyway, but like the async one, the async task one, maybe not.

00:16:04.640 --> 00:16:06.800
Because if you don't await it, it doesn't actually execute.

00:16:07.960 --> 00:16:08.140
Right?

00:16:08.180 --> 00:16:12.520
You create the co-routine, but then it's the awaiting of it that actually makes it go.

00:16:13.800 --> 00:16:20.580
And so if you said like log this message asynchronously, but you don't await it, it's never going to log it.

00:16:21.640 --> 00:16:21.880
Right?

00:16:22.700 --> 00:16:25.120
Maybe if you call create task, it might start.

00:16:25.140 --> 00:16:25.380
I don't know.

00:16:25.540 --> 00:16:27.260
There's like some different ways in which it could be done.

00:16:27.820 --> 00:16:29.840
No, but this is great to have some.

00:16:30.000 --> 00:16:36.960
I feel like this is like, what, scaffolding or training wheels or something to put on stuff just to make sure that things are running right.

00:16:37.620 --> 00:16:38.020
This is good.

00:16:38.720 --> 00:16:40.180
Yeah, it's definitely, definitely good.

00:16:40.920 --> 00:16:41.020
Cool.

00:16:42.320 --> 00:16:42.840
What else is good?

00:16:43.520 --> 00:16:44.960
Authentication that you don't have to deal with is good.

00:16:45.600 --> 00:16:46.520
Yes, it is.

00:16:47.020 --> 00:16:50.280
So on that note, we want to thank Propel Off.

00:16:50.560 --> 00:16:52.880
So this episode is sponsored by PropelOth.

00:16:53.220 --> 00:16:57.580
PropelOth is the easiest way to turn authentication into your advantage.

00:16:58.260 --> 00:17:03.720
For B2B SaaS companies, great authentication is non-negotiable, but it can often be a hassle.

00:17:04.380 --> 00:17:07.660
With PropelOth, it's more than just functional, it's powerful.

00:17:08.360 --> 00:17:16.240
PropelOth comes with tools like managed UIs, enterprise SSO, robust user management features, and actionable insights.

00:17:16.939 --> 00:17:23.060
As your product grows, PropelAuth adapts with it, supporting more advanced authentication features.

00:17:23.699 --> 00:17:24.220
And the best part?

00:17:25.600 --> 00:17:31.260
PropelAuth has native support for major Python libraries like FastAPI, Flask, and Django.

00:17:31.820 --> 00:17:34.020
You can easily integrate them into your product.

00:17:35.440 --> 00:17:39.740
When auth is effortless, your team can focus on scaling, not troubleshooting.

00:17:40.320 --> 00:17:44.180
That means more releases, happier customers, and more growth for your business.

00:17:44.760 --> 00:17:46.520
Check them out to get started today.

00:17:46.900 --> 00:17:48.900
The link is in your podcast player show notes.

00:17:49.460 --> 00:17:56.940
It's a clickable chapter URL as you're hearing this segment, and it's at the top of the episode page at pythonbytes.fm.

00:17:57.400 --> 00:18:00.140
Thank you to PropelAuth for supporting Python Bytes.

00:18:01.840 --> 00:18:03.880
Yes, indeed. Thanks, PropelAuth.

00:18:04.240 --> 00:18:09.120
And I would like to point out, Brian, that all of the chapters are clickable.

00:18:09.560 --> 00:18:14.200
So I don't know if everyone even knows that most of our episodes have chapters.

00:18:14.760 --> 00:18:18.500
If they don't, that's usually because I forgot somehow, which is not the case.

00:18:18.870 --> 00:18:24.120
But every item on there for the chapters is also a link to the main resource of whatever.

00:18:24.360 --> 00:18:28.920
Like, for example, the PyLeak one will link to the PyLeak GitHub repo if you click it.

00:18:29.620 --> 00:18:39.320
And I don't like people to skip on us, but I mean, I understand if we're talking about a topic that you really don't care about, that's one of the cool things about the chapter markers.

00:18:39.430 --> 00:18:42.080
You can just skip to the next topic or something.

00:18:42.700 --> 00:18:45.860
Yeah, or if you've heard it four times, you're like, yeah, this is the seventh time I've heard about this

00:18:45.860 --> 00:18:46.140
library.

00:18:46.430 --> 00:18:47.440
Like, you can skip it if you want.

00:18:47.570 --> 00:18:48.280
I mean, the show is pretty

00:18:48.280 --> 00:18:48.780
short, so.

00:18:50.000 --> 00:18:50.280
But still.

00:18:51.980 --> 00:18:53.000
Nonetheless, nonetheless.

00:18:53.240 --> 00:19:01.280
All right, let's talk about the thing that I was going to talk about first, but kicked it down the line, which is typed FFmpeg.

00:19:02.380 --> 00:19:02.600
Okay.

00:19:02.740 --> 00:19:11.060
So, I don't know if folks know, but FFmpeg is a command line CLI video processing masterpiece.

00:19:11.100 --> 00:19:13.340
It is a beast of a library.

00:19:14.800 --> 00:19:25.100
And it's actually what I use for the Talk Python training courses to generate all these different versions and resolutions and streaming styles and stuff.

00:19:25.300 --> 00:19:38.000
And, you know, if we had, let's say, a five-hour course, it would probably turn FFmpeg loose on the videos for, I don't know, 15, 20 hours, something like that, and just let it grind

00:19:38.000 --> 00:19:39.360
on my Apple Silicon.

00:19:40.040 --> 00:19:42.580
and I've got a whole bunch of automation to make that happen, which is cool.

00:19:44.140 --> 00:19:46.340
It would be easier if this existed, probably.

00:19:47.440 --> 00:19:55.840
So this typed FFmpeg is a Python wrapper that supports working with filters and typing for FFmpeg.

00:19:56.500 --> 00:19:57.680
So pretty neat.

00:19:58.420 --> 00:20:00.260
And it's kind of like PyLeak.

00:20:00.260 --> 00:20:02.540
It's more comprehensive than you would imagine.

00:20:03.100 --> 00:20:11.180
So this one offers a modern Pythonic interface to FFmpeg, providing extensive support for complex filters with pictures.

00:20:12.560 --> 00:20:25.840
It's inspired by FFmpeg-Python, but this one enhances that functionality with autocomplete, comprehensive type information, JSON serialization, and so on.

00:20:27.000 --> 00:20:33.680
So if you look at the repo they show you, if you type FFmpeg.input.

00:20:34.760 --> 00:20:41.220
and then down comes a huge list of things with stunning documentation and type information.

00:20:41.420 --> 00:20:42.160
I mean, look at that, Brian.

00:20:42.320 --> 00:20:44.000
That's pretty nice there, right?

00:20:44.360 --> 00:20:45.460
Yeah, it really is.

00:20:45.900 --> 00:20:47.060
Yeah, I was really surprised.

00:20:47.300 --> 00:20:53.200
So it comes with zero dependencies, comprehensive filter support, robust typing.

00:20:53.740 --> 00:20:54.900
You know, that's the point of it basically.

00:20:56.460 --> 00:21:03.940
Graph visualization, which I was talking about, hinting at, partial evaluation, media file analysis, and a bunch of things.

00:21:04.180 --> 00:21:05.600
So easy to use.

00:21:05.800 --> 00:21:16.580
It shows you how you can, you know, if you wanted to flip a video horizontally and then output it, you can see a little graph of input, and then it applies all the operations.

00:21:16.800 --> 00:21:20.660
There's an H flip operation in the graph, and then there's an output to the file.

00:21:21.700 --> 00:21:22.460
You get it more.

00:21:22.460 --> 00:21:23.200
I like the pictures.

00:21:24.000 --> 00:21:29.240
I know this is like you get even an interactive playground where you can drag and drop the filter bits together.

00:21:29.980 --> 00:21:30.300
What?

00:21:30.680 --> 00:21:31.160
I know.

00:21:31.680 --> 00:21:33.340
I'm telling you, it's way more than you would expect.

00:21:34.520 --> 00:21:36.980
So, yeah, really need to visualize what's happening.

00:21:37.320 --> 00:21:41.980
And, yeah, I don't do this kind of stuff where I'm, like, creating really complex graphs.

00:21:42.220 --> 00:21:46.300
It's more like format conversion, resolution conversion stuff that I use it for.

00:21:47.200 --> 00:21:50.920
But, yeah, if you do a lot with FFMPEG and you do stuff with video, check this out.

00:21:51.960 --> 00:21:59.520
If you pay hundreds or thousands of dollars to cloud providers to, like, re-encode video for you, you definitely want to check this out.

00:22:00.380 --> 00:22:01.060
Oh, okay.

00:22:01.640 --> 00:22:03.320
It might be saving a lot of money.

00:22:03.360 --> 00:22:04.160
I used to use AWS.

00:22:04.920 --> 00:22:07.760
They've got some video processing API sort of thing.

00:22:08.680 --> 00:22:13.120
And eventually, it was Cecil Phillip, actually, that convinced me I should just do FFmpeg.

00:22:13.680 --> 00:22:16.340
Yeah, AWS is probably just calling FFmpeg in the background.

00:22:17.040 --> 00:22:19.100
I'm sure that they are, which is crazy, right?

00:22:21.320 --> 00:22:21.380
Yeah.

00:22:21.740 --> 00:22:23.920
I mean, it's a little bit faster if they do it, but you know what?

00:22:24.560 --> 00:22:26.140
I only do it once per course.

00:22:26.300 --> 00:22:26.940
It's not very often.

00:22:27.760 --> 00:22:34.320
Well, I guess if you're doing like all of your courses were like 15 hours, I get why you have to pay people to do that.

00:22:34.580 --> 00:22:35.520
But, you know, whatever.

00:22:35.840 --> 00:22:36.000
Yeah.

00:22:37.480 --> 00:22:37.600
Cool.

00:22:37.980 --> 00:22:38.100
Yep.

00:22:38.500 --> 00:22:38.560
Yeah.

00:22:38.960 --> 00:22:42.800
If you use good caching, then life is much easier.

00:22:43.030 --> 00:22:45.740
You can just rerun it if you add a new video to reencode the whole thing.

00:22:46.420 --> 00:22:47.080
I love cache.

00:22:47.360 --> 00:22:47.680
I don't know.

00:22:47.680 --> 00:22:48.000
I do too.

00:22:48.840 --> 00:22:49.180
Over to you.

00:22:50.180 --> 00:22:52.940
I was going to talk about – what am I going to talk about?

00:22:53.220 --> 00:22:55.520
I'm going to talk about pytest.

00:22:56.020 --> 00:22:57.640
I kind of like pytest, actually.

00:22:59.320 --> 00:23:00.100
You don't say.

00:23:00.799 --> 00:23:53.680
it's a fun article by tim kamen and this is short so i almost put it as a second like a an extra but it's just really cool um so it's a his article is optimizing test execution and it's running live server tests last with py test okay so this is about testing websites web you know using the live server fixture. And, and so if you're using that, we're using Playwright or Selenium, that's definitely, this is definitely for you. But also really, if you have the techniques in this are, are, are really cool for even if you're just having, if you have any other, like if you have a test suite, that's, there's some slow parts and it's slow because of some fixture that you're using, like some external resource or whatever, any test that uses that is a little slower.

00:23:54.400 --> 00:23:55.600
You can use the same technique.

00:23:55.920 --> 00:23:57.140
So I just want to preface that.

00:23:58.220 --> 00:24:01.840
So why run slow tests last?

00:24:02.180 --> 00:24:03.700
Why does he want to run them last?

00:24:04.240 --> 00:24:11.560
Well, for efficiency, you get faster feedback for unit tests that allows you to, faster feedback for the fast tests.

00:24:12.120 --> 00:24:13.460
I don't know why he puts unit tests.

00:24:13.540 --> 00:24:14.500
It could be any fast test.

00:24:15.320 --> 00:24:18.060
Allows you to catch and fix issues easier, faster.

00:24:18.140 --> 00:24:31.420
you're not waiting for them. Also, resource management keeps resources consumed by slow tests like database connections and external services and stuff not tied up through the whole test. So keeping those isolated

00:24:31.420 --> 00:24:31.680
to the

00:24:31.680 --> 00:24:31.880
end.

00:24:32.120 --> 00:24:44.020
Totally makes sense. So how do we do this? Well, he's talking about installing pytest Playwright, which also is a great plug-in to drive web tests using pytest.

00:24:45.240 --> 00:24:46.240
And pytest Django.

00:24:46.420 --> 00:24:49.800
So this application is running a Django app.

00:24:51.240 --> 00:24:54.900
And then using, so his tests are using Live Server.

00:24:54.980 --> 00:24:55.620
So what does he do?

00:24:56.679 --> 00:25:00.720
He's adding a new marker, an E2E marker for end-to-end.

00:25:01.480 --> 00:25:05.100
But he's not actually marking anything with that manually.

00:25:06.120 --> 00:26:04.880
He comes by and uses one of the pytest's lovely hook functions and this one is collect modify items and it's sort of an oddball so it's good it's good to have like some easy examples like that so what this does is it goes through all your tests and looks for all of them that are using the live server fixture and then it does a couple things he's adding the marker e to e so um and adding the end-to-end marker to all of the tests that use live server it really he was you could do live server marker you could do any marker name you want but why do we do that i'll get to that later um so he's adding the marker to the slower tests and then and then he's splitting them up and running the uh all the other tests first and then the live server test second and that's really kind of the trick about pytext collect modify items is the way to either you can bail on some tests or you can reorder them.

00:26:06.340 --> 00:26:08.120
And he's using the reorder.

00:26:08.400 --> 00:26:12.980
But since we're having to loop through all of them anyway, he's using that to add the marker.

00:26:13.720 --> 00:26:16.540
And then, so why do that?

00:26:16.740 --> 00:26:21.420
Well, he's got a little example with a slow one or fast one.

00:26:21.900 --> 00:26:26.960
But you can use that marker then and say, you know what, I'm debugging a unit test.

00:26:27.030 --> 00:26:28.720
I don't want the live service ones to run.

00:26:28.820 --> 00:26:31.580
So you can say, hey, don't run the end-to-end ones.

00:26:31.590 --> 00:26:34.900
You can say pytest-m, not E to E.

00:26:35.320 --> 00:26:38.320
And that will run all of your tests that are not using the live server.

00:26:38.640 --> 00:26:43.800
And that's a cool use of markers, automatically applying markers.

00:26:43.980 --> 00:26:44.520
It's a cool thing.

00:26:45.660 --> 00:26:54.080
And then also, for example, if you just want to run the live server ones, you can say E to E as well.

00:26:54.320 --> 00:27:03.660
So a really fun little example of how to automate pushing your slow test to the end and being able to select them or not select them.

00:27:03.990 --> 00:27:04.280
It's cool.

00:27:04.380 --> 00:27:05.700
I love this idea.

00:27:06.560 --> 00:27:08.280
I think I might adopt it.

00:27:10.500 --> 00:27:10.840
That's nice.

00:27:11.280 --> 00:27:19.260
Also, gentle introduction to hook functions because hook functions can be a little scary in something simple like reordering your tests.

00:27:20.210 --> 00:27:24.020
It doesn't seem like it would be simple, but it's only, what, 13 lines of code?

00:27:24.160 --> 00:27:26.020
including a comment, some blank ones.

00:27:26.240 --> 00:27:26.680
It's not bad.

00:27:27.360 --> 00:27:28.600
Yeah, that's not too bad at all.

00:27:29.200 --> 00:27:29.300
Okay.

00:27:29.680 --> 00:27:38.080
Yeah, I'm definitely going to look at this because I've got some tests that are blazing fast and some that are pretty slow for the various web apps I got.

00:27:38.260 --> 00:27:39.500
So I'll check it out.

00:27:40.440 --> 00:27:51.320
I don't use live server or any of those things, but it's like I want to get the sitemap and then call a representative subset of things within there just to make sure it's all hanging together.

00:27:51.500 --> 00:27:52.780
That's definitely an E to E test.

00:27:53.300 --> 00:28:08.340
Well, and also, like, so I see a lot of cases if somebody's using a database connection, they'll have, like, or, you know, using a database to, even if it's just a mock database or a small one, but they've got a whole bunch of test data that they've filled in.

00:28:08.940 --> 00:28:12.360
And maybe it's not really slow, but it's, you know, it's slower than their other stuff.

00:28:13.360 --> 00:28:19.400
It's often accessed via a fixture, and you can easily select the tests that use that fixture.

00:28:19.720 --> 00:28:20.160
It's pretty cool.

00:28:20.800 --> 00:28:30.420
The other thing I brought this up by because is I want to make sure everybody, I mean, yes, I write about pytest a lot, but I like other people to write about it too.

00:28:30.700 --> 00:28:37.120
So please, if you've written some cool pytest documentation, send them to me.

00:28:39.399 --> 00:28:39.840
Indeed.

00:28:40.330 --> 00:28:40.740
Looks good.

00:28:41.200 --> 00:28:41.600
All right.

00:28:41.640 --> 00:28:43.000
Let's jump over to some extras.

00:28:43.980 --> 00:28:44.420
All right.

00:28:45.120 --> 00:28:50.860
We have a new course at Talk Python Training, And this is the very first announcement for it.

00:28:51.020 --> 00:28:51.720
I haven't even got

00:28:51.720 --> 00:29:02.120
a chance to send out email about this, but Vincent Bormerdom, who's been on Python Bytes before, created a short LLM building blocks for Python course.

00:29:02.760 --> 00:29:06.060
And so this isn't like prompt engineering or anything like that.

00:29:06.240 --> 00:29:13.620
It's like, what are some good libraries you can use to build code that uses LLMs for various things?

00:29:13.780 --> 00:29:14.860
How do you get structured output?

00:29:15.140 --> 00:29:23.280
Like, for example, how can you use Pydantic to communicate to the LLM how it should speak to you in a JSON response instead of a text response?

00:29:24.220 --> 00:29:24.440
Stuff

00:29:24.440 --> 00:29:24.800
like that.

00:29:25.500 --> 00:29:26.020
Yeah, super

00:29:26.020 --> 00:29:26.220
neat.

00:29:26.390 --> 00:29:27.820
So check the course out.

00:29:27.980 --> 00:29:30.400
It's just $19 over at Talk Python Training.

00:29:30.580 --> 00:29:33.200
Just go to Courses or go to talkpython.fm.

00:29:33.360 --> 00:29:33.900
Click on Courses.

00:29:34.050 --> 00:29:36.140
It'll be right there at the top of the new courses list.

00:29:36.270 --> 00:29:36.920
So check that out.

00:29:37.060 --> 00:29:38.080
That's super exciting.

00:29:38.840 --> 00:29:47.220
Also, over at Talk Python, I've done this thing called deep dives where it goes into a particular episode.

00:29:48.460 --> 00:29:49.320
And you can look at it.

00:29:49.400 --> 00:30:05.120
It'll tell you, like, background on the guests, background on important concepts you might want to learn to, like, get a better sense of understanding what's going on or, you know, diving extra details into each of the things we've spoken about and so on.

00:30:05.620 --> 00:30:14.780
So the news is I have finished a long journey of getting one of those deep dive analysis for every Talk Python episode for the last 10 years.

00:30:15.170 --> 00:30:19.100
And the result is 600,000 words of analysis.

00:30:19.290 --> 00:30:22.200
If you were to go through and read them all, it's 4.5 million characters.

00:30:24.200 --> 00:30:24.320
Wow.

00:30:24.480 --> 00:30:25.420
That's a lot of content.

00:30:25.920 --> 00:30:42.580
But that makes the search over there better because if you search, that now includes basically the search engine considers the deep dive as part of the episode and looks for content within there, not just within what I put in the show notes and so on.

00:30:43.680 --> 00:30:44.580
So really, really cool.

00:30:45.040 --> 00:30:45.640
Super proud of that.

00:30:46.100 --> 00:30:48.560
That was a lot of work, but it is now done.

00:30:49.000 --> 00:30:53.620
So I wrote a little article about that, and I'll link to it if you're more interested than what I just said.

00:30:54.360 --> 00:30:54.600
Nice.

00:30:55.300 --> 00:30:57.160
Also, remember I had a rant.

00:30:57.160 --> 00:31:02.220
I even named last week's episode, stop putting your dot folders in my tilde dash or tilde slash

00:31:02.220 --> 00:31:02.780
or

00:31:02.780 --> 00:31:03.000
whatever.

00:31:03.920 --> 00:31:11.180
Well, Eric Mesa said, hey, the places to store dot files is defined by the XDG standard on Linux.

00:31:11.500 --> 00:31:17.500
Because remember, I was whinging about doing this to my macOS setup.

00:31:18.800 --> 00:31:22.540
And Windows is even worse because the dot files and folders are not even hidden.

00:31:24.180 --> 00:31:25.660
But what about Linux?

00:31:25.920 --> 00:31:29.920
Well, this XDD standard speaks to that.

00:31:30.640 --> 00:31:35.060
And so I even did a little, put together a little cheat sheet on it or whatever.

00:31:36.500 --> 00:31:39.640
So put stuff in your, you know, where do the config files go?

00:31:39.720 --> 00:31:45.100
Well, they go in home slash, you know, like tilde, whatever your dollar home is, right?

00:31:45.160 --> 00:31:47.540
Basically tilde slash dot config.

00:31:47.840 --> 00:31:50.920
So maybe dot config slash my app, some settings.

00:31:54.240 --> 00:31:57.760
there's a cache folder, and then you put it in the.cache in there.

00:31:58.200 --> 00:32:06.060
There's still a few.folders in your repo, but not one for every single application you happen to have run or something has run for you.

00:32:07.040 --> 00:32:08.900
So this is kind of cool, and people can check it out.

00:32:09.140 --> 00:32:19.280
There's a lot of details I've put together here, and even a way to use this XDG library, which is right here somewhere, in Python, how to use it.

00:32:20.700 --> 00:32:22.660
Or actually just a function you can use, but pretty cool.

00:32:23.960 --> 00:32:28.400
that's pretty cool yeah any idea what XDG stands for?

00:32:30.380 --> 00:32:34.520
zero I have

00:32:34.520 --> 00:32:35.080
zero idea

00:32:35.720 --> 00:32:36.680
okay that's

00:32:36.680 --> 00:32:39.340
fine we'll look it up for

00:32:39.340 --> 00:32:40.040
next time I did look it

00:32:40.040 --> 00:32:44.760
up as part of putting that little cheat sheet thing together but then it was last week and I forgot

00:32:45.860 --> 00:32:50.640
yeah that's me okay is that your extras?

00:32:51.620 --> 00:32:52.340
No, I got a couple more.

00:32:52.580 --> 00:32:52.900
I'll go quick.

00:32:53.010 --> 00:32:53.100
Okay.

00:32:54.000 --> 00:32:55.840
Every time I think, you know, are you a fan of Scarface?

00:32:56.020 --> 00:32:56.900
Do you watch that when you're younger?

00:32:58.260 --> 00:32:59.040
No, this is a godfather.

00:32:59.240 --> 00:32:59.900
Sorry, this is a godfather.

00:32:59.970 --> 00:33:00.040
This is a godfather.

00:33:00.040 --> 00:33:00.520
I'm the only people I'd ever have.

00:33:01.780 --> 00:33:02.800
This is a godfather, actually.

00:33:03.420 --> 00:33:04.940
This is Al Pacino, though, so that's why I thought.

00:33:05.120 --> 00:33:05.720
Same actor.

00:33:06.260 --> 00:33:09.120
Every time I think I'm out, they pull me right back in, right?

00:33:09.820 --> 00:33:12.640
Well, that's me and the pro version of OpenAI.

00:33:12.790 --> 00:33:16.240
I thought, like, okay, I'm just going to go back to being a regular, normal user of this thing.

00:33:16.340 --> 00:33:17.800
And then, no, they go and release 03 Pro.

00:33:17.960 --> 00:33:24.760
So I'm like, I have to pay the ridiculous money to try that out again because it's really worth it.

00:33:24.920 --> 00:33:27.360
Although I will say, I'll take one for the team here.

00:33:27.420 --> 00:33:32.360
I will say O1 Pro was incredible, and it's starting to be phased out.

00:33:32.540 --> 00:33:33.880
I don't know how much longer it will last.

00:33:34.480 --> 00:33:39.040
O3 Pro does not seem nearly as good to me, not even close.

00:33:39.700 --> 00:33:40.320
I don't know why.

00:33:41.860 --> 00:33:42.560
O3 is pretty good.

00:33:43.220 --> 00:33:46.460
So maybe I'm considering going back to a regular user again.

00:33:46.700 --> 00:33:49.400
But every time I'm out, Brian, they pull me right back in.

00:33:51.600 --> 00:33:51.820
Okay.

00:33:53.260 --> 00:33:55.660
Another one, this is dynamic.

00:33:55.780 --> 00:33:56.940
When I wrote it down, it was 17.

00:33:57.120 --> 00:33:57.820
Right now it's 20.

00:33:58.280 --> 00:34:03.580
But Python Bytes is the 20th most popular tech news podcast in the world.

00:34:04.920 --> 00:34:06.060
According to good pods.

00:34:06.280 --> 00:34:06.400
Okay.

00:34:06.640 --> 00:34:09.060
According to good pods, which is decent.

00:34:10.880 --> 00:34:15.100
And number one developer news show period.

00:34:15.179 --> 00:34:15.679
How about that?

00:34:16.060 --> 00:34:21.620
specifically developer, not like also covers just tech or AI or whatever.

00:34:22.320 --> 00:34:22.740
That's pretty cool.

00:34:22.840 --> 00:34:24.659
So thanks, GoodPods, for pointing that out.

00:34:25.000 --> 00:34:28.940
I used to use Chartable, but then Spotify bought them and shut them down.

00:34:29.360 --> 00:34:29.879
Thanks, Spotify.

00:34:31.399 --> 00:34:32.080
I think it was Spotify.

00:34:32.260 --> 00:34:32.700
I'm pretty sure.

00:34:32.780 --> 00:34:34.139
They were definitely bought and shut down.

00:34:35.700 --> 00:34:35.840
Okay.

00:34:36.320 --> 00:34:44.259
I want you, anyone out there listening, do not take action on this item until you hear the second follow-up item in this extra because it's important.

00:34:45.179 --> 00:34:49.580
On June 3rd, Python 3.13.4 was released.

00:34:49.800 --> 00:34:51.820
Hey, right, this is cool.

00:34:52.700 --> 00:35:04.660
Covered some CVEs that had to be fixed, so we quickly got things like tarball security issues that could be really bad if you process tarballs from external input.

00:35:05.860 --> 00:35:07.300
So you might think, I want to go install that.

00:35:07.620 --> 00:35:08.100
No, no, no.

00:35:08.820 --> 00:35:19.240
Just a few days later, hey, 3.13.5 is out because we had to quickly release this to fix an issue that was in 3.13.4.

00:35:20.120 --> 00:35:20.560
Okay.

00:35:20.810 --> 00:35:33.400
So make sure you get 3.13.5 if you have either 3.13.3 or 4 because 4 doesn't actually, I don't know what the actual issue was, but this one is like, oh, my gosh, we've got to fix it again.

00:35:34.820 --> 00:35:35.620
That's it. Those are my extras.

00:35:36.360 --> 00:35:39.960
All right. I only have a couple, but let's pop over.

00:35:41.300 --> 00:35:52.300
So along the free threading topic, this was mentioned by what John Hagen sent this in.

00:35:52.880 --> 00:35:58.440
And this is from the python.org discussion thread.

00:35:59.160 --> 00:36:05.720
There's a discussion thread called is free threading our only option?

00:36:06.260 --> 00:36:32.540
this is from Eric snow whose um opinion i at least want to listen to so there's a um interesting discussion about really about whether or not free threading is the only way to go and he does uh mention he's not recommending to not support free free threading but there's other things to think about so i'm just going to drop this link it's a uh kind of a long uh discussion so but it's an interesting read.

00:36:33.060 --> 00:36:33.460
Yeah,

00:36:33.560 --> 00:36:33.940
it's also

00:36:34.120 --> 00:36:38.280
noteworthy that Eric Snow did a ton of the work on sub-interpreters.

00:36:39.560 --> 00:36:39.800
Yeah.

00:36:40.280 --> 00:36:43.800
So there's, and that's part of it, is talking around sub-interpreters.

00:36:44.160 --> 00:37:05.000
And some of the interesting discussions here, like one of the things popped down that I thought from Antoine Petrou, and he's the maintainer pi arrow, says, just as a data point, our library supports free-threaded Python, but I've not even looked at sub-interpreters.

00:37:06.880 --> 00:37:18.400
And I kind of, I know that it's going to be complicated to, or at least it might be complicated to think about free-threading, but thinking about sub-interpreters blows my brain up.

00:37:18.720 --> 00:37:20.880
So I'm not thinking about them at all.

00:37:21.460 --> 00:37:22.200
You could have

00:37:22.200 --> 00:37:24.700
each thread have its own sub-interpreter. How about that?

00:37:25.960 --> 00:37:28.140
Or multiple sub-interpreters. I don't know.

00:37:29.180 --> 00:37:31.860
Or each sub-interpreters have its own multiple threads.

00:37:33.120 --> 00:37:33.320
Sure.

00:37:33.820 --> 00:37:35.620
Yeah, hence the brain blowing up.

00:37:36.200 --> 00:37:36.680
Yeah, anyway.

00:37:38.640 --> 00:37:40.240
And another free-threading topic.

00:37:41.840 --> 00:37:44.440
This is from Hugo von Kaminad.

00:37:45.180 --> 00:37:47.700
Free-threaded Python in GitHub Actions.

00:37:48.320 --> 00:37:50.960
This is just, he actually released this in March.

00:37:51.380 --> 00:37:55.080
But this is really how to make sure.

00:37:55.480 --> 00:38:05.680
So we're encouraging people now to make sure with 3.14 and at the very least with 3.14 to test free threading for their project.

00:38:05.800 --> 00:38:23.760
So if you have a third party, if you are a maintainer of a third party, basically if I can get your stuff via pip and it's got a library that I can use in other code, please test it for free threading and then tell people whether or not you're supporting free threading.

00:38:24.800 --> 00:38:28.520
And this discussion is how to do that within GitHub Actions.

00:38:28.840 --> 00:38:32.980
So a really great write-up on how, and it's basically just add a T.

00:38:35.300 --> 00:38:35.820
It's not bad.

00:38:36.120 --> 00:38:37.800
So this isn't a lot of extra work.

00:38:39.720 --> 00:38:40.200
Indeed,

00:38:40.560 --> 00:38:41.500
not too much.

00:38:41.660 --> 00:38:43.320
All right, well, you're ready for a joke?

00:38:43.940 --> 00:38:44.040
Yes.

00:38:44.160 --> 00:38:44.540
Close it

00:38:44.540 --> 00:38:48.880
out with an idea.

00:38:49.140 --> 00:38:51.920
So naming things is hard, right?

00:38:52.100 --> 00:39:00.560
There's the famous joke, which will introduce this joke, is that there's two things in computer science that are hard.

00:39:00.980 --> 00:39:03.980
Naming things, cache and validation, and off by one errors, right?

00:39:04.400 --> 00:39:04.540
Yeah.

00:39:04.900 --> 00:39:07.600
So this one comes from Programming Humor, and it's a bit of a meme.

00:39:07.670 --> 00:39:13.760
It has two senior devs just like fighting, like, you know, literally wrestling, fighting away.

00:39:14.340 --> 00:39:15.480
It says here's a code review meeting.

00:39:16.000 --> 00:39:22.660
The variable name should be number to be updated, says one of the senior devs while she's throwing down the other senior dev.

00:39:23.020 --> 00:39:24.820
The variable name should be updated number.

00:39:25.740 --> 00:39:29.120
Meanwhile, the junior dev is sitting there eating popcorn, watching it go down.

00:39:30.500 --> 00:39:34.840
While working on a new file with variable names such as AA1 and XYZ.

00:39:38.940 --> 00:39:39.080
Yeah.

00:39:40.240 --> 00:39:40.960
And I'm over here.

00:39:40.960 --> 00:39:41.320
Do you guys have

00:39:41.320 --> 00:39:41.540
naming?

00:39:41.970 --> 00:39:42.840
Do you have naming debates?

00:39:43.160 --> 00:39:43.620
Sorry, go ahead.

00:39:43.860 --> 00:39:44.140
You're over there.

00:39:44.320 --> 00:39:44.560
No,

00:39:44.670 --> 00:39:48.280
we use linters to do the argument for us.

00:39:49.180 --> 00:39:53.860
but I'm looking at this going it's a camel case it needs

00:39:53.860 --> 00:39:54.560
to be a

00:39:54.560 --> 00:39:55.680
snake case what's up with this?

00:39:55.880 --> 00:39:57.940
it's got to be like a javascript or a c-sharp

00:39:57.940 --> 00:39:58.320
argument

00:40:02.180 --> 00:40:02.900
we've got to get

00:40:02.900 --> 00:40:03.900
in there take them both down

00:40:05.500 --> 00:40:39.440
I'm one of the worst whenever I see style guides getting written I always cringe when there's a new style guide in a team but I always make sure to make sure that it complies it at least adds to and doesn't distract from actual common practice in the rest of the industry and the other thing is for the short variable names you have to allow things like xyz for and i and j for loop variables and stuff

00:40:39.440 --> 00:40:40.360
although I do agree

00:40:40.360 --> 00:40:46.660
that using both i and j is evil because some fonts you can't really tell much of a difference between the two

00:40:46.680 --> 00:40:49.960
Yeah, but like 4n in int,

00:40:50.120 --> 00:40:52.200
that's

00:40:52.200 --> 00:40:59.860
like steeped in historical math style outside of programming, right?

00:41:00.760 --> 00:41:00.960
Yeah.

00:41:01.500 --> 00:41:01.600
And

00:41:01.600 --> 00:41:02.500
X and Y

00:41:02.500 --> 00:41:03.700
for algebra, absolutely.

00:41:04.520 --> 00:41:10.820
And then I've had people gripe about using i as a variable for a loop.

00:41:11.300 --> 00:41:18.100
And I'm like, that's just so common is like for i in this, especially if it's not a nested loop.

00:41:18.380 --> 00:41:18.720
Why not?

00:41:19.360 --> 00:41:19.520
Yeah.

00:41:19.860 --> 00:41:22.280
Well, have you done any C++?

00:41:22.620 --> 00:41:22.840
Come on.

00:41:22.940 --> 00:41:24.100
That's like one of the first things you do.

00:41:24.220 --> 00:41:25.640
For nt i

00:41:25.640 --> 00:41:28.060
equals zero, i++,

00:41:28.360 --> 00:41:31.780
i less than n, you index into the array because that's how it goes.

00:41:32.220 --> 00:41:32.340
Yeah.

00:41:33.100 --> 00:41:33.200
Yeah.

00:41:34.280 --> 00:41:34.740
Anyway, well.

00:41:36.580 --> 00:41:37.460
So you don't invite

00:41:37.460 --> 00:41:42.020
me to your code review meeting because I'll be the grump in the background.

00:41:43.200 --> 00:41:43.600
Well,

00:41:43.780 --> 00:41:44.580
sometimes you do.

00:41:45.100 --> 00:41:46.100
Maybe you should.

00:41:48.320 --> 00:41:48.660
I know you

00:41:48.660 --> 00:41:48.860
don't

00:41:48.860 --> 00:41:50.200
like what they wrote, but they have a point.

00:41:51.080 --> 00:41:52.080
Let the I be.

00:41:52.380 --> 00:41:52.760
Let it be.

00:41:55.220 --> 00:41:55.720
All right.

00:41:55.780 --> 00:41:56.060
Well, thanks.

00:41:56.900 --> 00:41:59.340
Yeah, thank you as always, and thanks, everyone.

00:41:59.700 --> 00:42:00.020
Bye, y'all.

00:42:00.660 --> 00:42:00.780
Bye.

