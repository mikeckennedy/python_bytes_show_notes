WEBVTT

00:00:00.000 --> 00:00:07.680
Hey, everybody, welcome to our recording of the episode today.


00:00:07.680 --> 00:00:08.720
So Python Bytes.


00:00:08.720 --> 00:00:13.680
Hello and welcome to Python Bytes, where we deliver Python news and


00:00:13.680 --> 00:00:15.640
headlines directly to your earbuds.


00:00:15.640 --> 00:00:20.560
This is episode 235, recorded May 26, 2021.


00:00:20.560 --> 00:00:21.720
And I'm Brian Okken.


00:00:21.720 --> 00:00:23.080
I'm Michael Kennedy.


00:00:23.080 --> 00:00:25.280
And I'm Vincent Wormadam.


00:00:25.280 --> 00:00:27.200
Yeah.


00:00:27.220 --> 00:00:32.980
So we have a we talked about vincent a while ago and got his name wrong and he told us the story


00:00:32.980 --> 00:00:37.620
That was good. Uh that um that we accidentally pronounced his name


00:00:37.620 --> 00:00:39.140
uh


00:00:39.140 --> 00:00:41.140
What wanderman? Yes


00:00:41.140 --> 00:00:44.340
So, sorry about that. That's fine. It's fine


00:00:44.340 --> 00:00:49.220
I was bragging to my wife that I was on the podcast and then I was announced as vincent wanderman


00:00:49.220 --> 00:00:53.460
And she's still kind of philosophical about the whole thing, but it was a fun introduction. It's the best


00:00:54.260 --> 00:00:59.680
Best mispronunciation of my life. Let me put it that way. It's it's your alter ego. It's like your name


00:00:59.680 --> 00:01:08.680
Well, thanks for joining us today my pleasure should we jump into the first step topic sure


00:01:08.680 --> 00:01:12.280
Okay. Well, I think we covered we mentioned


00:01:12.280 --> 00:01:15.600
last time that flask 2.0 was out and


00:01:15.600 --> 00:01:20.140
And then Michael had done you had you talked with somebody didn't you?


00:01:21.800 --> 00:01:33.400
I did. I had David Lord and also Philip Jones on talk Python to basically announce flask 2.0 and talk about all their features.


00:01:33.400 --> 00:01:38.000
Yeah, and that was a great episode. I listened to both those.


00:01:38.000 --> 00:01:40.000
Listened to that, it was great.


00:01:40.000 --> 00:01:44.600
What I wanted to cover was a couple articles or an article and video.


00:01:44.600 --> 00:01:48.500
So first off, we've got a link to the change list.


00:01:48.500 --> 00:01:52.240
So if I actually lost the change list.


00:01:52.240 --> 00:01:53.640
Yeah, there it is.


00:01:53.640 --> 00:01:58.200
So you can read through that, and maybe that's exciting to you,


00:01:58.200 --> 00:02:00.380
but I like a couple other ways.


00:02:00.380 --> 00:02:05.180
So there's an article by Patrick Kennedy,


00:02:05.180 --> 00:02:07.240
Async and Flask 2.0.


00:02:07.240 --> 00:02:09.400
And I really like this article.


00:02:09.400 --> 00:02:15.600
It goes through kind of describing what it means to have Async in Flask


00:02:15.600 --> 00:02:18.180
and how it works with some nice little diagrams.


00:02:18.240 --> 00:02:21.280
- Diagrams are always nice.


00:02:21.280 --> 00:02:23.160
- Oh yeah, pictures.


00:02:23.160 --> 00:02:24.000
- Yes.


00:02:24.000 --> 00:02:28.040
- And then a description of the ASGI


00:02:28.040 --> 00:02:30.700
and why we don't need it yet.


00:02:30.700 --> 00:02:32.440
And I'm not sure,


00:02:32.440 --> 00:02:34.680
I'm not sure what the framework,


00:02:34.680 --> 00:02:37.720
the timeline is for Flask,


00:02:37.720 --> 00:02:38.720
if they're gonna do it more,


00:02:38.720 --> 00:02:40.080
but there is a discussion of that.


00:02:40.080 --> 00:02:42.000
It's not completely ASIC.


00:02:42.000 --> 00:02:45.840
- There was a lot of discussion with David and Phillip


00:02:45.840 --> 00:02:50.840
that they may be leaving court to take place full on.


00:02:50.840 --> 00:02:53.600
- Okay.


00:02:53.600 --> 00:02:55.480
- ASGI Flask.


00:02:55.480 --> 00:02:58.260
And the idea being that there's a lot of stuff


00:02:58.260 --> 00:02:59.560
that kind of has to change,


00:02:59.560 --> 00:03:00.940
especially around the extensions,


00:03:00.940 --> 00:03:03.500
and you get nearly that, but not exactly that,


00:03:03.500 --> 00:03:08.000
by using the gevent async stuff that's in regular Flask,


00:03:08.000 --> 00:03:09.900
and that integrates in,


00:03:09.900 --> 00:03:13.720
if you just do an async def method in your regular Flask.


00:03:13.720 --> 00:03:16.720
But if you want true asyncio integration,


00:03:16.720 --> 00:03:20.940
then they basically were saying for the foreseeable future,


00:03:20.940 --> 00:03:25.360
instead of import Flask and go in that,


00:03:25.360 --> 00:03:27.240
just import court and wherever you see Flask,


00:03:27.240 --> 00:03:29.040
replace it with the word court.


00:03:29.040 --> 00:03:29.880
- Okay.


00:03:29.880 --> 00:03:34.080
But there's other cool stuff other than the async


00:03:34.080 --> 00:03:35.880
that's coming into Flask 2.0.


00:03:35.880 --> 00:03:36.840
So I appreciate it.


00:03:36.840 --> 00:03:41.680
There's also a video from, we don't want it to play,


00:03:41.680 --> 00:03:43.080
from Miguel Grinberg,


00:03:43.080 --> 00:03:49.080
and talking about some of the new stuff in Flask.


00:03:49.080 --> 00:03:51.480
And I really like this.


00:03:51.480 --> 00:03:54.400
One of the things that he covers right away


00:03:54.400 --> 00:03:56.400
is the new route decorators.


00:03:56.400 --> 00:03:57.800
And-- - Yeah, those are nice.


00:03:57.800 --> 00:04:00.400
- Might be just a syntax thing, but it's really nice.


00:04:00.400 --> 00:04:02.720
So you used to have to say app route


00:04:02.720 --> 00:04:06.880
and then methods equals post or list the method.


00:04:06.880 --> 00:04:09.160
And now you can just say app post.


00:04:09.160 --> 00:04:10.280
That's nice.


00:04:10.280 --> 00:04:15.880
And then a really clean discussion of the WebSocket support with Flask.


00:04:15.880 --> 00:04:18.780
And then he goes in to talk about the async.


00:04:18.780 --> 00:04:22.080
And with that also does a little demo timing it.


00:04:22.080 --> 00:04:31.180
And I was actually surprised at how easy it was to set up this demo of timing


00:04:31.180 --> 00:04:35.480
and showing that he showed that you could increase the users


00:04:35.540 --> 00:04:42.660
And then still get, it doesn't really increase your response time or how many


00:04:42.660 --> 00:04:49.780
users per request per second doesn't increase because of the way that Flask 2.0 was done.


00:04:49.780 --> 00:04:55.380
But it was nice. And then he also talked about some of the extensions that he wrote too


00:04:55.380 --> 00:05:00.020
that work with Flask 2.0 and stuff. So it was definitely worth the listen.


00:05:00.020 --> 00:05:02.900
Oh, that's always cool. That's always the thing when you get like,


00:05:02.900 --> 00:05:05.700
Flask is like a pretty big project. So when there's like a new upgrade of that


00:05:05.700 --> 00:05:10.340
One of the things that people sometimes forget is like, oh like all the plugins do they kind of still work?


00:05:10.340 --> 00:05:13.540
So it's nice if someone does a little bit of the homework there and so says well


00:05:13.540 --> 00:05:15.800
Here's a list of stuff that i've checked and that's at least compatible


00:05:15.800 --> 00:05:21.460
well, he's mostly doing some so for instance, one of the things is around


00:05:21.460 --> 00:05:23.780
uh, which


00:05:23.780 --> 00:05:25.380
I don't know which um


00:05:25.380 --> 00:05:29.140
Yeah, just some of the web socket stuff has changed and some of the other things have changed


00:05:29.380 --> 00:05:33.860
And he has like some more, some different shims that he was recommending


00:05:33.860 --> 00:05:38.960
some things before, but now you don't have to swap out some things.


00:05:38.960 --> 00:05:42.560
So like, for instance, some of the extensions we're allowing for WebSockets


00:05:42.560 --> 00:05:46.800
required you to swap out the server for a different server,


00:05:46.800 --> 00:05:48.260
and you don't have to anymore.


00:05:48.260 --> 00:05:50.260
- So... - Ah, like that.


00:05:50.260 --> 00:05:51.260
Okay.


00:05:51.260 --> 00:05:54.760
Yeah, a couple of big other things that come to mind.


00:05:54.760 --> 00:05:59.060
One, they've dropped Python 2 support and even 3.5 and below.


00:05:59.060 --> 00:06:02.220
I mean, we're at this point where 3.5 is like old school legacy,


00:06:02.220 --> 00:06:04.220
which surprises me, that still feels new.


00:06:04.220 --> 00:06:06.460
Yeah, I remember when it came out.


00:06:06.460 --> 00:06:10.100
Yeah, yeah, well, that was when async and await arrived, right?


00:06:10.100 --> 00:06:12.100
That was the big deal there.


00:06:12.100 --> 00:06:14.100
But it doesn't have fstring, so it's...


00:06:14.100 --> 00:06:16.100
Yeah, that's the killer feature.


00:06:16.100 --> 00:06:18.100
Yeah.


00:06:18.100 --> 00:06:22.340
Yeah, so there's that, and they also said that you are not going to need to change


00:06:22.340 --> 00:06:26.260
your deployment infrastructure if you want to run async flask.


00:06:26.260 --> 00:06:29.860
you can just push a new version and it's good to go.


00:06:29.860 --> 00:06:31.660
So yeah, a lot of neat things there.


00:06:31.660 --> 00:06:32.740
It's very good.


00:06:32.740 --> 00:06:35.820
- Cool.


00:06:35.820 --> 00:06:36.980
Nice.


00:06:36.980 --> 00:06:38.780
What do we got next, Michael?


00:06:38.780 --> 00:06:42.140
- Well, what if Python were faster?


00:06:42.140 --> 00:06:43.300
That would be nice.


00:06:43.300 --> 00:06:44.140
- That's always good.


00:06:44.140 --> 00:06:45.580
- We actually talked about Sender.


00:06:45.580 --> 00:06:47.020
Do you remember Sender?


00:06:47.020 --> 00:06:48.260
- Yeah.


00:06:48.260 --> 00:06:51.220
- From the Facebook world.


00:06:51.220 --> 00:06:54.140
So that's one really interesting thing


00:06:54.140 --> 00:06:59.500
that is happening around Python. And there's a lot of cool stuff here, but remember, this is not


00:06:59.500 --> 00:07:07.100
supported. It's not meant to be a new runtime. It's just there to give ideas and motivation and


00:07:07.100 --> 00:07:14.780
examples and basically to run Instagram. On the other hand, Mike Driscoll tweeted out, "Hey,


00:07:14.780 --> 00:07:19.420
Python might get a two-time speed up of the next version of Python." And you might want to check


00:07:19.420 --> 00:07:25.180
out Guido's slides from the Python Language Summit at the Virtual PyCon. That's exciting,


00:07:25.180 --> 00:07:26.180
right?


00:07:26.180 --> 00:07:27.180
>> Yes.


00:07:27.180 --> 00:07:28.180
>> So, yeah.


00:07:28.180 --> 00:07:33.500
>> If Guido is saying it, then, you know, odds of it happening are right.


00:07:33.500 --> 00:07:39.860
>> Exactly. Exactly. So a while ago, we actually covered what has now become known as the Shannon


00:07:39.860 --> 00:07:47.820
plan for making Python faster a little bit each time over five years, over the next four,


00:07:47.820 --> 00:07:50.380
at least, I guess, four years at that point,


00:07:50.380 --> 00:07:51.780
and how to make that happen.


00:07:51.780 --> 00:07:55.340
So some of these ideas come from there.


00:07:55.340 --> 00:07:57.540
And so here I'm pulling up the slides,


00:07:57.540 --> 00:08:01.140
and Guido says, "Can we make CPython faster?


00:08:01.140 --> 00:08:02.100
"If so, by how much?


00:08:02.100 --> 00:08:03.400
"Could it be a factor of two?


00:08:03.400 --> 00:08:04.900
"Could it be a factor of 10?


00:08:04.900 --> 00:08:07.620
"And do we break people if we do things like this?"


00:08:07.620 --> 00:08:11.140
So the Shannon plan, which was posted last October


00:08:11.140 --> 00:08:12.140
and will be covered,


00:08:12.140 --> 00:08:17.100
talks about how do we make it 1.5 times faster each year,


00:08:17.100 --> 00:08:18.460
but do that four times


00:08:18.460 --> 00:08:22.020
and because of compounding performance, I guess.


00:08:22.020 --> 00:08:23.900
Yeah, it's five times faster.


00:08:23.900 --> 00:08:25.300
All right, so there's that.


00:08:25.300 --> 00:08:28.780
Guido said, "Thank you to the pandemic.


00:08:28.780 --> 00:08:29.620
"Thank you to boredom.


00:08:29.620 --> 00:08:31.500
"I decided to apply at Microsoft."


00:08:31.500 --> 00:08:33.460
And shocker, they hired him.


00:08:33.460 --> 00:08:37.740
So as part of that, it's kind of just like,


00:08:37.740 --> 00:08:39.060
hey, we think you're awesome.


00:08:39.060 --> 00:08:40.900
Why don't you just pick something to work on


00:08:40.900 --> 00:08:42.060
that will contribute back?


00:08:42.060 --> 00:08:43.740
That'd be really cool.


00:08:43.740 --> 00:08:48.140
So his project at Microsoft is around making Python faster,


00:08:48.140 --> 00:08:49.340
which I think is great.


00:08:49.340 --> 00:08:52.620
- Cool. - So, yeah.


00:08:52.620 --> 00:08:56.220
So there's a team of folks, Mark Shannon, Eric Snow,


00:08:56.220 --> 00:08:58.260
and Guido, and possibly others,


00:08:58.260 --> 00:09:01.500
who are working with the core devs at Microsoft


00:09:01.500 --> 00:09:04.300
to make it faster, which is really cool.


00:09:04.300 --> 00:09:07.660
Everything will be done on the public GitHub repo.


00:09:07.660 --> 00:09:09.220
There's not like a secret branch


00:09:09.220 --> 00:09:10.780
that will be then dropped on it.


00:09:10.780 --> 00:09:13.680
So it's all just gonna be PRs to GitHub.com,


00:09:13.680 --> 00:09:18.320
slash Python, slash CPython, whatever the URL is,


00:09:18.320 --> 00:09:19.760
just the public spot.


00:09:19.760 --> 00:09:21.600
And one of the main things they wanna do


00:09:21.600 --> 00:09:24.520
is not break compatibility.


00:09:24.520 --> 00:09:28.360
So that's important.


00:09:28.360 --> 00:09:31.560
Also said, what things could we change?


00:09:31.560 --> 00:09:33.800
Well, you can't change the base object, like,


00:09:33.800 --> 00:09:40.560
pi, what is it, pi obj, basically the base class, right?


00:09:40.560 --> 00:09:43.560
Pi object pointer, that's it, the pi object class.


00:09:43.560 --> 00:09:46.360
So that thing has to stay the same,


00:09:46.360 --> 00:09:48.560
and it really needs to keep reference counting semantics


00:09:48.560 --> 00:09:49.800
'cause so much is built on that.


00:09:49.800 --> 00:09:53.160
But they could change the bytecode that exists,


00:09:53.160 --> 00:09:56.840
the stack frame layout, the compiler, the interpreter,


00:09:56.840 --> 00:10:00.480
maybe make it a JIT compiler to JIT compile the bytecode,


00:10:00.480 --> 00:10:01.720
all of those types of things.


00:10:01.720 --> 00:10:03.020
So that's pretty cool.


00:10:03.020 --> 00:10:04.840
And they said, how are we gonna reach


00:10:04.840 --> 00:10:07.240
two times speed up in 3.11?


00:10:07.240 --> 00:10:10.880
An adaptive specialized bytecode interpreter


00:10:10.880 --> 00:10:14.240
that will be more performant around certain operations,


00:10:14.240 --> 00:10:19.120
optimized frame stacks, faster calls,


00:10:19.120 --> 00:10:21.760
zero overhead exception handling,


00:10:21.760 --> 00:10:24.740
and things like integral internals.


00:10:24.740 --> 00:10:28.180
So, you know, maybe treating numbers differently,


00:10:28.180 --> 00:10:29.420
changing out PYC files.


00:10:29.420 --> 00:10:30.660
So there's a lot of stuff going on.


00:10:30.660 --> 00:10:34.400
Also putting the dunder dict for a class


00:10:34.400 --> 00:10:36.860
always at a certain known location


00:10:36.860 --> 00:10:39.060
'cause anytime you access a field,


00:10:39.960 --> 00:10:41.640
you have to go to the DunderDick,


00:10:41.640 --> 00:10:44.240
get the value out and then read it.


00:10:44.240 --> 00:10:46.200
And I suspect the first thing that happens is,


00:10:46.200 --> 00:10:49.640
we'll go find the DunderDick pointer


00:10:49.640 --> 00:10:51.640
and then go get the element out of it.


00:10:51.640 --> 00:10:54.080
So if every access could just go,


00:10:54.080 --> 00:10:55.160
nope, it's always, you know,


00:10:55.160 --> 00:10:57.480
one certain byte off in memory


00:10:57.480 --> 00:10:59.680
from where the class starts.


00:10:59.680 --> 00:11:02.700
That would save, you know, that sort of traversal there.


00:11:02.700 --> 00:11:04.880
So some pretty neat things.


00:11:04.880 --> 00:11:06.920
- Yeah, I'm glad you explained that


00:11:06.920 --> 00:11:08.280
'cause I read it before and I'm like,


00:11:08.280 --> 00:11:09.560
why would that help at all?


00:11:09.560 --> 00:11:13.680
I think you can traverse one fewer pointers,


00:11:13.680 --> 00:11:15.640
which in general doesn't matter,


00:11:15.640 --> 00:11:18.440
but it literally everything you ever touch ever,


00:11:18.440 --> 00:11:20.140
if you could cut in half the number of pointers,


00:11:20.140 --> 00:11:21.640
you gotta follow that'd be good.


00:11:21.640 --> 00:11:22.480
- Yeah.


00:11:22.480 --> 00:11:23.920
- Yeah, this is always one of those things


00:11:23.920 --> 00:11:25.960
that always struck me with,


00:11:25.960 --> 00:11:26.800
when you're using Python,


00:11:26.800 --> 00:11:28.340
you don't think about these sorts of things.


00:11:28.340 --> 00:11:30.460
It's when you're doing something in Rust or something,


00:11:30.460 --> 00:11:31.800
then you are confronted with the fact


00:11:31.800 --> 00:11:32.740
that you really have to keep track


00:11:32.740 --> 00:11:35.200
of where's the pointer pointing and memory and all that.


00:11:35.200 --> 00:11:36.520
And you take a lot of this stuff for granted.


00:11:36.520 --> 00:11:39.120
So it's great that people are still sort of going at it


00:11:39.120 --> 00:11:41.000
and looking for things to improve there.


00:11:41.000 --> 00:11:42.000
- Yeah, absolutely.


00:11:42.000 --> 00:11:44.840
You know, in like C you do the arrow,


00:11:44.840 --> 00:11:46.640
you know, dash greater than sort of thing.


00:11:46.640 --> 00:11:47.480
Every pointer, so you're like,


00:11:47.480 --> 00:11:48.880
"I'm following a pointer, I'm following a pointer."


00:11:48.880 --> 00:11:50.320
Like, you know it, right?


00:11:50.320 --> 00:11:54.440
Here you just, you write nice clean code and magic happens.


00:11:54.440 --> 00:11:58.040
So let me round this out with who will benefit.


00:11:58.040 --> 00:11:58.880
So who will benefit?


00:11:58.880 --> 00:12:02.160
If you're running CPU intensive pure Python code,


00:12:02.160 --> 00:12:03.440
that will get faster


00:12:03.440 --> 00:12:06.360
because the Python execution should be faster.


00:12:06.360 --> 00:12:09.000
Websites should be faster


00:12:09.000 --> 00:12:12.240
'cause a lot of that code is running in the Python space


00:12:12.240 --> 00:12:14.040
and tools that happen to use Python.


00:12:14.040 --> 00:12:16.200
Who will not benefit so much?


00:12:16.200 --> 00:12:20.280
NumPy, TensorFlow, Pandas, all the code that's written in C,


00:12:20.280 --> 00:12:21.660
things that are IO bound.


00:12:21.660 --> 00:12:23.420
So if you're waiting on something else,


00:12:23.420 --> 00:12:26.360
like speeding up the part that goes to wait,


00:12:26.360 --> 00:12:28.040
doesn't really matter.


00:12:28.040 --> 00:12:30.820
Multi-threaded code because of the GIL at this point,


00:12:30.820 --> 00:12:34.420
but Eric Snow is also working on the sub-interpreters,


00:12:34.420 --> 00:12:35.880
which may fix that and so on.


00:12:35.880 --> 00:12:38.540
So anyway, pretty neat stuff.


00:12:38.540 --> 00:12:40.020
There's some peps out there.


00:12:40.020 --> 00:12:43.780
I'll link to the tweet by Mike Driscoll,


00:12:43.780 --> 00:12:48.260
but that'll take you straight to the GitHub repo,


00:12:48.260 --> 00:12:50.540
which has the PDF of the slides


00:12:50.540 --> 00:12:53.140
and people can check that out if they're interested.


00:12:53.140 --> 00:12:56.220
- I like the last bullet for the previous slide,


00:12:56.220 --> 00:12:58.100
people that will not benefit,


00:12:58.100 --> 00:13:00.540
code that's algorithmically inefficient.


00:13:00.540 --> 00:13:02.500
Otherwise, if your code already sucks,


00:13:02.500 --> 00:13:03.900
it's not going to be better.


00:13:03.900 --> 00:13:08.020
- It may be better, but it could be better.


00:13:08.020 --> 00:13:09.420
- I was about to say, like, theoretically,


00:13:09.420 --> 00:13:11.420
it actually would go faster and just...


00:13:11.420 --> 00:13:12.820
(laughing)


00:13:12.820 --> 00:13:14.580
- Not as much better as it could, right?


00:13:14.580 --> 00:13:16.900
- Yeah, it would still be like N to the power of three


00:13:16.900 --> 00:13:17.740
or something like that,


00:13:17.740 --> 00:13:20.780
but it would be faster N to the power of three.


00:13:20.780 --> 00:13:23.580
- Yeah, yeah, it won't change the big O notation,


00:13:23.580 --> 00:13:25.780
but it might make it run quicker on wall time.


00:13:25.780 --> 00:13:26.620
That's right.


00:13:26.620 --> 00:13:27.460
- Yeah.


00:13:27.460 --> 00:13:28.280
- Yeah.


00:13:28.280 --> 00:13:30.780
And Christopher Tyler out there in the live stream says,


00:13:30.780 --> 00:13:32.980
"I know I still need to improve my code,


00:13:32.980 --> 00:13:34.580
"but this would be great," right?


00:13:34.580 --> 00:13:36.620
I mean, it used to be that we could just


00:13:37.660 --> 00:13:39.860
a new CPU would come out that's like twice as fast


00:13:39.860 --> 00:13:40.700
as what we ran on before.


00:13:40.700 --> 00:13:42.460
Like, "Oh, now it's fast enough, we're good."


00:13:42.460 --> 00:13:43.940
That doesn't happen as much these days.


00:13:43.940 --> 00:13:46.440
So it's cool that the run times are getting faster.


00:13:46.440 --> 00:13:49.220
- Yeah, and I mean, let's be honest,


00:13:49.220 --> 00:13:52.260
Python is also still used for like just lots of script tasks


00:13:52.260 --> 00:13:54.100
like, "Hey, I just need this thing on the command line


00:13:54.100 --> 00:13:56.340
that does the thing and I put that in Chrome."


00:13:56.340 --> 00:13:58.060
And like a lot of that will be nice


00:13:58.060 --> 00:13:59.420
if that just gets a little bit faster


00:13:59.420 --> 00:14:02.620
and it sounds like this will just be right up that alley.


00:14:02.620 --> 00:14:05.660
- Yeah, and one of the things that I know has been


00:14:05.660 --> 00:14:13.380
been holding certain types of changes back has been concerned about slowing down the


00:14:13.380 --> 00:14:14.540
startup time.


00:14:14.540 --> 00:14:18.060
Because if all you want to do is run Python to make a very small thing happen, but like


00:14:18.060 --> 00:14:22.540
there's a big JIT overhead and all sorts of stuff, and it takes two seconds to start and


00:14:22.540 --> 00:14:25.500
a nanosecond, microsecond to run, right?


00:14:25.500 --> 00:14:29.460
They don't want to put those kinds of limitations and kill that use case either.


00:14:29.460 --> 00:14:31.660
So yeah, it's good to point that out.


00:14:31.660 --> 00:14:35.100
All right, Vincent, you're up next.


00:14:35.100 --> 00:14:40.940
Cool. Yeah, so I dabble a little bit in fairness algorithms. It's a big important thing.


00:14:40.940 --> 00:14:45.420
So I get a lot of questions from people like, "Hey, if I want to do machine learning and fairness,


00:14:45.420 --> 00:14:49.100
where should I start?" And I don't think you should start with algorithms. Instead,


00:14:49.100 --> 00:14:53.420
what you should do is you should go check out this Python project called Deon.


00:14:53.420 --> 00:14:56.620
And the project's really minimal. The main thing that it really just does


00:14:56.620 --> 00:15:01.420
is it gives you a checklist of just stuff to check before you do a big data science project


00:15:01.420 --> 00:15:04.300
at a big company or an enterprise or something like that.


00:15:04.300 --> 00:15:09.100
And they're really sensible things. They're sort of grouped together.


00:15:09.100 --> 00:15:13.660
So like, "Hey, can I check off that I have informed consent and collection bias?


00:15:13.660 --> 00:15:15.020
Can I check all these things off?"


00:15:15.020 --> 00:15:16.380
The main thing--


00:15:16.380 --> 00:15:19.020
It's literally a checkbox. You can check them off in the page


00:15:19.020 --> 00:15:21.820
to sort of get the feel of like, "Oh, yeah, these are good."


00:15:21.820 --> 00:15:24.140
It goes further. So the thing is, this is an actual Python project.


00:15:24.140 --> 00:15:26.540
You can generate this as YAML for your GitHub profile.


00:15:26.540 --> 00:15:29.180
So for your GitHub project, you actually have this checklist


00:15:29.180 --> 00:15:32.460
that has to be checked in git so you know that people signed off on it.


00:15:32.460 --> 00:15:36.540
You can actually see the checklist, you can even maybe in your git log see who checked it off.


00:15:36.540 --> 00:15:41.660
But what's really cool is two things. One, you can generate this checklist.


00:15:41.660 --> 00:15:46.540
Two, you can also customize the checklist. So if you are a specific company of certain legal


00:15:46.540 --> 00:15:50.300
requirements, this tool actually kind of makes it easy to customize this very specific checklist


00:15:50.300 --> 00:15:56.140
for data projects. But the real killer feature, if you ask me, again, all of these comments are good,


00:15:56.140 --> 00:16:01.340
like, is the data security well done? Is the analysis reproducible?


00:16:01.340 --> 00:16:04.940
How do we do deployment? All of these things that are usually things that go wrong


00:16:04.940 --> 00:16:06.740
and were obvious in hindsight.


00:16:06.740 --> 00:16:08.680
But the real killer feature is,


00:16:08.680 --> 00:16:10.940
usually you have to convince people to take this serious.


00:16:10.940 --> 00:16:14.280
So what the website offers is an example list.


00:16:14.280 --> 00:16:17.340
So for every single item that is on this checklist,


00:16:17.340 --> 00:16:21.040
they have one or two examples, typically these are newspaper articles,


00:16:21.040 --> 00:16:24.500
of places where this has actually gone wrong in the past.


00:16:24.580 --> 00:16:27.620
So if you need a really good argument for your boss,


00:16:27.620 --> 00:16:29.300
like, "Hey, we gotta take this serious,"


00:16:29.300 --> 00:16:31.860
there's a newspaper article you can just send along as well.


00:16:31.860 --> 00:16:36.420
-Oh, that's interesting. -Yeah, I like it.


00:16:36.420 --> 00:16:39.540
Yeah, and the fact you can also generate Jupyter Notebooks with this,


00:16:39.540 --> 00:16:41.300
you can customize it a little bit.


00:16:41.300 --> 00:16:44.740
The people that made this, the company I think is called Driven Data.


00:16:44.740 --> 00:16:46.940
They host Kaggle competitions for good causes.


00:16:46.940 --> 00:16:48.540
That's sort of a thing that they do there.


00:16:48.540 --> 00:16:50.340
But Deon is just a really cool project.


00:16:50.340 --> 00:16:54.100
I think if more people would just start with a sensible checklist


00:16:54.180 --> 00:16:56.820
and work from there, a lot of projects


00:16:56.820 --> 00:16:58.580
would immediately be better for it.


00:16:58.580 --> 00:17:01.860
- Yeah, this is really cool.


00:17:01.860 --> 00:17:04.540
So things are, can you go to the very bottom


00:17:04.540 --> 00:17:05.940
of that page that you're on?


00:17:05.940 --> 00:17:08.540
Sorry, just the checklist.


00:17:08.540 --> 00:17:09.380
- Oh, right, yeah, yeah.


00:17:09.380 --> 00:17:10.740
- There's some examples like,


00:17:10.740 --> 00:17:14.660
make sure that you've accounted for unintended use.


00:17:14.660 --> 00:17:16.340
Have you taken steps to identify


00:17:16.340 --> 00:17:18.420
and prevent unintended uses and abuse?


00:17:18.420 --> 00:17:22.620
So like, if you created up find my friends in pictures,


00:17:22.620 --> 00:17:24.820
So like, I want to find pictures my friends have taken of me.


00:17:24.820 --> 00:17:26.460
You could put it up and it would show you all the pictures


00:17:26.460 --> 00:17:27.780
your friends took,


00:17:27.780 --> 00:17:30.220
but maybe someone else is going to use that to,


00:17:30.220 --> 00:17:32.780
I don't know, try to fish you.


00:17:32.780 --> 00:17:34.660
Like, here's the picture of us together,


00:17:34.660 --> 00:17:37.020
or I don't know, some weird thing, right?


00:17:37.020 --> 00:17:39.500
Use it for like facial recognition and tracking


00:17:39.500 --> 00:17:41.220
when it had no such intent, right?


00:17:41.220 --> 00:17:42.380
Things like that.


00:17:42.380 --> 00:17:44.980
- I think for, and I might be,


00:17:44.980 --> 00:17:46.660
so it doesn't have this example.


00:17:46.660 --> 00:17:48.780
The best example of unattended use,


00:17:48.780 --> 00:17:50.540
there used to be this geo lookup company


00:17:50.540 --> 00:17:51.740
where you could give an IP address


00:17:51.740 --> 00:17:53.300
and give you like an actual address.


00:17:53.300 --> 00:17:56.300
However, sometimes you don't know where the IP address actually is.


00:17:56.300 --> 00:17:59.120
So just give like the center point of like a us state or the country.


00:17:59.120 --> 00:18:02.700
So there used to be this house in the middle of Kansas, I think


00:18:02.700 --> 00:18:08.480
the center point, but the thing is, this, they will get like FBI


00:18:08.480 --> 00:18:11.300
trucks driving by and like doing raids and stuff because they thought


00:18:11.300 --> 00:18:13.820
there were criminals there because the geo lookup service would always


00:18:13.820 --> 00:18:16.820
say like, ah, the crooks at that IP address, that's this latitude longitude.


00:18:16.820 --> 00:18:17.340
Right.


00:18:17.340 --> 00:18:17.560
Right.


00:18:17.560 --> 00:18:18.840
We had a cyber attack.


00:18:18.840 --> 00:18:19.980
It was from this IP.


00:18:19.980 --> 00:18:20.480
Yeah.


00:18:21.020 --> 00:18:27.260
Rate them boys. And of course it was just some poor farmer in the midwest going, you know


00:18:27.260 --> 00:18:32.140
Yeah, just the geographic center. Please stop raiding my farm. Yeah, but


00:18:32.140 --> 00:18:34.780
Like the story was actually quite serious


00:18:34.780 --> 00:18:38.780
Like I think the person who lived there could like death threats at some point as well because of the same mistake


00:18:38.780 --> 00:18:44.860
So like this is stuff to take serious. the one thing that I did like is the solution. I think now the the


00:18:44.860 --> 00:18:49.500
the the instead of it pointing to the house in kansas, I think it points to like


00:18:50.540 --> 00:18:53.260
The center of the three big lakes like in michigan


00:18:53.260 --> 00:18:58.060
I think there's just the middle of a puddle of water basically just to make it out like obvious to the fbi squads


00:18:58.060 --> 00:19:00.140
Like no, it's not a person living there


00:19:00.140 --> 00:19:04.300
Darn, these submarines are that they've moved underwater


00:19:04.300 --> 00:19:08.060
Or or whatever but I mean, but that's why you want to have a checklist like this


00:19:08.060 --> 00:19:12.860
Like you're not gonna the thing with unintended use is you it's unintended so you cannot really imagine it


00:19:12.860 --> 00:19:15.980
But you at least should do the exercise and that's what this list


00:19:15.980 --> 00:19:20.300
Uh does in a very sensible way and more people should just do it and there's interesting


00:19:20.460 --> 00:19:23.580
Examples too. You just have a look and there's also a little community


00:19:23.580 --> 00:19:28.060
There's a little community around it as well of like collecting these examples and they have like a wiki page with


00:19:28.060 --> 00:19:30.140
Examples that didn't make the front page cut


00:19:30.140 --> 00:19:33.820
so definitely recommend anyone interested in fairness, uh start here


00:19:33.820 --> 00:19:39.420
I was curious you you brushed by fairly quickly of fairness analysis


00:19:39.420 --> 00:19:47.820
Fairness analysis. Is that what you do? so, I just don't know what that means. So could you yeah, so,


00:19:47.900 --> 00:19:51.580
Oh, man, this is a longer like this topic deserves more time than i'll give it


00:19:51.580 --> 00:19:56.540
But the idea is that you might be able but we know that models aren't always fair, right?


00:19:56.540 --> 00:20:01.740
Like it can be that you have models that for example, um


00:20:01.740 --> 00:20:05.180
The amazon was a nice example. So they had like a


00:20:05.180 --> 00:20:12.940
A resume parsing algorithm that basically favored men because they hired more men historically. So the algorithm would prefer men like


00:20:12.940 --> 00:20:15.340
Okay, that kind of fairness. Okay


00:20:15.900 --> 00:20:18.620
These have been our good employees. Let's find more like them.


00:20:18.620 --> 00:20:22.540
Exactly. And the thing is you don't get an algorithm that's unfair.


00:20:22.540 --> 00:20:27.660
So there are these machine learning techniques and there's this community of researchers that try to look for ways like


00:20:27.660 --> 00:20:31.760
Can we improve the fairness of these systems so we don't just optimize for accuracy?


00:20:31.760 --> 00:20:36.460
We also say well, we want to make sure that subgroups are treated fairly and equally and stuff like that


00:20:36.460 --> 00:20:38.940
So I dabble a little bit in this there's this project


00:20:38.940 --> 00:20:43.100
I like to collaborate with my open source a couple of things with these people


00:20:43.420 --> 00:20:49.260
It's called fair learn the main thing that I really like about the package is that it starts by saying fairness of ai systems


00:20:49.260 --> 00:20:51.340
Is more than just running a few lines of code


00:20:51.340 --> 00:20:57.680
Like it starts by acknowledging that but they have mitigation techniques and algorithms and like tools to help you measure the unfairness


00:20:57.680 --> 00:21:01.100
it's like learn compatible as well and stuff to like


00:21:01.100 --> 00:21:07.580
Having said all that start here start like starting with a checklist. Don't worry about the machine learning stuff just yet start here


00:21:07.580 --> 00:21:11.020
Very cool


00:21:11.020 --> 00:21:14.660
Before we move on, Connor Furster in the live chat says,


00:21:14.660 --> 00:21:17.060
I'm glad the conversation of ethics and data science


00:21:17.060 --> 00:21:17.780
is enlarging.


00:21:17.780 --> 00:21:22.540
I think it's important about what we make.


00:21:22.540 --> 00:21:23.500
I agree.


00:21:23.500 --> 00:21:26.220
Totally.


00:21:26.220 --> 00:21:27.940
Now, before we do move on, though,


00:21:27.940 --> 00:21:31.700
let me tell you all about our sponsor for this episode,


00:21:31.700 --> 00:21:32.300
Sentry.


00:21:32.300 --> 00:21:34.140
So this episode is brought to you by Sentry.


00:21:34.140 --> 00:21:35.900
Thank you, Sentry.


00:21:35.900 --> 00:21:38.020
How would you like to remove a little bit of stress


00:21:38.020 --> 00:21:38.700
from your life?


00:21:38.700 --> 00:21:41.320
Do you worry that users may be having difficulties


00:21:41.320 --> 00:21:43.980
or encountering errors with your app right now?


00:21:43.980 --> 00:21:47.160
And would you even know it until they sent you that support email?


00:21:47.160 --> 00:21:49.160
How much better would it be to have the errors


00:21:49.160 --> 00:21:51.280
and performance details immediately sent to you,


00:21:51.280 --> 00:21:53.780
including the call stack and values of local variables


00:21:53.780 --> 00:21:56.620
and the active user recorded right in the report?


00:21:56.620 --> 00:21:59.620
With Sentry, it's not only possible, it's simple.


00:21:59.620 --> 00:22:02.420
We actually use Sentry on our website.


00:22:02.420 --> 00:22:05.720
It's on pythonbytes.fm, it's on Talk Python Training, all those things.


00:22:05.720 --> 00:22:08.920
And we've actually fixed a bug triggered by a user


00:22:08.920 --> 00:22:11.600
and had the upgrade ready to roll out


00:22:11.600 --> 00:22:13.340
as we got the support email.


00:22:13.340 --> 00:22:14.840
They said, "Hey, I'm having a problem with the site.


00:22:14.840 --> 00:22:16.220
I can't do this or that."


00:22:16.220 --> 00:22:17.840
I said, "Actually, I already saw the error.


00:22:17.840 --> 00:22:19.420
I just pushed the fix to production.


00:22:19.420 --> 00:22:20.880
So just try it again."


00:22:20.880 --> 00:22:22.800
Imagine they're surprised.


00:22:22.800 --> 00:22:24.560
So surprise and delight, your users,


00:22:24.560 --> 00:22:28.140
create your Sentry account at pythonbytes.fm/sentry.


00:22:28.140 --> 00:22:29.560
And when you sign up, there's a,


00:22:29.560 --> 00:22:30.760
got a promo code, redeem it.


00:22:30.760 --> 00:22:32.760
Make sure you put Python bytes in that section


00:22:32.760 --> 00:22:35.920
or you won't get two months of free Sentry team plans


00:22:35.920 --> 00:22:38.120
and other features and they won't know it came from us.


00:22:38.120 --> 00:22:41.920
So use the promo code at pythonbytes.fm/sentry.


00:22:41.920 --> 00:22:44.880
Yeah, thanks for supporting the show.


00:22:44.880 --> 00:22:49.640
Brian, I like this one that you picked here.


00:22:49.640 --> 00:22:51.760
- You like this?


00:22:51.760 --> 00:22:53.000
- I like it a lot, it's very good.


00:22:53.000 --> 00:22:55.900
It has pictures, little animated things


00:22:55.900 --> 00:22:57.960
and it's great looking tools.


00:22:57.960 --> 00:23:00.360
- Yeah, so there's a, it was an article that was sent to us.


00:23:00.360 --> 00:23:02.520
I can't remember who sent it, so apologies.


00:23:02.520 --> 00:23:08.920
But it's an article called "Three Tools to Track and Visualize the Execution of Your Python Code."


00:23:08.920 --> 00:23:14.180
And I don't know why, executing your code just seems funny to me.


00:23:14.180 --> 00:23:19.880
I know it just means run it, but chop its head off or something.


00:23:19.880 --> 00:23:25.580
Anyway, so the three tools it covers are...


00:23:25.580 --> 00:23:29.580
We don't cover this very much because I don't know how to pronounce it.


00:23:29.640 --> 00:23:35.120
L-O-G-U-R-U, it's Loguru or Loguru, not sure.


00:23:35.120 --> 00:23:40.480
Loguru is a pretty printer with better exceptions.


00:23:40.480 --> 00:23:42.840
Let's go and look at that.


00:23:42.840 --> 00:23:45.000
It does exceptions like this,


00:23:45.000 --> 00:23:48.080
breaks out your exceptions into colors.


00:23:48.080 --> 00:23:51.040
It's just a really great way to visualize it.


00:23:51.040 --> 00:23:56.440
I would totally use this if I was teaching a class or something.


00:23:56.440 --> 00:24:02.920
this might be a good way to teach people how to look at trace logs and error logs.


00:24:02.920 --> 00:24:05.580
This is fantastic. And if you're out there listening, not seeing it,


00:24:05.580 --> 00:24:07.140
you should definitely pull up this site,


00:24:07.140 --> 00:24:10.220
because the pictures really are what you need to tell quickly.


00:24:10.220 --> 00:24:11.280
Yeah.


00:24:11.280 --> 00:24:14.120
Yeah, and that's one of the things I like about this article,


00:24:14.120 --> 00:24:16.780
is that lots of great pictures.


00:24:16.780 --> 00:24:19.440
One thing out of curiosity, so what I'm seeing here is that,


00:24:19.440 --> 00:24:22.040
for example, it says return number one divided by number two,


00:24:22.040 --> 00:24:24.940
and then you actually see the numbers that were in those variables.


00:24:25.020 --> 00:24:27.960
Do you have to add a decorator or something to get this output?


00:24:27.960 --> 00:24:30.020
Or how does that work?


00:24:30.020 --> 00:24:34.960
-That's explained later, maybe. -I don't remember where...


00:24:34.960 --> 00:24:37.020
Yeah, it's explained later, I think.


00:24:37.020 --> 00:24:38.300
Yeah, okay.


00:24:38.300 --> 00:24:41.200
I think you just pull it in and it just does it, but I'm not sure.


00:24:41.200 --> 00:24:43.260
-Okay, interesting. -Anyway.


00:24:43.260 --> 00:24:47.700
So that's LogGuru.


00:24:47.700 --> 00:24:51.200
Then there's Snoop, which is kind of fun,


00:24:51.260 --> 00:24:56.260
that has full down to Snoop should have this already.


00:24:56.260 --> 00:24:58.560
Anyway, you put with Snoop,


00:24:58.560 --> 00:25:02.400
you can see Prince lines of code being executed in a function.


00:25:02.400 --> 00:25:06.900
So it just runs your code and then prints out each line


00:25:06.900 --> 00:25:08.840
in real time as it's going through it.


00:25:08.840 --> 00:25:12.160
You would hardly ever want this, I think,


00:25:12.160 --> 00:25:15.300
but when you do want it, I think might be kind of cool


00:25:15.300 --> 00:25:17.320
to watch it go along.


00:25:17.320 --> 00:25:20.640
And you could also do this in a debugger,


00:25:20.640 --> 00:25:22.480
But if you didn't want a debugger, do a debugger.


00:25:22.480 --> 00:25:23.320
You can do this on the--


00:25:23.320 --> 00:25:26.160
- Well, one of the things that most debuggers have


00:25:26.160 --> 00:25:30.000
that is a little challenging is you'll see the state


00:25:30.000 --> 00:25:31.480
and you'll see the state change


00:25:31.480 --> 00:25:33.360
and you'll see it change again.


00:25:33.360 --> 00:25:35.320
But in your mind, you've got to remember,


00:25:35.320 --> 00:25:37.600
okay, that was a seven and then it was a five


00:25:37.600 --> 00:25:39.680
and then it was a three.


00:25:39.680 --> 00:25:40.640
- Oh, right, yeah. - Right?


00:25:40.640 --> 00:25:44.320
I hear it'll actually reproduce each line,


00:25:44.320 --> 00:25:46.320
each block of code with the values over,


00:25:46.320 --> 00:25:47.580
if you are in a loop three times,


00:25:47.580 --> 00:25:50.120
it'll show like going through the loop three times


00:25:50.120 --> 00:25:53.480
with all the values set, and that's pretty neat.


00:25:53.480 --> 00:25:54.320
- Yeah.


00:25:54.320 --> 00:25:55.960
- I would also argue just for teaching recursion,


00:25:55.960 --> 00:25:57.400
I think this visualization is kind of nice


00:25:57.400 --> 00:25:59.760
'cause you see that you actually see like the indentation


00:25:59.760 --> 00:26:01.320
and the depth appear.


00:26:01.320 --> 00:26:02.880
And so you can actually see like this function


00:26:02.880 --> 00:26:04.440
is called inside of this other function


00:26:04.440 --> 00:26:06.320
and there's a timestamp.


00:26:06.320 --> 00:26:09.360
So I would also argue this one's pretty good for teaching.


00:26:09.360 --> 00:26:10.200
- I like it.


00:26:10.200 --> 00:26:12.360
In fact, Connor on the live stream says,


00:26:12.360 --> 00:26:14.320
"I'm teaching my first Python course tomorrow."


00:26:14.320 --> 00:26:17.340
So yeah, thanks for the timely article.


00:26:17.340 --> 00:26:20.340
And real-time follow-up for the log guru,


00:26:20.340 --> 00:26:22.400
you have to import logger,


00:26:22.400 --> 00:26:24.740
and then you got to put a decorator on the function,


00:26:24.740 --> 00:26:27.240
and then it'll capture that super detailed output.


00:26:27.240 --> 00:26:30.500
Then that's probably exactly what you want,


00:26:30.500 --> 00:26:33.600
because you don't really want to do that for everything, probably.


00:26:33.600 --> 00:26:36.740
So it'll be something you're working on that you want to trace.


00:26:36.740 --> 00:26:40.900
So heart rate is the last tool that we want to talk about.


00:26:40.900 --> 00:26:46.140
And it's a way to visualize the execution of a Python program in real time.


00:26:46.200 --> 00:26:48.920
So this is something we have not covered before,


00:26:48.920 --> 00:26:52.120
but it's, I thought there was a little video.


00:26:52.120 --> 00:26:56.880
Yeah, it kind of goes through and does a little,


00:26:56.880 --> 00:27:01.400
like a heat map sort of thing on the side of your code.


00:27:01.400 --> 00:27:03.880
So when it's running,


00:27:03.880 --> 00:27:05.760
you can kind of see that different things


00:27:05.760 --> 00:27:07.520
get hit more than others.


00:27:07.520 --> 00:27:09.480
So that's--


00:27:09.480 --> 00:27:12.920
- It's almost like a profiler, sort of.


00:27:12.920 --> 00:27:15.300
Not speed though, it's just number of hits.


00:27:15.300 --> 00:27:16.580
- Yeah. - Okay.


00:27:16.580 --> 00:27:20.100
- Yeah, I'm kind of on the fence about this,


00:27:20.100 --> 00:27:22.020
but it's pretty, so, see.


00:27:22.020 --> 00:27:26.120
- Yeah, same, but the Loggeroo one looks amazing.


00:27:26.120 --> 00:27:29.780
- I thought Loggeroo was also like a general logging tool.


00:27:29.780 --> 00:27:31.180
Like it does more, I think,


00:27:31.180 --> 00:27:36.020
than just things for debugging.


00:27:36.020 --> 00:27:38.460
- Yeah, I think it's a general logging tool as well.


00:27:38.460 --> 00:27:39.780
- Okay.


00:27:39.780 --> 00:27:41.980
- But I guess it logs errors really good.


00:27:41.980 --> 00:27:44.240
(laughing)


00:27:44.240 --> 00:27:47.400
- Logger not catch decorator.


00:27:47.400 --> 00:27:49.240
Okay, could probably do other things


00:27:49.240 --> 00:27:50.080
with the logger then as well,


00:27:50.080 --> 00:27:53.240
but having a good logging debugger catcher


00:27:53.240 --> 00:27:54.400
is always welcome.


00:27:54.400 --> 00:27:56.240
- Yeah, absolutely.


00:27:56.240 --> 00:27:58.240
All right, let's talk about ducks.


00:27:58.240 --> 00:28:01.000
I mean, Brian, you and I are in Oregon, go ducks.


00:28:01.000 --> 00:28:01.840
- Go ducks.


00:28:01.840 --> 00:28:03.280
- Well, I know your daughter goes there.


00:28:03.280 --> 00:28:07.440
My daughter goes to OSU, so go go beavers, I guess.


00:28:07.440 --> 00:28:10.120
Whatever, ducks, we're gonna talk duck databases anyway.


00:28:10.120 --> 00:28:11.720
And data science.


00:28:11.720 --> 00:28:15.460
So Alex Monahan sent over to us saying,


00:28:15.460 --> 00:28:18.620
"Hey, you should check out this article about DuckDB,"


00:28:18.620 --> 00:28:20.620
which is a thing I'm now learning about.


00:28:20.620 --> 00:28:25.060
And it's integration, it's direct integration with pandas.


00:28:25.060 --> 00:28:27.540
So instead of taking data from a database,


00:28:27.540 --> 00:28:30.740
loading it into a pandas data frame,


00:28:30.740 --> 00:28:33.660
doing stuff on it, and then getting the answer out,


00:28:33.660 --> 00:28:36.740
you basically put it into this embedded database, DuckDB,


00:28:36.740 --> 00:28:38.860
which is SQLite-like.


00:28:39.700 --> 00:28:42.980
And then, sorry, you put it into a pandas data frame,


00:28:42.980 --> 00:28:45.420
but then the query engine of DuckDB


00:28:45.420 --> 00:28:48.260
can query it directly without any data exchange,


00:28:48.260 --> 00:28:50.320
without transferring it back and forth


00:28:50.320 --> 00:28:52.060
between the two systems or formats.


00:28:52.060 --> 00:28:54.260
That's pretty cool, right?


00:28:54.260 --> 00:28:56.740
So, let me pull this up here.


00:28:56.740 --> 00:28:57.580
- Oh, that's Thomas.


00:28:57.580 --> 00:28:58.400
- I know him.


00:28:58.400 --> 00:29:00.260
Nice.


00:29:00.260 --> 00:29:01.980
- Yeah, he's from Amsterdam.


00:29:01.980 --> 00:29:03.220
- Yeah, very cool.


00:29:03.220 --> 00:29:04.560
So here's the idea.


00:29:04.560 --> 00:29:08.300
We've got SQL on pandas, basically.


00:29:09.540 --> 00:29:11.300
So if we had a data frame,


00:29:11.300 --> 00:29:13.060
here they have a really simple data frame,


00:29:13.060 --> 00:29:15.340
but just a single array,


00:29:15.340 --> 00:29:18.860
but it could be a very complex data frame.


00:29:18.860 --> 00:29:21.620
And then what you can do is you can import DuckDB


00:29:21.620 --> 00:29:23.500
and you can say duckdb.query,


00:29:23.500 --> 00:29:24.780
and then you write something like,


00:29:24.780 --> 00:29:29.780
so one of the columns is called A in the data frame,


00:29:29.780 --> 00:29:34.760
and you could say select some of A from the data frame.


00:29:34.760 --> 00:29:36.780
How cool is that?


00:29:38.020 --> 00:29:39.820
- I don't know, is it cool?


00:29:39.820 --> 00:29:40.660
- It's very cool.


00:29:40.660 --> 00:29:41.620
So then you can also,


00:29:41.620 --> 00:29:44.180
there's also a two data frame on the result.


00:29:44.180 --> 00:29:50.420
So what happens here is this is parsed by DuckDB,


00:29:50.420 --> 00:29:54.020
which has an advanced query optimizer


00:29:54.020 --> 00:29:57.420
for things like joins and filtering and indexes


00:29:57.420 --> 00:29:59.100
and all that kind of stuff.


00:29:59.100 --> 00:30:00.740
And then it says, oh, okay,


00:30:00.740 --> 00:30:04.220
so you said there's a thing called mydf,


00:30:04.220 --> 00:30:06.720
which I'll just go look in the locals


00:30:06.720 --> 00:30:09.960
of my current call stack and see if I can find that.


00:30:09.960 --> 00:30:13.280
- Yeah, that is neat.


00:30:13.280 --> 00:30:14.880
- So you can write arbitrary SQL


00:30:14.880 --> 00:30:16.000
and this one looks pretty straight forward.


00:30:16.000 --> 00:30:18.780
You're like, yeah, yeah, okay, interesting, interesting.


00:30:18.780 --> 00:30:22.400
But you can come down here and do more interesting things.


00:30:22.400 --> 00:30:24.800
Let's see, I'll pull up some examples.


00:30:24.800 --> 00:30:29.200
So they do a select aggregation group by things.


00:30:29.200 --> 00:30:31.000
So select these two things


00:30:31.000 --> 00:30:33.340
and then also do a sum min max and average


00:30:33.340 --> 00:30:36.540
on some part of the data frame.


00:30:36.540 --> 00:30:38.340
and then you pull it out of the data frame


00:30:38.340 --> 00:30:40.980
and you group by two of the elements.


00:30:40.980 --> 00:30:43.140
All right, and they show also what that would look like


00:30:43.140 --> 00:30:46.400
if you did that in true pandas format.


00:30:46.400 --> 00:30:47.240
That's cool.


00:30:47.240 --> 00:30:51.260
And they say, well, it's about two to three times faster


00:30:51.260 --> 00:30:53.380
in the DuckDB version.


00:30:53.380 --> 00:30:54.720
- That is interesting.


00:30:54.720 --> 00:30:55.940
- That's interesting, right?


00:30:55.940 --> 00:30:57.780
But then they say, well, what if we wanted


00:30:57.780 --> 00:31:00.740
not to just group by, but we wanted a filter?


00:31:00.740 --> 00:31:02.820
Seems real simple, like where the ship date


00:31:02.820 --> 00:31:05.820
is less than 1998, no big deal.


00:31:05.820 --> 00:31:12.260
But because the way that this can be really officially figured out by the query optimizer,


00:31:12.260 --> 00:31:15.480
it turns out to be much faster.


00:31:15.480 --> 00:31:22.280
So 0.6 seconds on single threaded or it actually supports parallel execution as well.


00:31:22.280 --> 00:31:28.160
So multi-threaded, they tested on a system that only had two cores, but it can be many, many cores.


00:31:28.620 --> 00:31:34.120
So it's faster, 0.4 seconds when threaded versus 2.2 seconds,


00:31:34.120 --> 00:31:36.960
sorry, 3.5 seconds on regular pandas.


00:31:36.960 --> 00:31:41.220
But there's this more complicated, non-obvious thing


00:31:41.220 --> 00:31:44.240
you can do called a manual pushdown in pandas, which


00:31:44.240 --> 00:31:46.360
will help drive some of the efficiency


00:31:46.360 --> 00:31:48.360
before other work happens.


00:31:48.360 --> 00:31:50.600
And then they finally show one at the very end


00:31:50.600 --> 00:31:52.400
where there's more stuff going on


00:31:52.400 --> 00:31:54.080
than Query Optimizer does.


00:31:54.080 --> 00:31:56.520
So the threaded one's 0.5 seconds.


00:31:56.520 --> 00:31:58.520
regular pandas is 15 seconds.


00:31:58.520 --> 00:32:03.080
So all that's cool and what's really neat is it all just happens like on the data frame.


00:32:03.080 --> 00:32:06.920
Yeah, there's two things about that that are pretty interesting.


00:32:06.920 --> 00:32:11.240
Like one is we shouldn't underestimate how many people are still new to pandas, but do understand SQL.


00:32:11.240 --> 00:32:13.240
So just for that use case, I can imagine.


00:32:13.240 --> 00:32:14.680
Yeah, that's a good one.


00:32:14.680 --> 00:32:16.440
You're going to get a lot of people on board.


00:32:16.440 --> 00:32:21.560
But the fact there's a query optimizer in there that's able to work on top of pandas. That's also pretty neat.


00:32:21.560 --> 00:32:25.320
Because I'm assuming it's doing clever things like, oh, I need to filter data.


00:32:25.480 --> 00:32:27.880
I should do that as early on as possible in my query plan


00:32:27.880 --> 00:32:29.880
and doing some of that logic internally.


00:32:29.880 --> 00:32:34.760
And the fact is you can paralyze it because Pandas doesn't paralyze easily.


00:32:34.760 --> 00:32:37.560
Yeah, I don't know that it paralyzes at all.


00:32:37.560 --> 00:32:39.560
You've got to go to something like Dask.


00:32:39.560 --> 00:32:43.400
Yeah, so there are some tricks that you could do,


00:32:43.400 --> 00:32:45.560
but they're tricks, they're not really natively supported.


00:32:45.560 --> 00:32:49.480
- Right. - But just having a SQL interface is neat.


00:32:49.480 --> 00:32:54.120
Yeah, this is pretty... And also, now I learned about DuckDB,


00:32:54.120 --> 00:32:57.320
So apparently that's a thing, which is pretty awesome.


00:32:57.320 --> 00:33:00.720
So it's in process, just like SQLite.


00:33:00.720 --> 00:33:04.020
It's written in C++ 11 with no dependencies.


00:33:04.020 --> 00:33:08.720
Super fast. So this is also a cool thing that maybe I'll check out


00:33:08.720 --> 00:33:11.520
unrelated to querying pandas, but the fact that you can,


00:33:11.520 --> 00:33:13.020
I think is pretty cool.


00:33:13.020 --> 00:33:15.020
It's got a great name.


00:33:15.020 --> 00:33:18.820
You know, another database out there I hear a lot about,


00:33:18.820 --> 00:33:21.220
but I've never used or have really an opinion about,


00:33:21.220 --> 00:33:23.220
is CockroachDB.


00:33:23.520 --> 00:33:26.280
I'm not a huge fan of-- just on the name,


00:33:26.280 --> 00:33:27.900
although it has some interesting ideas.


00:33:27.900 --> 00:33:30.540
I think it's meant to communicate resiliency,


00:33:30.540 --> 00:33:32.620
and it can't be killed because it's geolocated


00:33:32.620 --> 00:33:33.940
and it's just going to survive.


00:33:33.940 --> 00:33:34.940
But yeah.


00:33:34.940 --> 00:33:35.460
Ducks.


00:33:35.460 --> 00:33:36.300
I'll go with ducks.


00:33:36.300 --> 00:33:39.140
[INTERPOSING VOICES]


00:33:39.140 --> 00:33:42.220
Yeah, and then out in the live stream chat,


00:33:42.220 --> 00:33:45.740
Christopher says, so DuckDB is querying on pandas data frames,


00:33:45.740 --> 00:33:48.380
or can you load the data method chain with DuckDB


00:33:48.380 --> 00:33:49.820
and reduce memory?


00:33:49.820 --> 00:33:52.140
I believe you could do either.


00:33:52.140 --> 00:33:55.820
If you could load data into it and then there's a two data frame option,


00:33:55.820 --> 00:33:57.820
that probably could come out of it, but...


00:33:57.820 --> 00:34:00.700
- I think... - This is right on it.


00:34:00.700 --> 00:34:02.700
- Yeah, go ahead. - Doesn't...


00:34:02.700 --> 00:34:05.420
I might have just seen it briefly while you were scrolling in the blog post,


00:34:05.420 --> 00:34:08.700
but I believe it also said that it supports the parquet file format.


00:34:08.700 --> 00:34:11.260
- It does. - So the nice thing about parquets,


00:34:11.260 --> 00:34:13.500
you can kind of index your data cleverly,


00:34:13.500 --> 00:34:15.860
like you can index it by date on the file system.


00:34:15.860 --> 00:34:19.100
And then presumably, if you were to write the SQL query in DuckDB,


00:34:19.100 --> 00:34:21.420
it would only read the files of the appropriate date


00:34:21.420 --> 00:34:23.420
if you put a filter in there.


00:34:23.420 --> 00:34:25.420
So I can imagine, just because of that reason,


00:34:25.420 --> 00:34:28.240
DuckDB on its own might be more memory performant


00:34:28.240 --> 00:34:30.240
than Pana's, I guess.


00:34:30.240 --> 00:34:32.240
- Yeah, perhaps. - That's...


00:34:32.240 --> 00:34:34.240
- Very cool. - Stuff like that you could do.


00:34:34.240 --> 00:34:36.240
Yeah, and then Nick Harvey also says,


00:34:36.240 --> 00:34:38.240
"I wonder if it's read-only, if you can insert or update?"


00:34:38.240 --> 00:34:40.240
I don't know for sure,


00:34:40.240 --> 00:34:42.240
but you can see in some of the places,


00:34:42.240 --> 00:34:44.240
they are doing projections.


00:34:44.240 --> 00:34:48.240
So, for example, they're doing a select some min/max average.


00:34:48.240 --> 00:34:50.240
That's generating data that goes into it.


00:34:50.240 --> 00:34:52.740
and then the result is a data frame.


00:34:52.740 --> 00:34:55.140
So you can just add into the data frame afterwards


00:34:55.140 --> 00:34:57.200
if you want to be more manual about it.


00:34:57.200 --> 00:35:00.940
Yeah.


00:35:00.940 --> 00:35:03.840
All right. Vincent, you got the last one?


00:35:03.840 --> 00:35:07.840
Yeah. So the thing is, I work for a company called Rasa.


00:35:07.840 --> 00:35:11.440
We make software with Python to make virtual assistants


00:35:11.440 --> 00:35:13.500
easier to make in Python.


00:35:13.500 --> 00:35:15.740
And I was looking in our community showcase,


00:35:15.740 --> 00:35:19.140
and I just found this project that just made me feel hopeful.


00:35:19.200 --> 00:35:21.200
So this is a personal project, I think.


00:35:21.200 --> 00:35:26.480
So we have a name here, Amit, and I hope I'm pronouncing it correctly, Arvind.


00:35:26.480 --> 00:35:31.360
But what they did is they used Rasa kind of like a Lego brick, but they made this


00:35:31.360 --> 00:35:34.560
assistant, if you will, that you can send a text message to.


00:35:34.560 --> 00:35:36.880
Now what it does,


00:35:36.880 --> 00:35:40.160
I'll zoom in a little bit for people on YouTube that might be able to see the GIF,


00:35:40.160 --> 00:35:48.580
but every 10 minutes it scrapes the weather information, the fire hazard information, and I think evacuation information from local government in California,


00:35:49.120 --> 00:35:51.120
meant to help people during wildfire season.


00:35:51.120 --> 00:35:54.320
And they completely open-sourced this project as well.


00:35:54.320 --> 00:35:58.160
So there's a linked GitHub project where you can just see how they implemented it.


00:35:58.160 --> 00:36:01.280
And it's a fairly simple implementation.


00:36:01.280 --> 00:36:03.200
They use Raza with a Twilio API.


00:36:03.200 --> 00:36:06.720
They're doing some neat little clever things here with like,


00:36:06.720 --> 00:36:09.440
if you misspelled your city,


00:36:09.440 --> 00:36:11.840
they're using like a fuzzy string matching library


00:36:11.840 --> 00:36:13.760
to make sure that even if you misspell your city,


00:36:13.760 --> 00:36:16.080
they can still try to give you like accurate information.


00:36:17.120 --> 00:36:21.520
But what they do is they just have this endpoint where you can send the text message to like give me the update of


00:36:21.520 --> 00:36:22.720
San Francisco


00:36:22.720 --> 00:36:26.400
And then it will tell you all the weather information air quality information and that sort of thing


00:36:26.400 --> 00:36:28.640
And if you need to evacuate they will also be able to tell you that


00:36:28.640 --> 00:36:33.840
and what I just loved about this, if you look at the way that they described it


00:36:33.840 --> 00:36:40.560
These this was just two people who knew python who were a little bit disappointed with the communication that was happening


00:36:40.560 --> 00:36:46.000
But because the apis were open they just built their own solution and like thousands of people use this


00:36:46.640 --> 00:36:49.180
And what's even greater is that, you know,


00:36:49.180 --> 00:36:51.660
if your mobile coverage isn't great,


00:36:51.660 --> 00:36:54.000
watching a YouTube video or like trying to get audio in


00:36:54.000 --> 00:36:57.320
can be tricky, but a text message is really low bandwidth.


00:36:57.320 --> 00:36:58.160
So for a lot of people,


00:36:58.160 --> 00:37:00.080
this is like a great way to communicate.


00:37:00.080 --> 00:37:02.760
And of course, I'm a little biased 'cause I work for Rasa


00:37:02.760 --> 00:37:05.240
and I think it's awesome that they use Rasa to build this.


00:37:05.240 --> 00:37:07.560
But again, the whole thing is just open source.


00:37:07.560 --> 00:37:10.440
You can go to their GitHub and you can just,


00:37:10.440 --> 00:37:14.960
if I'm not mistaking, there's like the scraping job


00:37:14.960 --> 00:37:17.660
of the endpoints actually in here as well.


00:37:17.660 --> 00:37:19.020
But this is like exactly what you want.


00:37:19.020 --> 00:37:21.460
Just a couple of open APIs and sort of citizen science,


00:37:21.460 --> 00:37:23.000
building something that's useful for the community.


00:37:23.000 --> 00:37:24.540
It's great.


00:37:24.540 --> 00:37:25.780
- Yeah, I like it.


00:37:25.780 --> 00:37:27.940
And text message is probably a really good way


00:37:27.940 --> 00:37:29.760
to communicate for disasters, right?


00:37:29.760 --> 00:37:33.540
You're possibly in a place where, you know,


00:37:33.540 --> 00:37:36.660
LTE is crashed, Wi-Fi is out, right?


00:37:36.660 --> 00:37:39.860
Like, even if you're on edge, you know,


00:37:39.860 --> 00:37:41.500
text should still get there.


00:37:41.500 --> 00:37:42.320
- Exactly.


00:37:42.320 --> 00:37:43.580
- Unless you're on iMessage, then you're out of luck.


00:37:43.580 --> 00:37:45.580
I don't know what I'm saying. Sort of.


00:37:45.580 --> 00:37:47.660
-Well, yeah. -I live in Europe,


00:37:47.660 --> 00:37:49.740
so I cannot comment on that, of course, but...


00:37:49.740 --> 00:37:53.100
It's a little bit different here. But no, but the data service,


00:37:53.100 --> 00:37:55.180
you can just look in here, and this is like, again,


00:37:55.180 --> 00:37:59.180
I like these little projects that don't need anyone's permission to help people.


00:37:59.180 --> 00:38:01.420
Like, that stuff, I'm like, "This is good stuff."


00:38:01.420 --> 00:38:04.620
-Yeah. -And the thing that I also really like about it is...


00:38:04.620 --> 00:38:08.620
It's really just sending you a text message with air quality information


00:38:08.620 --> 00:38:10.620
and enough information, and that's good.


00:38:10.700 --> 00:38:14.940
It's not like they're trying to make like a giant predictive model on top of this or anything like that


00:38:14.940 --> 00:38:19.580
They're just really doing enough and enough is plenty. Like that's the thing I really love about this little demo


00:38:19.580 --> 00:38:25.260
um, of course i'm using rasa which is great, but this is the kind of stuff that


00:38:25.260 --> 00:38:28.460
this is why I get up in the morning projects like this


00:38:28.460 --> 00:38:31.980
Yeah, fantastic


00:38:31.980 --> 00:38:34.940
Yeah, I I love it that's a really good one


00:38:34.940 --> 00:38:38.060
Brian is that it?


00:38:38.060 --> 00:38:41.260
Yeah, that's it. That's our six items.


00:38:41.260 --> 00:38:44.060
Any extras that you want to talk about?


00:38:44.060 --> 00:38:46.860
-I might have one. -Okay.


00:38:46.860 --> 00:38:50.920
Okay, so I'm totally tooting my own horn here,


00:38:50.920 --> 00:38:53.060
but this is a project I made a little while ago.


00:38:53.060 --> 00:38:55.720
But I think people might like it.


00:38:55.720 --> 00:39:00.400
At some point, it struck me that people were making these machine learning algorithms,


00:39:00.400 --> 00:39:03.000
and they're trying to, on a two-dimensional plane,


00:39:03.000 --> 00:39:06.400
trying to separate the green dots from the red ones from the blue ones.


00:39:06.460 --> 00:39:09.500
I just started wondering, "Why do you need an algorithm


00:39:09.500 --> 00:39:12.860
if you can just maybe draw one?"


00:39:12.860 --> 00:39:15.400
So very typically, you've got these clusters of red points


00:39:15.400 --> 00:39:16.940
and clusters of blue points.


00:39:16.940 --> 00:39:20.840
I just started wondering, maybe all we need is this little user interface element


00:39:20.840 --> 00:39:23.280
that you can load from a Jupyter Notebook.


00:39:23.280 --> 00:39:25.240
And maybe once you've made a drawing,


00:39:25.240 --> 00:39:28.380
it'd be nice if we can just turn it into a scikit-learn model.


00:39:28.380 --> 00:39:32.720
So there's this project called Human Learn that does exactly this.


00:39:32.720 --> 00:39:35.920
It's a tool of little buttons and widgets


00:39:35.980 --> 00:39:39.740
that I've made to just make it easier for you to do your domain knowledge thing


00:39:39.740 --> 00:39:41.420
and turn it into a model.


00:39:41.420 --> 00:39:45.340
So one of the things that it currently features is the ability to draw a model,


00:39:45.340 --> 00:39:49.420
which is great because domain experts can just put their knowledge in here.


00:39:49.420 --> 00:39:54.140
It can do outlier detection as well, because if a point falls outside of one of your drawn circles,


00:39:54.140 --> 00:39:56.140
that also means that it's probably an outlier.


00:39:56.140 --> 00:40:00.300
But it also has a tool in there that allows you to turn any Python function,


00:40:00.300 --> 00:40:03.260
like any custom Python-written function,


00:40:03.260 --> 00:40:05.260
into a scikit-learn compatible tool as well.


00:40:05.260 --> 00:40:08.060
If you can just declare logic in a Python function,


00:40:08.060 --> 00:40:10.760
that can also be a machine learning model from now on.


00:40:10.760 --> 00:40:13.960
There's an extra fancy thing, if people are interested.


00:40:13.960 --> 00:40:17.000
I just made a little blog post about that,


00:40:17.000 --> 00:40:21.460
where I'm using a very advanced coloring technique


00:40:21.460 --> 00:40:23.860
using parallel coordinates.


00:40:23.860 --> 00:40:27.160
It's a very fancy technique. I won't go into too much depth there.


00:40:27.160 --> 00:40:29.720
But what's really cool is that you can basically show


00:40:29.720 --> 00:40:33.000
that a drawn model cannot perform the model


00:40:33.060 --> 00:40:35.360
It's on the Keras Deep Learning blog,


00:40:35.360 --> 00:40:39.140
which I just thought was a very cool feature as well.


00:40:39.140 --> 00:40:40.600
The project's called Human Learn.


00:40:40.600 --> 00:40:43.880
It's just components for inside of Jupyter Notebook


00:40:43.880 --> 00:40:46.420
to make domain knowledge and human learning


00:40:46.420 --> 00:40:48.620
and all that good stuff better.


00:40:48.620 --> 00:40:50.480
Also, with the fairness thing in mind,


00:40:50.480 --> 00:40:55.720
I really like the idea that people can do the exploratory data analysis bit


00:40:55.720 --> 00:40:59.120
and at the same time also work on their first machine learning models and benchmark.


00:40:59.120 --> 00:41:00.260
That's what Human Learn does.


00:41:00.320 --> 00:41:03.240
So if people are sort of curious to play around with that,


00:41:03.240 --> 00:41:07.000
please do, it's open source, PIV installed, please use it.


00:41:07.000 --> 00:41:08.720
- I'm impressed, this is cool.


00:41:08.720 --> 00:41:10.640
That is really cool. - Yeah, right?


00:41:10.640 --> 00:41:12.000
There.


00:41:12.000 --> 00:41:14.120
- Matty out in the live stream asks,


00:41:14.120 --> 00:41:16.360
how does it handle ND data?


00:41:16.360 --> 00:41:18.480
Where N, I guess, is three or larger.


00:41:18.480 --> 00:41:20.680
- Yeah, so you can make, like,


00:41:20.680 --> 00:41:22.040
so if you have four columns,


00:41:22.040 --> 00:41:23.800
you can make two charts with two dimensions.


00:41:23.800 --> 00:41:24.800
That's one way of dealing with it.


00:41:24.800 --> 00:41:25.960
And there's like a little trick


00:41:25.960 --> 00:41:28.320
where you can combine all of your drawings into one thing.


00:41:28.320 --> 00:41:29.520
If you go to the examples though,


00:41:29.520 --> 00:41:31.920
the parallel coordinates chart that you see here,


00:41:31.920 --> 00:41:35.280
that has 30 columns and it works just fine.


00:41:35.280 --> 00:41:37.520
I do think 30 is probably the limit.


00:41:37.520 --> 00:41:40.920
But a parallel coordinates chart, you can make a subselection


00:41:40.920 --> 00:41:44.000
across multiple dimensions, that just works.


00:41:44.000 --> 00:41:48.800
It's really hard to explain a parallel coordinates chart on a podcast, though.


00:41:48.800 --> 00:41:51.240
[LAUGHTER]


00:41:51.240 --> 00:41:54.080
Yeah, so it's a super interactive visualization thing


00:41:54.080 --> 00:41:55.920
with lots of colors and stuff happening.


00:41:55.920 --> 00:41:58.920
Sorry, you have to go to the docs to fully experience that, I guess.


00:41:58.920 --> 00:42:04.320
But again, also, like if you, let's say you work for a fraud office,


00:42:04.320 --> 00:42:07.160
and someone asks you like, "Hey, without looking at any data,


00:42:07.160 --> 00:42:09.160
can you come up with rules that's probably fraud?"


00:42:09.160 --> 00:42:12.600
And you can kind of go, "Yeah, if you're 12, and you earn over a million dollars,


00:42:12.600 --> 00:42:14.800
that's probably weird. Someone should just look at that."


00:42:14.800 --> 00:42:17.400
And the thing is, you can just write down rules that way,


00:42:17.400 --> 00:42:20.560
and that should already be, can already be turned into a machine learning model,


00:42:20.560 --> 00:42:23.640
you don't always need data. And that's the thing I'm trying to cover here,


00:42:23.640 --> 00:42:26.320
like just make it easier for you to declare stuff like that.


00:42:26.320 --> 00:42:28.240
It's a more human approach, I guess.


00:42:28.240 --> 00:42:29.240
Nice.


00:42:29.240 --> 00:42:31.300
Brian, I cut you off. Were you going to say something?


00:42:31.300 --> 00:42:34.500
Oh, one of the things, I don't know if we've covered this already,


00:42:34.500 --> 00:42:39.840
but we've talked about comcode.io a lot on this podcast,


00:42:39.840 --> 00:42:42.760
and you're the person behind it, right?


00:42:42.760 --> 00:42:43.840
Yeah, I am.


00:42:43.840 --> 00:42:47.760
It's been a fun little side project that I've been doing for a year now.


00:42:47.760 --> 00:42:50.700
Yeah, so nice videos. I like how short they are.


00:42:50.700 --> 00:42:51.960
Thanks.


00:42:51.960 --> 00:42:54.660
Now, so the thing I like to hear, people tell me that,


00:42:54.660 --> 00:42:56.640
and that's also the thing that I was kind of going for,


00:42:56.700 --> 00:43:01.820
Like I love the you know those when you watch a video it's like a lightning talk and you learn something in five minutes


00:43:01.820 --> 00:43:06.300
Yeah, oh, that's an amazing feeling like that's the thing. I'm trying to capture there a little bit like if


00:43:06.300 --> 00:43:09.180
if it takes more than five minutes to get a point across then


00:43:09.180 --> 00:43:13.260
I should go on to a different topic, but i'm happy to hear you like it


00:43:13.260 --> 00:43:17.980
Yeah, very cool. How about mike you michael anything extra? Well, I


00:43:17.980 --> 00:43:25.340
Had two now I have three because I was reading the source code of one of pinson's projects there


00:43:25.580 --> 00:43:29.280
as we were talking, and I learned about Fuzzy Wuzzy.


00:43:29.280 --> 00:43:33.300
So Fuzzy Wuzzy was being used


00:43:33.300 --> 00:43:38.260
in that emergency disaster recovery awareness thing.


00:43:38.260 --> 00:43:40.780
And it's fuzzy string matching in Python,


00:43:40.780 --> 00:43:43.420
and it says fuzzy string matching like a boss,


00:43:43.420 --> 00:43:45.740
which you gotta love.


00:43:45.740 --> 00:43:47.460
So it was like slight misspellings


00:43:47.460 --> 00:43:49.620
and plural versus not plural and whatnot.


00:43:49.620 --> 00:43:52.900
And Brian even uses hypothesis,


00:43:52.900 --> 00:43:54.700
which is kind of interesting.


00:43:54.700 --> 00:43:56.420
Yeah, Mpytest.


00:43:56.420 --> 00:43:57.700
Yeah, Mpytest, of course.


00:43:57.700 --> 00:44:01.100
So anyway, that's pretty cool. I just discovered that.


00:44:01.100 --> 00:44:03.820
So Fuzzy Wuzzy is a pretty cool tool.


00:44:03.820 --> 00:44:05.420
The only thing I don't like about it,


00:44:05.420 --> 00:44:07.420
and it's the one thing I do have to mention,


00:44:07.420 --> 00:44:10.100
it is my understanding that Fuzzy Wuzzy is a slur


00:44:10.100 --> 00:44:11.900
in certain regions of the world.


00:44:11.900 --> 00:44:14.140
So in terms of naming a package, they could have done better there,


00:44:14.140 --> 00:44:15.980
but I think they only realized that in hindsight.


00:44:15.980 --> 00:44:17.580
Other than that, there's some cool stuff in there.


00:44:17.580 --> 00:44:19.580
Definitely just...


00:44:19.580 --> 00:44:21.700
When I learned about this, I did make the comment to myself,


00:44:21.700 --> 00:44:24.100
"Okay, I should always acknowledge it whenever I talk about the package."


00:44:24.100 --> 00:44:27.040
But yeah, it's definitely useful stuff in there.


00:44:27.040 --> 00:44:29.100
Fuzzy string matching is a useful problem


00:44:29.100 --> 00:44:30.500
to have a tool for.


00:44:30.500 --> 00:44:31.920
- Yeah, very cool.


00:44:31.920 --> 00:44:35.220
And PyCon, way out in the future,


00:44:35.220 --> 00:44:38.540
2024, 2025 announcement is out.


00:44:38.540 --> 00:44:42.620
So the next two PyCons are already theoretically


00:44:42.620 --> 00:44:44.300
in Salt Lake City.


00:44:44.300 --> 00:44:46.740
So hopefully we actually go to Salt Lake City


00:44:46.740 --> 00:44:49.540
and not just go and we'll virtually imagine


00:44:49.540 --> 00:44:50.380
and it was there, right?


00:44:50.380 --> 00:44:51.220
Like this year.


00:44:52.100 --> 00:44:55.300
But last two years because of the pandemic,


00:44:55.300 --> 00:44:58.780
Pittsburgh lost its opportunity to have PyCon.


00:44:58.780 --> 00:45:00.900
So not just once, but twice.


00:45:00.900 --> 00:45:04.260
So they are rescheduling the next one back into Pittsburgh.


00:45:04.260 --> 00:45:08.060
So folks there will be able to go and be part of PyCon.


00:45:08.060 --> 00:45:09.100
- That's pretty cool.


00:45:09.100 --> 00:45:11.060
So because of Corona,


00:45:11.060 --> 00:45:13.700
they've now been able to plan four years ahead of the way.


00:45:13.700 --> 00:45:14.540
- Exactly.


00:45:14.540 --> 00:45:16.900
Everything's upside down now.


00:45:16.900 --> 00:45:20.200
And then also I just wanna give a quick shout out


00:45:20.200 --> 00:45:22.640
to an episode that I think is coming out this week


00:45:22.640 --> 00:45:23.460
on Talk Python.


00:45:23.460 --> 00:45:27.240
I'm pretty sure that's the schedule called codecarbon.io.


00:45:27.240 --> 00:45:30.660
And it is a, let's see if I can pull it up here.


00:45:30.660 --> 00:45:33.520
It is both a dashboard that lets you look


00:45:33.520 --> 00:45:37.480
at the carbon generation, the CO2 footprint


00:45:37.480 --> 00:45:39.680
of your machine learning models,


00:45:39.680 --> 00:45:43.160
as you specifically around the training of the models.


00:45:43.160 --> 00:45:45.820
So what you do is you pip install somewhere in here,


00:45:45.820 --> 00:45:48.800
you pip install this emission tracker,


00:45:48.800 --> 00:45:52.360
and then you just say, start tracking, train, stop tracking.


00:45:52.360 --> 00:45:55.120
It uses your location, your data center,


00:45:55.120 --> 00:45:58.600
the local energy grid, the sources of energy from all that.


00:45:58.600 --> 00:46:00.460
And it'll say like, oh, if you actually switch


00:46:00.460 --> 00:46:05.360
to say the Oregon AWS data center from Virginia,


00:46:05.360 --> 00:46:06.520
you'd be using more,


00:46:06.520 --> 00:46:10.320
you would be using more hydroelectric


00:46:10.320 --> 00:46:12.640
rather than, I don't know, gas or whatever, right?


00:46:12.640 --> 00:46:15.800
So just we were talking about some of the ethics


00:46:15.800 --> 00:46:17.480
and cool things that we should be paying attention to.


00:46:17.480 --> 00:46:23.080
I feel like the sort of energy impact of model training might be worth looking at as well.


00:46:23.080 --> 00:46:27.720
So I totally agree with model training. I've been wondering about this other thing, though,


00:46:27.720 --> 00:46:31.400
and that's testing on GitHub. Like if you think about some of these CI pipelines,


00:46:31.400 --> 00:46:35.720
they can be big too. Like I've heard projects that take like an hour on every commit.


00:46:35.720 --> 00:46:38.120
I'd be curious to run this on that stuff as well.


00:46:38.120 --> 00:46:44.520
Yeah, well, you could turn on, you could employ this as part of your CI/CD.


00:46:44.520 --> 00:46:47.780
It doesn't really have to do with model training per se,


00:46:47.780 --> 00:46:51.460
but it does things like when you train models that use a GPU,


00:46:51.460 --> 00:46:55.120
it'll actually ask the GPU for the electrical current.


00:46:55.120 --> 00:46:56.320
>> Right.


00:46:56.320 --> 00:46:58.160
>> It goes down into the hardware.


00:46:58.160 --> 00:46:59.760
>> That's a fancy feature.


00:46:59.760 --> 00:47:02.480
>> It goes down to the CPU level,


00:47:02.480 --> 00:47:03.860
the CPU level voltage,


00:47:03.860 --> 00:47:05.040
and all sorts of low.


00:47:05.040 --> 00:47:06.660
It's not just, well, it ran for this long,


00:47:06.660 --> 00:47:09.760
so it's this. It's really detailed.


00:47:09.760 --> 00:47:12.320
That said, I suspect you could actually answer


00:47:12.320 --> 00:47:15.960
the same question on a CI, right?


00:47:15.960 --> 00:47:18.200
It would just say, well, it looks like you're training on a CPU.


00:47:18.200 --> 00:47:20.840
[LAUGHTER]


00:47:20.840 --> 00:47:22.040
>> Yeah, true.


00:47:22.040 --> 00:47:25.360
But it's a nice way to be conscious about compute times and stuff.


00:47:25.360 --> 00:47:25.840
So that's--


00:47:25.840 --> 00:47:26.360
>> Yeah.


00:47:26.360 --> 00:47:30.040
And what's cool is it has the dashboard that actually lets you explore.


00:47:30.040 --> 00:47:33.120
Like, well, if I were to shift it to Europe rather than train in the US,


00:47:33.120 --> 00:47:37.320
which who really cares where it trains, what difference would that have?


00:47:37.320 --> 00:47:41.440
>> Look at how green Paraguay is for your hosting.


00:47:41.440 --> 00:47:48.560
Yeah, that's incredible. I suspect a lot of waterfalls. I know that's countries down there have insane amounts of hydro


00:47:48.560 --> 00:47:52.400
like chile, maybe I can't remember exactly but yeah, there's yeah


00:47:52.400 --> 00:47:57.760
And you see and you see iceland as well and it's probably because of the volcanoes and warmth and heat and yeah the geo. Yeah


00:47:57.760 --> 00:47:59.520
Yeah


00:47:59.520 --> 00:48:00.720
All right


00:48:00.720 --> 00:48:02.400
Brian, you got anything?


00:48:02.400 --> 00:48:04.720
No, not this week. How about we do a joke?


00:48:04.720 --> 00:48:07.520
Sounds good. So, uh


00:48:10.080 --> 00:48:12.960
It's been a while since I've been to a strongest man competition.


00:48:12.960 --> 00:48:15.280
World's strongest man.


00:48:15.280 --> 00:48:18.400
You know, like maybe one of those things where you pick up like a telephone pole


00:48:18.400 --> 00:48:20.400
and you have to carry this throw it as far as you can,


00:48:20.400 --> 00:48:24.400
or you lift like the heaviest barbells, or like you carry huge rocks some distance.


00:48:24.400 --> 00:48:26.800
So here's one of those things.


00:48:26.800 --> 00:48:32.000
There's like three judges, a bunch of people who look way over pumped.


00:48:32.000 --> 00:48:34.720
They're all flexing, getting ready.


00:48:34.720 --> 00:48:39.360
The first one is this person carrying a huge rock, sweating clearly,


00:48:39.360 --> 00:48:43.040
And the judges are they're not super impressed. They give a five a two and a six


00:48:43.040 --> 00:48:45.680
Then there's another one lifting this, you know


00:48:45.680 --> 00:48:51.440
500 pound barbell over his head says eight seven and six is their score and then there's this particularly not


00:48:51.440 --> 00:48:54.960
overly strong looking person here it says


00:48:54.960 --> 00:49:01.360
I don't code. I don't use google encoding. Wow, so strong the judges give them straight tens


00:49:01.360 --> 00:49:07.840
And and he's he's also being like really sincere like his hand over his heart


00:49:08.400 --> 00:49:11.300
Oh, yeah, like it's very humble. Yeah, exactly


00:49:11.300 --> 00:49:15.440
All right, well that that's what I got for you


00:49:15.440 --> 00:49:20.400
Take it take it for what you will that's pretty good. Just stack overflow


00:49:20.400 --> 00:49:25.600
Yeah. Yeah. Well, I feel like stack overflow would be we give take it to 11. Honestly


00:49:25.600 --> 00:49:29.120
I don't use stack overflow now


00:49:29.120 --> 00:49:31.920
Yeah


00:49:31.920 --> 00:49:34.480
Definitely that's funny


00:49:36.080 --> 00:49:40.720
Well, thanks for that. You're usually pretty good about finding our jokes. I appreciate it.


00:49:40.720 --> 00:49:44.320
And thanks, Vincent, for coming on the show.


00:49:44.320 --> 00:49:47.040
Thanks for having me. It's fun.


00:49:47.040 --> 00:49:48.880
I think that's a wrap.


00:49:48.880 --> 00:49:51.840
That is. Thanks, Brian. Bye, Vincent.


00:49:51.840 --> 00:49:55.280
Y'all have a good one.

