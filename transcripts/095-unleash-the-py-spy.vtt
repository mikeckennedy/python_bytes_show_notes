WEBVTT

00:00:00.001 --> 00:00:05.020
Hello and welcome to Python Bytes, where we deliver Python news and headlines directly to your earbuds.

00:00:05.020 --> 00:00:10.340
This is episode 95, recorded September 12th, 2018. I'm Michael Kennedy.

00:00:10.340 --> 00:00:11.280
And I'm Brian Huckett.

00:00:11.280 --> 00:00:13.540
Hey, Brian. How are you doing this fine, fine Wednesday?

00:00:13.540 --> 00:00:14.700
I am excellent.

00:00:14.700 --> 00:00:17.660
Nice. It's also excellent that Datadog is sponsoring a show.

00:00:17.660 --> 00:00:21.160
So before getting further, tell them thank you. Pythonbytes.fm slash Datadog.

00:00:21.160 --> 00:00:25.140
It's a cool shirt if you go there and follow along. We'll talk more about that later.

00:00:25.140 --> 00:00:30.260
You know, I feel like summer's coming to an end, and I've been quite lazy all summer.

00:00:30.260 --> 00:00:34.940
I'm not sure I'm ready to get back into the main swing of things, but it's upon us.

00:00:34.940 --> 00:00:38.240
Yeah. And do you know who else is lazy? Programmers are lazy.

00:00:38.240 --> 00:00:41.360
Productively lazy. They put lazy to good use.

00:00:41.360 --> 00:00:42.580
Yes.

00:00:42.580 --> 00:00:43.820
They make lazy a virtue.

00:00:43.820 --> 00:00:51.640
And so this was our segue from nothing into the first item, which is Dataset.

00:00:51.980 --> 00:00:58.520
And Dataset is a Python package that bills itself as databases for lazy people.

00:00:58.520 --> 00:01:03.340
And this is actually something I totally want to try because it looks fun.

00:01:03.340 --> 00:01:05.840
Their premise is programmers are lazy.

00:01:05.840 --> 00:01:09.120
Oh, it says, first, I'll just read some of the top.

00:01:09.120 --> 00:01:13.740
Although managing data in relational databases has plenty of benefits,

00:01:13.740 --> 00:01:17.920
they're rarely used in day-to-day work with small and medium-scale datasets.

00:01:17.920 --> 00:01:18.960
But why is that?

00:01:19.200 --> 00:01:22.840
It's because people are lazy, and they'll throw it in JSON or CSV instead.

00:01:22.840 --> 00:01:25.080
Oh, they say the answer is programs are lazy.

00:01:25.080 --> 00:01:26.880
They'll use the easy solution.

00:01:26.880 --> 00:01:28.900
And I guess I can't disagree.

00:01:28.900 --> 00:01:33.860
I've used JSON format as essentially a local database before.

00:01:33.860 --> 00:01:35.440
But this is kind of cool.

00:01:35.440 --> 00:01:40.360
This is what it is, is that it's built on top of Alchemy.

00:01:40.740 --> 00:01:46.220
So it's built on top of SQLAlchemy, so it can work with any database or a SQL-style database.

00:01:46.220 --> 00:01:47.880
And it's just really easy.

00:01:47.880 --> 00:01:51.160
It looks kind of like a NoSQL.

00:01:51.160 --> 00:01:54.040
It's kind of hard to describe, of course, over the air.

00:01:54.040 --> 00:01:57.240
But it's pretty simple and worth checking out, I think.

00:01:57.240 --> 00:01:57.840
Yeah, I like it.

00:01:57.840 --> 00:02:01.000
It does automatic schema creation, upshirts.

00:02:01.000 --> 00:02:04.180
It has query helpers, like distinct and stuff like that.

00:02:04.180 --> 00:02:11.280
So if you were to say, I'm just going to use like an in-memory dictionary or other things like that, it's kind of nice that it helps with some of those things.

00:02:11.280 --> 00:02:14.660
So you just said a couple terms that I don't even know what those are.

00:02:14.660 --> 00:02:16.100
So upcert.

00:02:16.100 --> 00:02:21.000
Upcert is I have a record, and I'm going to try to save it to the database.

00:02:21.140 --> 00:02:25.160
If it does not exist in the database, an update would fail, right?

00:02:25.160 --> 00:02:29.220
But if it already exists, an insert would fail because it would be a duplicate key.

00:02:29.220 --> 00:02:33.600
And upcert says, hey, data access layer, take this thing and save it.

00:02:33.600 --> 00:02:35.400
If it doesn't exist, put it in there as a new thing.

00:02:35.400 --> 00:02:38.140
If it does, make an update and set the values to the new one.

00:02:38.140 --> 00:02:38.480
Okay.

00:02:38.480 --> 00:02:40.680
And it also deals with sparse stuff.

00:02:40.680 --> 00:02:45.000
So one of their initial examples is, let's say you've got people or something.

00:02:45.000 --> 00:02:49.300
And in the first person, you give them a name and an age, and you can insert that.

00:02:49.680 --> 00:02:53.540
The second person comes along, and you give them a name and age and a gender.

00:02:53.540 --> 00:02:57.440
And then you can search easily.

00:02:57.440 --> 00:03:02.300
And yeah, like you said, it deals with the schema for you already, and you don't have to deal with that.

00:03:02.300 --> 00:03:07.420
Yeah, and the example that you have in the show notes here uses SQLite as the back-end database,

00:03:07.420 --> 00:03:11.040
but it uses the memory connection version.

00:03:11.040 --> 00:03:13.820
So you can just load it up with data and then query it and work with it.

00:03:13.820 --> 00:03:15.760
And then when your app shuts down, it just goes away.

00:03:15.760 --> 00:03:19.300
Maybe you output stuff to a JSON file or whatever.

00:03:19.560 --> 00:03:21.820
So you don't even have to store the database necessarily.

00:03:21.820 --> 00:03:24.780
Yeah, to be able to use some queries on information.

00:03:24.780 --> 00:03:25.440
That's interesting.

00:03:25.440 --> 00:03:32.520
But you can also just play with it this way and then turn it into a file-stored fileback database as well,

00:03:32.520 --> 00:03:34.680
even with SQLite or with something else.

00:03:34.680 --> 00:03:35.200
Yeah, absolutely.

00:03:35.200 --> 00:03:36.580
Yeah, it's a good find.

00:03:36.580 --> 00:03:37.500
It's quite interesting.

00:03:37.500 --> 00:03:38.040
I like it.

00:03:38.040 --> 00:03:38.200
Yeah.

00:03:38.200 --> 00:03:39.600
So I have a question for you, Brian.

00:03:39.600 --> 00:03:40.080
Okay.

00:03:40.080 --> 00:03:46.420
Why is NumPy, not this thing that we're going to talk about next, but NumPy itself, faster than regular Python?

00:03:46.420 --> 00:03:47.140
Do you know?

00:03:47.140 --> 00:03:49.840
I think because it's got stuff compiled in C.

00:03:49.840 --> 00:03:50.280
Exactly.

00:03:50.280 --> 00:03:53.540
Because it's written in C, and it can even do parallelism and stuff.

00:03:53.540 --> 00:03:54.620
It could take advantage of cores.

00:03:54.680 --> 00:03:56.260
Like, my new laptop is ridiculous.

00:03:56.260 --> 00:03:57.220
It has 12 cores.

00:03:57.220 --> 00:03:57.660
Nice.

00:03:57.780 --> 00:03:58.360
That's a lot, right?

00:03:58.360 --> 00:04:01.540
So maybe we could actually take advantage of that with NumPy.

00:04:01.540 --> 00:04:06.100
Well, if you have NumPy code, this thing that I'm going to tell you about takes it to another level.

00:04:06.100 --> 00:04:09.160
It's called Kupy.

00:04:09.160 --> 00:04:11.740
I think it's how you say it, because I think it's based on CUDA.

00:04:11.740 --> 00:04:13.960
So Kupy is what I'm going to go with.

00:04:13.960 --> 00:04:18.380
And its full name is KupyGPUNumpy.

00:04:18.380 --> 00:04:23.600
And the idea is it's an API-compatible library with NumPy.

00:04:23.600 --> 00:04:30.580
So all the NumPy features that NumPy has, you can call the same functions on Kupy, I called it.

00:04:30.580 --> 00:04:41.640
But instead of running on your, you know, 6, 4, whatever cores you have on your machine, it runs them on the GPU cores, which is insane.

00:04:41.640 --> 00:04:42.840
Oh, wow.

00:04:42.840 --> 00:04:43.800
Okay.

00:04:43.800 --> 00:04:44.200
Isn't that cool?

00:04:44.200 --> 00:04:52.440
And I looked, and I did a quick little search, just like, hey, what's like a modern machine learning or data science type GPU you might get?

00:04:52.780 --> 00:04:58.600
So pretty standard one might be the GeForce GTX 1080 Ti.

00:04:58.600 --> 00:04:59.080
Okay.

00:04:59.080 --> 00:05:03.220
These things are getting super expensive because of all the Bitcoin miners and stuff.

00:05:03.220 --> 00:05:09.500
But anyway, you get one of these things, and it has 3,584 cores.

00:05:09.500 --> 00:05:10.460
3,000.

00:05:10.460 --> 00:05:14.820
And you can run your code parallel on all of those.

00:05:14.820 --> 00:05:15.180
Wow.

00:05:15.820 --> 00:05:19.380
So instead of, you know, like having like, oh my gosh, I can't believe I have 12.

00:05:19.380 --> 00:05:20.860
No, you have 3,500.

00:05:20.860 --> 00:05:33.460
And all you have to do, the only line of code you have to change is instead of import NumPy as NP, which is the very common thing that people do, you would say import Kupy as NumPy.

00:05:33.460 --> 00:05:34.780
That's it.

00:05:35.280 --> 00:05:39.680
And now you're running on these CUDA cores doing GPU-backed data science.

00:05:39.680 --> 00:05:40.040
Okay.

00:05:40.040 --> 00:05:41.520
Do you remember what CUDA is?

00:05:41.520 --> 00:05:42.940
I don't know what CUDA stands for.

00:05:42.940 --> 00:05:45.080
I bet it's an acronym because it's all capitalized.

00:05:45.080 --> 00:05:45.880
Yeah.

00:05:47.640 --> 00:05:48.320
There's a lot.

00:05:48.320 --> 00:05:50.860
There's like layers upon layers of acronyms here.

00:05:50.860 --> 00:05:52.880
I don't actually know what CUDA cores are.

00:05:52.880 --> 00:05:53.240
Okay.

00:05:53.240 --> 00:05:53.700
Yeah.

00:05:53.700 --> 00:05:55.240
It didn't mean to put you on this.

00:05:55.240 --> 00:05:58.820
It's the mechanism of parallelism on the GPU, basically.

00:05:58.820 --> 00:05:59.040
Okay.

00:05:59.040 --> 00:06:00.440
Nice.

00:06:00.440 --> 00:06:02.060
But I don't actually know more than that.

00:06:02.060 --> 00:06:02.920
Yeah.

00:06:02.920 --> 00:06:03.720
Isn't that cool?

00:06:03.720 --> 00:06:04.400
I like it.

00:06:04.400 --> 00:06:04.880
Yeah, yeah.

00:06:04.880 --> 00:06:06.100
So it's really cool.

00:06:06.100 --> 00:06:07.320
It has this compatible API.

00:06:07.320 --> 00:06:10.360
I threw a little code sample in the show notes there.

00:06:11.320 --> 00:06:19.280
And if for some reason you're like, you know, I actually need to customize how my code runs on the GPU, which is a thing sometimes people do.

00:06:19.280 --> 00:06:23.000
You can like program against the CUDA cores and CUDA kernels and things like that.

00:06:23.000 --> 00:06:33.940
You can actually embed in your Python code, C++ code, and CUDA pie will actually compile that down to a CUDA binary, which is even cooler.

00:06:33.940 --> 00:06:34.360
Okay.

00:06:34.360 --> 00:06:35.320
I was just curious.

00:06:35.320 --> 00:06:37.160
So I'm really not a hardware guy.

00:06:37.160 --> 00:06:37.900
So bear with me.

00:06:37.900 --> 00:06:39.640
You said you have 12 cores.

00:06:39.640 --> 00:06:41.120
Is it on a laptop that you're running?

00:06:41.280 --> 00:06:41.440
Yeah.

00:06:41.440 --> 00:06:43.400
It's a new MacBook Pro.

00:06:43.400 --> 00:06:46.700
So it's an Intel Core i9 maxed out.

00:06:46.700 --> 00:06:51.100
And it's really six cores that are each hyperthreaded is how it works.

00:06:51.100 --> 00:06:52.460
But the OS sees them as 12.

00:06:52.460 --> 00:06:56.360
So are there GPUs on a normal laptop or on your laptop?

00:06:56.360 --> 00:06:58.840
Or is this GPUs just something that, okay.

00:06:58.840 --> 00:06:59.340
No, no.

00:06:59.340 --> 00:07:02.760
There's a pretty high end one on my MacBook.

00:07:02.760 --> 00:07:05.080
It's not as high end as this.

00:07:05.080 --> 00:07:05.940
Not even close.

00:07:05.940 --> 00:07:08.580
But, you know, maybe half or something, I would guess, in terms of performance.

00:07:08.580 --> 00:07:11.120
That's a pretty bad estimate because I don't really know.

00:07:11.240 --> 00:07:13.060
But yeah, you could run this on a laptop.

00:07:13.060 --> 00:07:13.280
Yeah.

00:07:13.280 --> 00:07:19.300
I'm just curious if the Kupai would speed up things on just on a laptop or something or if

00:07:19.300 --> 00:07:19.580
it would.

00:07:19.580 --> 00:07:20.480
I would think so.

00:07:20.480 --> 00:07:25.000
I mean, you got to have an algorithm that's like well adapted to GPUs.

00:07:25.120 --> 00:07:26.780
But if you did, then I would think so.

00:07:26.780 --> 00:07:26.960
Yeah.

00:07:26.960 --> 00:07:27.440
Okay.

00:07:27.440 --> 00:07:28.560
Well, this is neat.

00:07:28.560 --> 00:07:31.660
For the people that really care about it, really care about it.

00:07:31.660 --> 00:07:32.420
So this is cool.

00:07:32.420 --> 00:07:33.120
Yeah, absolutely.

00:07:33.120 --> 00:07:39.860
And I mean, you can go and get like GPU clusters on AWS or on DigitalOcean or things like that.

00:07:39.860 --> 00:07:40.180
Yeah.

00:07:40.180 --> 00:07:40.940
Okay.

00:07:41.060 --> 00:07:43.560
And so you could actually ship your code up there even if you don't have one.

00:07:43.560 --> 00:07:49.820
Final note on this one is there was a PyCon 2018 presentation on this.

00:07:49.820 --> 00:07:52.920
And so I'm going to link to the presentation as well if people want to watch 30 more minutes

00:07:52.920 --> 00:07:53.220
of this.

00:07:54.720 --> 00:07:55.680
I think I would.

00:07:55.680 --> 00:07:57.040
Yeah, I actually do too.

00:07:57.040 --> 00:07:57.940
It looks really interesting.

00:07:57.940 --> 00:07:58.320
Yeah.

00:07:58.320 --> 00:07:58.940
All right.

00:07:58.940 --> 00:08:00.040
I'm feeling a theme coming on.

00:08:00.040 --> 00:08:04.540
In episode 84, we did touch on somebody called in or called in.

00:08:04.540 --> 00:08:05.940
We actually don't have phone lines.

00:08:05.940 --> 00:08:09.620
Somebody contacted us and said, hey, you should cover pre-commit.

00:08:09.620 --> 00:08:11.140
And we have.

00:08:11.140 --> 00:08:15.260
We did talk about pre-commit in episode 84, but we just sort of talked about what it was.

00:08:15.260 --> 00:08:22.940
But today I ran across this fairly cool article called Automate Python Workflow using pre-commit.

00:08:23.200 --> 00:08:29.220
I like this kind of an article actually of, okay, here's these cool tools using pre-commit

00:08:29.220 --> 00:08:30.100
black and flake.

00:08:30.100 --> 00:08:32.880
How do I put that in my day-to-day workflow?

00:08:32.880 --> 00:08:34.680
And how does it really work?

00:08:34.680 --> 00:08:37.080
And this is from LJ Miranda.

00:08:37.080 --> 00:08:38.260
So good job, LJ.

00:08:38.260 --> 00:08:42.300
It's got a great graphic at the start with telling you that you've got changes.

00:08:42.300 --> 00:08:45.600
When you add something, you go to get add, you go to staging.

00:08:45.600 --> 00:08:50.480
And then when you do a commit, what happens is the pre-commit will intercept that part and

00:08:50.480 --> 00:08:52.980
it kicks off whatever pre-commit hooks you've got.

00:08:53.120 --> 00:08:53.760
Set it up.

00:08:53.760 --> 00:08:58.020
And if all of those pass, then it lets the commit happen.

00:08:58.020 --> 00:09:00.200
And if it doesn't, it kicks it back.

00:09:00.200 --> 00:09:06.120
And then it shows you how to deal with all of the different configuration that is available

00:09:06.120 --> 00:09:07.140
with pre-commit.

00:09:07.140 --> 00:09:08.260
I like this.

00:09:08.260 --> 00:09:09.300
It's a good starter.

00:09:09.300 --> 00:09:13.600
If you're still quite not on board with pre-commit, this is a good article to read.

00:09:13.600 --> 00:09:13.900
Yeah.

00:09:13.900 --> 00:09:15.240
Pre-commit's pretty cool.

00:09:15.240 --> 00:09:20.200
And that's a Python package that you install that then manages all the rest, which I think

00:09:20.200 --> 00:09:20.560
that's great.

00:09:20.720 --> 00:09:21.000
Yeah.

00:09:21.000 --> 00:09:22.800
This article, there's a little video.

00:09:22.800 --> 00:09:25.200
And I think it's an animated GIF or something.

00:09:25.200 --> 00:09:27.440
A little short demo video that runs.

00:09:27.440 --> 00:09:29.220
I don't know how to do this.

00:09:29.220 --> 00:09:29.800
This is neat.

00:09:29.800 --> 00:09:32.040
So it shows it in action.

00:09:32.040 --> 00:09:32.380
Yeah.

00:09:32.380 --> 00:09:32.560
Yeah.

00:09:32.560 --> 00:09:33.100
That's really cool.

00:09:33.360 --> 00:09:36.720
I like those little autoplay GIFs that'll animate stuff.

00:09:36.720 --> 00:09:40.040
Because sometimes it's like, you know, if you could just see it happening, it would be

00:09:40.040 --> 00:09:43.960
so much more easy to grok with little pictures trying to tell me.

00:09:43.960 --> 00:09:44.220
Yeah.

00:09:44.220 --> 00:09:45.500
And I also don't mind.

00:09:45.500 --> 00:09:48.760
Something like that is fine if it has like an actual video to play.

00:09:48.760 --> 00:09:50.540
But don't give me a half hour video.

00:09:50.540 --> 00:09:53.440
A little couple minute video at most is great.

00:09:53.440 --> 00:09:53.820
Yeah.

00:09:53.820 --> 00:09:56.520
A half hour GIF, probably not the way to go.

00:09:57.140 --> 00:09:58.640
I don't even know if you can do that.

00:09:58.640 --> 00:10:03.880
So the way, one way to go that is good though, is to check out Datadog.

00:10:04.480 --> 00:10:08.120
So this episode is sponsored by Datadog, as I said, and I really appreciate them supporting

00:10:08.120 --> 00:10:08.940
the podcast.

00:10:08.940 --> 00:10:14.760
Datadog is a monitoring platform that brings metrics, logs, requests, traces, all that kind

00:10:14.760 --> 00:10:19.120
of stuff into one place across different systems and computers and all sorts of stuff.

00:10:19.120 --> 00:10:24.280
So you can use their trace search and analysis, which lets you break down Python application

00:10:24.280 --> 00:10:29.720
performance using high cardinality attributes like show me what this customer has done across

00:10:29.720 --> 00:10:35.180
my application or show me all the behaviors for this URL and really easy to troubleshoot

00:10:35.180 --> 00:10:35.520
your app.

00:10:35.520 --> 00:10:41.040
So start doing that with your Python apps today with a free trial and Datadog will send you

00:10:41.040 --> 00:10:43.600
a free t-shirt, which has a cute little dog on it.

00:10:43.600 --> 00:10:47.640
So visit them at pythonbytes.fm/Datadog to get started.

00:10:47.640 --> 00:10:51.740
So you were talking earlier about that cool little GIF thing, and I think you can do it with

00:10:51.740 --> 00:10:52.180
Camtasia.

00:10:52.180 --> 00:10:53.240
Like you can record.

00:10:53.240 --> 00:10:53.780
Okay.

00:10:53.780 --> 00:10:55.000
So I think you can do it with Camtasia.

00:10:55.000 --> 00:11:00.000
You can record basically a screencast and export it as a GIF, which is already pretty

00:11:00.000 --> 00:11:00.260
cool.

00:11:00.260 --> 00:11:00.840
Oh, okay.

00:11:00.840 --> 00:11:05.880
But this next item has a really nice little animated GIF thing going on as well because

00:11:05.880 --> 00:11:07.840
it's super good to see it in action.

00:11:07.840 --> 00:11:10.380
So have you heard about PySpy?

00:11:10.380 --> 00:11:11.560
I have not.

00:11:11.560 --> 00:11:15.180
So PySpy is interesting for a couple of reasons.

00:11:15.180 --> 00:11:19.040
It's interesting because it's a cool tool that people can use in some places that they

00:11:19.040 --> 00:11:20.600
could not previously do so.

00:11:21.020 --> 00:11:25.240
It's a Python profiler, so you can hook it up to your Python application and it'll tell

00:11:25.240 --> 00:11:30.200
you where your Python app is spending its time, what functions and what it's doing and things

00:11:30.200 --> 00:11:30.680
like that.

00:11:30.680 --> 00:11:35.580
And it acts kind of like the Unix top command, which will take over your screen and it'll

00:11:35.580 --> 00:11:38.820
show you a list that's kind of updating every couple of seconds what's happening.

00:11:38.820 --> 00:11:39.240
Okay.

00:11:39.240 --> 00:11:39.840
That's pretty cool.

00:11:39.840 --> 00:11:46.260
So I can hook up this profiler and it'll live show me sort of the equivalent of like a process

00:11:46.260 --> 00:11:48.120
report, like a CPU usage report.

00:11:48.120 --> 00:11:51.760
But it'll say right now you have these various functions that have run recently and here

00:11:51.760 --> 00:11:54.440
like we'll put the most expensive ones on top, things like that.

00:11:54.440 --> 00:11:54.820
Oh, neat.

00:11:54.820 --> 00:11:55.440
That's cool, right?

00:11:55.440 --> 00:11:59.020
And so you can watch that little graph, that little GIF thing and see it going.

00:11:59.020 --> 00:12:02.720
This is written by Ben Fredrickson and it's just taken off.

00:12:02.720 --> 00:12:05.020
I think it was started in July or something like that.

00:12:05.020 --> 00:12:06.560
It's already got 2000 GitHub stars.

00:12:06.560 --> 00:12:12.020
So what's even cooler though is it'll let you visualize your Python's app's time without

00:12:12.020 --> 00:12:14.720
restarting or modifying your code in any way.

00:12:14.960 --> 00:12:19.200
And it can attach to running processes and then start to profile them.

00:12:19.200 --> 00:12:19.900
Oh, nice.

00:12:19.900 --> 00:12:26.000
So normally profiling happens by I run a profiler, which runs my code, which does a bunch of stuff.

00:12:26.000 --> 00:12:31.080
Or maybe I reverse, I'll write some code, I'll import C profile and I'll call a function,

00:12:31.080 --> 00:12:33.500
start profile, save profile, export, et cetera.

00:12:33.500 --> 00:12:33.760
Right?

00:12:33.760 --> 00:12:34.980
Like you, it's really invasive.

00:12:35.300 --> 00:12:39.600
So if you do it from the outside, like the profiler runs your app, you can't do it in

00:12:39.600 --> 00:12:39.900
production.

00:12:39.900 --> 00:12:41.640
It makes it slow, all sorts of stuff.

00:12:41.640 --> 00:12:44.820
If you do it the other way, you're doing all sorts of writing code to change it.

00:12:44.820 --> 00:12:47.720
This, you just say, Hey, there's a random Python program.

00:12:47.720 --> 00:12:50.260
I'm going to go profile that and it'll just attach to it.

00:12:50.260 --> 00:12:50.880
Nice.

00:12:50.880 --> 00:12:51.380
Yeah.

00:12:51.380 --> 00:12:52.860
You can just give it a process ID.

00:12:52.860 --> 00:12:53.480
Yeah, exactly.

00:12:53.480 --> 00:12:54.520
Give it a PID.

00:12:54.520 --> 00:12:58.700
And what's cool is because of that, that means you can use it in production.

00:12:59.120 --> 00:13:04.600
I could log into my web server that's getting pounded on, not responding correctly or whatever.

00:13:04.600 --> 00:13:10.420
And I could actually begin to profile it without like wrecking my thing or slowing it down or

00:13:10.420 --> 00:13:13.800
restarting it or whatever, or any long running process.

00:13:13.800 --> 00:13:17.940
Like while the problem is happening, you can just attach to it and figure out what's wrong.

00:13:17.940 --> 00:13:18.820
That's the key thing.

00:13:18.820 --> 00:13:22.360
Cause maybe restarting it, rerunning it, it takes like four hours to get into that weird state.

00:13:22.360 --> 00:13:23.100
You never know, right?

00:13:23.100 --> 00:13:23.460
Yeah.

00:13:23.460 --> 00:13:24.320
Oh yeah.

00:13:24.320 --> 00:13:25.000
This is cool.

00:13:25.000 --> 00:13:25.540
Sweet.

00:13:25.540 --> 00:13:26.300
That's pretty trick.

00:13:26.620 --> 00:13:30.280
So it's written in Rust actually, but it's pip installable.

00:13:30.280 --> 00:13:32.440
So all sorts of cool things.

00:13:32.440 --> 00:13:35.980
And then he even goes into, Ben goes into how does it work?

00:13:35.980 --> 00:13:38.200
So there's a section on how does PySpy work?

00:13:38.200 --> 00:13:41.980
So I'll just read you this and tell me if this sounds like a program you would have written.

00:13:41.980 --> 00:13:43.460
It's not what I would have.

00:13:43.460 --> 00:13:51.780
PySpy works by directly reading the memory of the Python program using process VM Red V system

00:13:51.780 --> 00:13:56.920
call Linux or VM read on OS 10 or read process memory on windows.

00:13:56.920 --> 00:13:59.560
And then it just analyzes the memory over and over.

00:13:59.560 --> 00:14:01.380
That's crazy, right?

00:14:01.380 --> 00:14:07.100
But it knows enough about Python to go, well, that means X.

00:14:07.100 --> 00:14:08.460
And it just, you know, off it goes.

00:14:08.460 --> 00:14:12.020
So there's a bunch of more details on how he actually makes it work.

00:14:12.020 --> 00:14:13.820
I'll link to that section as well.

00:14:14.040 --> 00:14:15.360
It's a pretty cool profiler.

00:14:15.360 --> 00:14:20.160
And I really like the attach to running processes without affecting them.

00:14:20.160 --> 00:14:21.860
That's pretty unique, I think.

00:14:21.860 --> 00:14:22.960
And so I wanted to highlight it.

00:14:22.960 --> 00:14:23.460
Yeah.

00:14:23.460 --> 00:14:24.260
Nice.

00:14:24.260 --> 00:14:29.060
And it can do icicle graphs, which I don't know why that would be neat, but it looks neat.

00:14:29.060 --> 00:14:29.800
Yeah.

00:14:29.800 --> 00:14:30.340
Those are cool.

00:14:30.340 --> 00:14:34.620
I get sometimes, you know, just visually some things are really out of whack.

00:14:34.620 --> 00:14:36.300
You're like, what is that big bar from?

00:14:36.300 --> 00:14:38.020
Oh, that's a radot sort.

00:14:38.100 --> 00:14:39.440
Why are we calling that a thousand times?

00:14:39.440 --> 00:14:40.260
Yeah.

00:14:40.260 --> 00:14:41.580
Things like that.

00:14:41.580 --> 00:14:42.880
Let's just sort it once.

00:14:42.880 --> 00:14:43.500
All right.

00:14:43.500 --> 00:14:44.280
What do you got for us next?

00:14:44.280 --> 00:14:48.020
I've got SymPy, which is just sort of fun.

00:14:48.020 --> 00:14:53.400
SymPy is a, it's a, well, I'm just going to read it, read the little bit here too.

00:14:53.400 --> 00:14:55.020
Symbolic computation.

00:14:55.020 --> 00:14:57.300
So like you're in math class or something.

00:14:57.300 --> 00:15:02.560
We realized early on with programming that you can, if you punch things into the calculator

00:15:02.560 --> 00:15:07.120
too fast, it just mucks things up because you have rounding and various things like that.

00:15:07.120 --> 00:15:11.760
So symbolic computation deals with the computation of mathematical objects symbolically.

00:15:11.760 --> 00:15:16.100
This means that mathematical objects are represented exactly, not approximately.

00:15:16.100 --> 00:15:22.240
And math expressions are with unevaluated variables are left in symbolic form.

00:15:22.240 --> 00:15:25.520
And SymPy allows you to do that with Python.

00:15:25.520 --> 00:15:29.020
And it's sort of blasted cool.

00:15:29.340 --> 00:15:37.720
I've got a little example of doing an integration of, of the sine of X squared over negative infinity

00:15:37.720 --> 00:15:38.900
to positive infinity.

00:15:38.900 --> 00:15:41.220
And it will tell you what the answer is.

00:15:41.220 --> 00:15:48.400
And these sorts of symbolic math manipulations for a lot of people, boy, if I had to do this

00:15:48.400 --> 00:15:50.040
by hand, I'd be in trouble.

00:15:50.040 --> 00:15:51.760
I did not do that well in math.

00:15:51.980 --> 00:15:55.480
And so being able to do this programmatically is cool.

00:15:55.480 --> 00:15:58.700
And the introduction and the website is pretty awesome too.

00:15:58.700 --> 00:16:03.220
It has a bunch of live, it's got engine in the back that runs it.

00:16:03.220 --> 00:16:09.500
So you can try the examples out and pop up a little window and, and do it interactively.

00:16:09.820 --> 00:16:10.840
So this is neat.

00:16:10.840 --> 00:16:11.260
Yeah.

00:16:11.260 --> 00:16:13.560
There's a ton of cool stuff that comes out of this.

00:16:13.560 --> 00:16:18.120
So for example, you can say X comma Y equals symbols X and Y.

00:16:18.120 --> 00:16:23.280
And then after that, you can do algebraic expressions, like truly algebraically.

00:16:23.280 --> 00:16:27.960
So like expression equals X plus two Y, not in quotes or anything, just like as if it were

00:16:27.960 --> 00:16:28.740
regular math.

00:16:28.740 --> 00:16:35.020
And then you could like add one to that expression and it'll reform the equation and stuff like

00:16:35.020 --> 00:16:35.320
that.

00:16:35.320 --> 00:16:37.320
You can ask it to do integration.

00:16:37.380 --> 00:16:42.180
Like the example you have in our show notes is to integrate sine of X squared from a minus

00:16:42.180 --> 00:16:43.220
infinity to positive infinity.

00:16:43.220 --> 00:16:46.540
Instead of giving you the answer of, oh my gosh, what is that?

00:16:46.540 --> 00:16:49.220
Like 1.5 dot, dot, dot, dot.

00:16:49.220 --> 00:16:52.440
You know, it just says that's square root of two pi over two.

00:16:52.440 --> 00:16:55.340
Like the exact answer.

00:16:55.340 --> 00:16:56.320
That is pretty awesome.

00:16:56.320 --> 00:17:01.240
You know, we just wrecked the whole math experience for so many of our listeners who are students.

00:17:01.240 --> 00:17:01.960
They're like, you know what?

00:17:01.960 --> 00:17:04.160
That calculus class, I just solved that problem.

00:17:05.420 --> 00:17:08.140
Well, I would have loved this while I was taking calculus.

00:17:08.140 --> 00:17:09.940
Yeah, for sure.

00:17:09.940 --> 00:17:10.660
Yeah.

00:17:10.660 --> 00:17:11.700
You could totally check your work.

00:17:11.700 --> 00:17:12.800
Like there's no answers in the book.

00:17:12.800 --> 00:17:13.420
Oh yeah, really?

00:17:13.420 --> 00:17:14.000
Hold on.

00:17:14.000 --> 00:17:18.860
That's pretty awesome.

00:17:18.860 --> 00:17:22.220
So if you can take your laptop to your tests, you're set.

00:17:22.220 --> 00:17:22.760
Yeah.

00:17:22.760 --> 00:17:23.520
Probably not likely.

00:17:23.520 --> 00:17:24.520
All right.

00:17:25.060 --> 00:17:27.940
So this next one that I found, Brian, it's pretty cool.

00:17:27.940 --> 00:17:32.460
So something that I'm going to, I've been digging into lately behind the scenes, and I'm going

00:17:32.460 --> 00:17:36.620
to be talking more and more about probably in the next few weeks is async programming in

00:17:36.620 --> 00:17:36.880
Python.

00:17:36.880 --> 00:17:40.600
Like I've really been doing a lot with that lately and we'll have some cool stuff to share

00:17:40.600 --> 00:17:41.200
pretty soon.

00:17:41.200 --> 00:17:45.780
But that means I'm running across all this cool async stuff.

00:17:45.900 --> 00:17:50.420
So you've heard of WSGI, WSGI, which is the web service gateway interface.

00:17:50.420 --> 00:17:53.680
That's like how Pyramid, Flask, Django, all those things work.

00:17:53.680 --> 00:18:00.000
None of them do a great job of supporting async programming because fundamentally this WSGI

00:18:00.000 --> 00:18:01.880
interface is synchronous.

00:18:01.880 --> 00:18:02.980
It can't be made async.

00:18:02.980 --> 00:18:04.100
Yeah.

00:18:04.180 --> 00:18:10.320
So there's this other framework called ASGI for async gateway interface, I guess, that

00:18:10.320 --> 00:18:13.520
allows these frameworks to be asynchronous.

00:18:13.520 --> 00:18:19.700
So the thing I'm talking about this week is Starlet, which is an ASGI web framework.

00:18:19.700 --> 00:18:24.940
And I like its little subtitle, the little ASGI framework that shines.

00:18:24.940 --> 00:18:27.380
It's cute.

00:18:27.380 --> 00:18:28.780
It is cute.

00:18:28.780 --> 00:18:35.080
So it's basically intended to build high performance asyncio services.

00:18:35.080 --> 00:18:40.060
So if you have anything that talks to a database, to caches, to file systems, things like that,

00:18:40.060 --> 00:18:45.040
even calls other web services or microservices, super easy to build.

00:18:45.040 --> 00:18:49.320
The API is basically Flask, like a Flask-ish API.

00:18:49.320 --> 00:18:52.320
And you create like a web method.

00:18:52.320 --> 00:18:54.900
You say async def regular view method.

00:18:54.900 --> 00:18:56.340
And you go do a bunch of stuff.

00:18:56.340 --> 00:18:59.800
And it has cool support for like response types.

00:18:59.800 --> 00:19:03.860
So you can have a file response object that you just send back to the framework that's

00:19:03.860 --> 00:19:08.340
based on async AIO files, which is an asyncio file based thing.

00:19:08.340 --> 00:19:10.340
And there's a lot of nice integration like that.

00:19:10.340 --> 00:19:10.720
Okay.

00:19:10.720 --> 00:19:14.060
You're just interested in this or do you have an application that you're going to try to?

00:19:14.060 --> 00:19:16.200
No, I'm building a course on it.

00:19:16.200 --> 00:19:16.820
Oh, okay.

00:19:16.820 --> 00:19:21.760
Trying to make a nice, well-rounded async concurrent programming Python course.

00:19:21.760 --> 00:19:22.860
Oh, well, yeah.

00:19:22.860 --> 00:19:25.060
So I've been building tons of little apps and stuff.

00:19:25.060 --> 00:19:26.320
So here we go.

00:19:26.320 --> 00:19:26.920
Here's one of them.

00:19:26.920 --> 00:19:27.100
Cool.

00:19:27.100 --> 00:19:31.620
If you want to build an app that is way more scalable, you know, 10 times more scalable

00:19:31.620 --> 00:19:37.300
than regular web apps on the same hardware and whatnot, it's pretty easy to do if mostly

00:19:37.300 --> 00:19:40.240
what that web app is doing is waiting, right?

00:19:40.240 --> 00:19:46.400
You can just, you know, basically the asyncio web frameworks can just adapt to that more

00:19:46.400 --> 00:19:48.260
easily because they're not blocking while they're waiting.

00:19:48.260 --> 00:19:52.020
Also discovered a couple of cool things while looking into this.

00:19:52.100 --> 00:19:59.080
One is they say you should install the ultra JSON package, which the pip install command

00:19:59.080 --> 00:19:59.880
was ujson.

00:19:59.880 --> 00:20:06.660
And that is a replace, basically a drop-in replacement for the JSON built-in that is like

00:20:06.660 --> 00:20:09.640
between 50% and three times faster.

00:20:09.640 --> 00:20:12.420
So if you're doing a lot of JSON, you can just use ultra JSON.

00:20:12.420 --> 00:20:13.480
And that's pretty awesome.

00:20:13.480 --> 00:20:14.080
Yeah.

00:20:14.600 --> 00:20:14.940
Okay.

00:20:14.940 --> 00:20:16.300
I have to check that out too.

00:20:16.300 --> 00:20:16.620
Yeah.

00:20:16.620 --> 00:20:21.680
So all you have to do is, you know, import a ujson as JSON.

00:20:21.680 --> 00:20:23.600
And then that like makes your code faster.

00:20:23.600 --> 00:20:25.080
Of course it has to be there, right?

00:20:25.080 --> 00:20:26.140
But that's pretty sweet.

00:20:26.140 --> 00:20:31.440
The other thing is you've maybe heard of G Unicorn for the traditional web frameworks.

00:20:31.440 --> 00:20:37.180
There's a uveacorn, which is based on uvloop and gunicorn, which is also pretty awesome for

00:20:37.180 --> 00:20:38.840
these async web frameworks.

00:20:38.840 --> 00:20:42.340
Well, it's cool.

00:20:42.340 --> 00:20:47.840
And I get the name, but eventually if we, if everybody starts using that, people forget

00:20:47.840 --> 00:20:48.640
where that came from.

00:20:48.640 --> 00:20:50.820
And it's just going to be a weird word, uveacorn.

00:20:50.820 --> 00:20:51.920
I know.

00:20:51.920 --> 00:20:53.560
Uveacorn.

00:20:53.560 --> 00:20:54.500
No, it's uveacorn.

00:20:54.500 --> 00:20:55.900
You got to understand where the name comes from.

00:20:55.900 --> 00:20:56.360
Come on.

00:20:56.360 --> 00:20:57.560
Get it together.

00:20:58.780 --> 00:21:00.000
Well, that's it for our items.

00:21:00.000 --> 00:21:01.700
I do have some extra stuff to share.

00:21:01.700 --> 00:21:02.140
How about you?

00:21:02.140 --> 00:21:04.520
Just one thing I wanted to point out if I remember it.

00:21:04.520 --> 00:21:04.980
Okay, cool.

00:21:04.980 --> 00:21:06.060
I'll go first.

00:21:06.060 --> 00:21:06.620
You can think.

00:21:06.620 --> 00:21:08.300
So really big news.

00:21:08.300 --> 00:21:10.400
You and I, we had a good time at PyCon, right?

00:21:10.400 --> 00:21:10.920
Oh, yeah.

00:21:10.920 --> 00:21:13.600
I can tell you when we're going to have a good time again.

00:21:13.600 --> 00:21:20.220
It's going to be, if we can go to a tutorial, it's May 1st and 2nd.

00:21:20.220 --> 00:21:23.840
If you want to go to talks, it's May 3rd, 4th, and 5th.

00:21:23.840 --> 00:21:27.140
And if you want to do the sprints, it's May 6th, 7th, 8th, and 9th.

00:21:27.140 --> 00:21:30.440
So basically, the announcement is that the PyCon dates are out.

00:21:30.440 --> 00:21:32.280
Yes, and it's not over.

00:21:32.280 --> 00:21:35.100
I don't think it's over Mother's Day this year.

00:21:35.100 --> 00:21:35.900
I hope it's not.

00:21:35.900 --> 00:21:38.260
I hope it's not.

00:21:38.260 --> 00:21:40.760
I also have a quick little follow-up.

00:21:40.760 --> 00:21:42.400
You talked about the pre-commit package.

00:21:42.400 --> 00:21:46.860
Also, another listener, Matthew Lehman, sent in some notes about how his team is using it

00:21:46.860 --> 00:21:53.580
and basically talked about how they're using pre-commit, the Python package,

00:21:53.960 --> 00:22:00.180
so that their Flake 8 and Black and other things that automatically run during continuous integration

00:22:00.180 --> 00:22:03.420
also automatically run when people do Git commits.

00:22:03.420 --> 00:22:08.060
So they have fewer failing builds, which is pretty awesome and has a couple of nice links.

00:22:08.060 --> 00:22:09.120
So I threw that in there at the end.

00:22:09.120 --> 00:22:13.340
And then, finally, you talked about the Gang of Four Patterns last week, right?

00:22:13.340 --> 00:22:13.840
Yeah.

00:22:14.060 --> 00:22:20.700
So John Tosher, I think he's right, sent us some messages pointing out another talk from PyCon AU

00:22:20.700 --> 00:22:23.800
called You Don't Need That, which is pretty cool.

00:22:23.800 --> 00:22:28.260
And it basically talks about how if you study the Gang of Four Patterns,

00:22:28.260 --> 00:22:32.960
a lot of what they were doing was because they were using Smalltalk or Java or C++.

00:22:33.360 --> 00:22:37.520
And in Python, here's a new way that you just basically don't need that pattern.

00:22:37.520 --> 00:22:38.720
So pretty cool talk.

00:22:38.720 --> 00:22:40.520
And that was a link to the video for that.

00:22:40.520 --> 00:22:41.160
Yeah.

00:22:41.160 --> 00:22:43.640
Yeah.

00:22:43.640 --> 00:22:47.360
If you translated the Gang of Four book directly to Python, it would be like a pamphlet.

00:22:47.360 --> 00:22:48.280
That's right.

00:22:48.280 --> 00:22:50.660
Nice.

00:22:50.660 --> 00:22:51.560
Do you remember your item?

00:22:51.560 --> 00:22:52.400
I did not.

00:22:52.400 --> 00:22:53.140
So...

00:22:53.140 --> 00:22:53.480
Oh.

00:22:53.480 --> 00:22:54.240
Save it for next week?

00:22:54.240 --> 00:22:54.460
Yeah.

00:22:54.460 --> 00:22:55.140
Yeah.

00:22:55.140 --> 00:22:55.980
Save it for next week.

00:22:55.980 --> 00:22:57.200
Yeah.

00:22:57.200 --> 00:22:58.580
We'll do this again next week, right?

00:22:58.580 --> 00:22:59.000
Yeah.

00:22:59.000 --> 00:23:00.600
Maybe we should just do it every week.

00:23:00.600 --> 00:23:00.900
Yeah.

00:23:00.900 --> 00:23:01.340
All right.

00:23:01.600 --> 00:23:01.960
Deal.

00:23:01.960 --> 00:23:02.580
We'll do it every week.

00:23:02.580 --> 00:23:03.300
Okay.

00:23:03.300 --> 00:23:03.760
Cool.

00:23:03.760 --> 00:23:04.120
Cool.

00:23:04.120 --> 00:23:04.360
All right.

00:23:04.360 --> 00:23:05.860
Well, thanks for doing the show this week.

00:23:05.860 --> 00:23:06.540
Thank you.

00:23:06.540 --> 00:23:07.200
You bet.

00:23:07.200 --> 00:23:07.400
Bye.

00:23:07.400 --> 00:23:07.600
Bye.

00:23:07.600 --> 00:23:10.300
Thank you for listening to Python Bytes.

00:23:10.300 --> 00:23:12.880
Follow the show on Twitter via at Python Bytes.

00:23:12.880 --> 00:23:15.760
That's Python Bytes as in B-Y-T-E-S.

00:23:15.760 --> 00:23:19.180
And get the full show notes at Pythonbytes.fm.

00:23:19.180 --> 00:23:23.520
If you have a news item you want featured, just visit Pythonbytes.fm and send it our way.

00:23:23.520 --> 00:23:26.220
We're always on the lookout for sharing something cool.

00:23:26.220 --> 00:23:29.620
On behalf of myself and Brian Okken, this is Michael Kennedy.

00:23:30.100 --> 00:23:33.240
Thank you for listening and sharing this podcast with your friends and colleagues.

