
00:00:00.000 --> 00:00:08.480
Hello and welcome to Python bites where we deliver Python news and headlines directly to your earbuds. This is episode 95 recorded September 12th


00:00:08.480 --> 00:00:15.060
2018 I'm Michael Kennedy and I'm Brian. Okay. Hey Brian. How you doing this fine fine Wednesday. I am excellent nice


00:00:15.060 --> 00:00:19.040
It's also excellent that data dog is sponsoring a show. So for getting further tell them


00:00:19.040 --> 00:00:24.020
Thank you, I found by setup m/data dog. It's a cool shirt if you go there and follow along


00:00:24.020 --> 00:00:25.520
We'll talk more about that later


00:00:25.520 --> 00:00:30.240
You know, I've been I feel like summer is coming to an end and I'm I've been quite lazy all summer


00:00:30.240 --> 00:00:34.840
I haven't really I'm not sure I'm ready to get back into the main swing of things, but it's upon us


00:00:34.840 --> 00:00:41.180
Yeah, and you know who else is lazy programmers are lazy productively lazy. They put it into good use


00:00:41.180 --> 00:00:43.920
Yes, they make lazy a virtue


00:00:43.920 --> 00:00:49.200
And so this was our segue from nothing into the first


00:00:49.200 --> 00:00:51.800
item which is a data set and


00:00:52.200 --> 00:00:58.600
And Dataset is a Python package that builds itself as databases for lazy people.


00:00:58.600 --> 00:01:03.440
And this is actually something I totally want to try because it looks fun.


00:01:03.440 --> 00:01:06.000
Their premise is programmers are lazy.


00:01:06.000 --> 00:01:09.200
Oh, it says at first, I'll just read some of the top.


00:01:09.200 --> 00:01:13.880
Although managing data in relational databases has plenty of benefits,


00:01:13.880 --> 00:01:18.200
they're rarely used in day to day work with small and medium scale datasets.


00:01:18.200 --> 00:01:19.000
But why is that?


00:01:19.400 --> 00:01:23.400
it's because people are lazy and they'll throw it in JSON or CSV instead.


00:01:23.400 --> 00:01:25.400
Oh, they say the answer is programs are lazy.


00:01:25.400 --> 00:01:29.400
They'll use the easy solution and I guess I can't disagree.


00:01:29.400 --> 00:01:34.400
I've used JSON format as essentially a local database before.


00:01:34.400 --> 00:01:36.400
But this is kind of cool.


00:01:36.400 --> 00:01:40.400
What it is, is it's built on top of Alchemy.


00:01:40.400 --> 00:01:46.400
So it's built on top of SQLAlchemy so it can work with any database or a SQL style database.


00:01:46.400 --> 00:01:51.400
And it's just really easy. It looks kind of like a NoSQL.


00:01:51.400 --> 00:01:57.400
It's kind of hard to describe, of course, over the air, but it's pretty simple and worth checking out, I think.


00:01:57.400 --> 00:02:04.400
Yeah, I like it. It does automatic schema creation, upserts, has query helpers like distinct and stuff like that.


00:02:04.400 --> 00:02:09.400
So if you were to say, I'm just going to use like an in-memory dictionary or other things like that,


00:02:09.400 --> 00:02:11.400
it's kind of nice that it helps with some of those things.


00:02:11.400 --> 00:02:14.400
So you just said a couple of terms that I don't even know what those are.


00:02:14.400 --> 00:02:21.460
are so absurd absurd is I have a record and I'm going to try to save it to the database.


00:02:21.460 --> 00:02:26.960
If it does not exist in the database and update would fail right but if it already exists


00:02:26.960 --> 00:02:31.480
an insert would fail because it would be a duplicate key and absurd says hey data access


00:02:31.480 --> 00:02:35.640
layer take this thing and save it if it doesn't exist put it in there as a new thing if it


00:02:35.640 --> 00:02:38.440
does make an update and set the values to the new one.


00:02:38.440 --> 00:02:43.520
Okay and it's also deals with sparse stuff so one of their initial examples is let's


00:02:43.520 --> 00:02:49.520
say you've got people or something and then the first person you give them a name and an age and you can insert that.


00:02:49.520 --> 00:02:53.520
The second person comes along and you give them a name and age and a gender.


00:02:53.520 --> 00:03:02.520
And then you can, you know, search easily and it, yeah, like you said, it deals with the schema for you already and you don't have to deal with that.


00:03:02.520 --> 00:03:07.520
Yeah, and the example that you have in the show notes here uses SQLite as the back-end database,


00:03:07.520 --> 00:03:11.160
but it uses the memory connection version.


00:03:11.160 --> 00:03:13.800
So you can just load it up with data and then query and work with it.


00:03:13.800 --> 00:03:16.160
And then when your app shuts down, it just goes away.


00:03:16.160 --> 00:03:19.400
Maybe you output stuff to a JSON file or whatever.


00:03:19.400 --> 00:03:22.040
So you don't even have to store the database necessarily.


00:03:22.040 --> 00:03:25.840
Yeah, to be able to use some queries on information, that's interesting.


00:03:25.840 --> 00:03:29.280
But you can also just play with it this way and then turn it into


00:03:29.280 --> 00:03:32.840
to a file stored file back database as well with


00:03:32.840 --> 00:03:34.680
even with SQLite or with something else.


00:03:34.680 --> 00:03:35.760
Yeah, absolutely.


00:03:35.760 --> 00:03:37.760
It's a good find. It's quite interesting. I like it.


00:03:37.760 --> 00:03:38.760
Yeah.


00:03:38.760 --> 00:03:39.760
So I have a question for you, Brian.


00:03:39.760 --> 00:03:40.760
Okay.


00:03:40.760 --> 00:03:42.760
Why is NumPy, not this thing that we're going to talk about next,


00:03:42.760 --> 00:03:46.760
but NumPy itself faster than regular Python? Do you know?


00:03:46.760 --> 00:03:49.760
I think because it's got stuff compiled in C.


00:03:49.760 --> 00:03:52.760
Exactly, because it's written in C, and it can even do parallelism and stuff.


00:03:52.760 --> 00:03:54.760
It can take advantage of cores.


00:03:54.760 --> 00:03:56.760
My new laptop is ridiculous. It has 12 cores.


00:03:56.760 --> 00:03:57.760
Nice.


00:03:57.760 --> 00:03:58.760
That's a lot, right?


00:03:58.760 --> 00:04:01.760
So maybe we could actually take advantage of that with NumPy.


00:04:01.760 --> 00:04:04.760
Well, if you have NumPy code, this thing that I'm going to tell you about


00:04:04.760 --> 00:04:10.600
takes it to another level. It's called KooPi, I think is how you say it, because I think it's


00:04:10.600 --> 00:04:18.440
based on CUDA. So KooPi is what I'm going to go with. And it's, its full name is KooPi GPU NumPy.


00:04:18.440 --> 00:04:25.360
And the idea is it's a API compatible library with NumPy. So all the NumPy features that it has,


00:04:25.360 --> 00:04:32.800
that NumPy has, you can call the same functions on KooPi, I called it. But instead of running on


00:04:32.800 --> 00:04:39.040
on your, you know, six, four, whatever cores you have on your machine, it runs them on


00:04:39.040 --> 00:04:41.300
the GPU cores, which is insane.


00:04:41.300 --> 00:04:42.300
Oh, wow.


00:04:42.300 --> 00:04:43.300
Okay, cool.


00:04:43.300 --> 00:04:49.080
And I looked, I looked and I did a quick little search, just like, hey, what's like a modern


00:04:49.080 --> 00:04:53.080
machine learning or data science type GPU you might get.


00:04:53.080 --> 00:04:58.760
So pretty standard one might be the GeForce GTX 1080 Ti.


00:04:58.760 --> 00:05:03.400
Okay, these things are getting super expensive because of all the Bitcoin miners and stuff.


00:05:03.400 --> 00:05:12.320
But anyway, you get one of these things and it has 3584 cores.


00:05:12.320 --> 00:05:15.920
And you can run your code parallel on all of those.


00:05:15.920 --> 00:05:19.320
So instead of, you know, like having like, oh my gosh, I can't believe I have 12.


00:05:19.320 --> 00:05:22.000
No, you have 3500.


00:05:22.000 --> 00:05:26.520
And all you have to do, the only line of code you have to change is instead of import numpy


00:05:26.520 --> 00:05:30.200
NumPy as NP, which is the very common thing that people do.


00:05:30.200 --> 00:05:33.760
You would say, "Import CUPI as NumPy."


00:05:33.760 --> 00:05:34.760
That's it.


00:05:34.760 --> 00:05:39.640
And now you're running on these CUDA cores doing GPU-backed data science.


00:05:39.640 --> 00:05:41.600
Okay, do you remember what CUDA is?


00:05:41.600 --> 00:05:43.000
I don't know what CUDA stands for.


00:05:43.000 --> 00:05:45.480
I bet it's an acronym because it's all capitalized.


00:05:45.480 --> 00:05:46.480
Yeah.


00:05:46.480 --> 00:05:47.480
There's a lot.


00:05:47.480 --> 00:05:50.880
There's like layers upon layers of acronyms here.


00:05:50.880 --> 00:05:53.080
I don't actually know what CUDA cores are.


00:05:53.080 --> 00:05:54.080
Okay, yeah.


00:05:54.080 --> 00:05:55.400
I didn't mean to put you on the spot.


00:05:55.400 --> 00:05:58.400
the mechanism of parallelism on the GPU.


00:05:58.400 --> 00:06:00.600
>> Okay. Nice.


00:06:00.600 --> 00:06:02.400
>> But I don't actually know more than that.


00:06:02.400 --> 00:06:03.000
>> Yeah.


00:06:03.000 --> 00:06:03.860
>> Isn't that cool?


00:06:03.860 --> 00:06:04.400
>> I like it.


00:06:04.400 --> 00:06:06.160
>> Yeah. It's really cool.


00:06:06.160 --> 00:06:07.600
It has this compatible API through


00:06:07.600 --> 00:06:11.120
a little code sample in the show notes there.


00:06:11.120 --> 00:06:12.920
For some reason, you're like,


00:06:12.920 --> 00:06:17.340
I actually need to customize how my code runs on the GPU,


00:06:17.340 --> 00:06:19.320
which is a thing sometimes people do.


00:06:19.320 --> 00:06:21.640
You can program against the CUDA cores


00:06:21.640 --> 00:06:23.180
and CUDA kernels and things like that.


00:06:23.180 --> 00:06:32.920
you can actually embed in your python code C++ code and could pie will actually compile that down to a binary.


00:06:32.920 --> 00:06:38.000
Which is even cooler ok i was just curious so i'm really not a hardware guy so bear with me.


00:06:38.000 --> 00:06:46.800
You said you have twelve cores is on a laptop that you're running yeah it's a new macbook pro it's a intel core i nine maxed out.


00:06:46.760 --> 00:06:52.760
It's really six cores that are each hyper-threaded is how it works, but the OS sees them as 12.


00:06:52.760 --> 00:06:58.760
So are there GPUs on a normal laptop or on your laptop or is this GPU just something that...


00:06:58.760 --> 00:07:02.760
No, no, there's a pretty high-end one on my MacBook.


00:07:02.760 --> 00:07:08.760
It's not as high-end as this, not even close, but maybe half or something I would guess in terms of performance.


00:07:08.760 --> 00:07:12.760
That's a pretty bad estimate because I don't really know, but yeah, you could run this on a laptop.


00:07:12.760 --> 00:07:20.440
Yeah, I'm just curious if the Coupie would speed up things on just on a laptop or something or if it would I would think so


00:07:20.440 --> 00:07:26.760
I mean you got to have an algorithm that's like well adapted to GPUs, but if you did then I would think so


00:07:26.760 --> 00:07:32.400
Yeah, okay. Well, this is neat for the right the people that really care about it really care about it. So this is cool


00:07:32.400 --> 00:07:39.760
Yeah, absolutely. And I mean you can go and get like GPU clusters on AWS or on digital ocean or things like that


00:07:39.760 --> 00:07:42.760
Yeah, okay, and so you could actually ship your code up there


00:07:42.760 --> 00:07:47.160
Even if you don't have one final note on this one is there was a pycon 2018


00:07:47.160 --> 00:07:53.120
Presentation on this and so I'm gonna link to the presentation as well people want to watch 30 more minutes of this


00:07:53.120 --> 00:07:58.880
Yeah, I actually do too it looks really interesting yeah, all right


00:07:58.880 --> 00:08:04.460
I'm feeling a theme coming on in episode 84 we did touch on somebody called in or called in


00:08:04.460 --> 00:08:09.580
We actually don't have phone lines somebody contacted us and said hey you should cover pre commit


00:08:09.580 --> 00:08:13.640
And we have, we did talk about pre-commit in episode 84,


00:08:13.640 --> 00:08:15.720
but we just sort of talked about what it was.


00:08:15.720 --> 00:08:19.360
But today I ran across this fairly cool article


00:08:19.360 --> 00:08:23.540
called "Automate Python Workflow Using Pre-Commits."


00:08:23.540 --> 00:08:26.400
I like this kind of an article actually of,


00:08:26.400 --> 00:08:28.360
okay, here's these cool tools,


00:08:28.360 --> 00:08:30.400
using pre-commit, black and flake,


00:08:30.400 --> 00:08:33.480
how do I put that in my work day-to-day workflow?


00:08:33.480 --> 00:08:34.740
And how does it really work?


00:08:34.740 --> 00:08:37.280
And this is from LJ Miranda.


00:08:37.280 --> 00:08:38.720
So good job, LJ.


00:08:38.720 --> 00:08:42.640
it's got a great graphic at the start with telling you that you've got changes.


00:08:42.640 --> 00:08:43.960
When you add something,


00:08:43.960 --> 00:08:46.000
you go to get add, you go to staging.


00:08:46.000 --> 00:08:47.520
Then when you do a commit,


00:08:47.520 --> 00:08:50.280
what happens is the pre-commit will intercept that part,


00:08:50.280 --> 00:08:54.240
and it kicks off whatever pre-commit hooks you've got set up.


00:08:54.240 --> 00:08:55.980
If all of those pass,


00:08:55.980 --> 00:08:58.080
then it lets the commit happen,


00:08:58.080 --> 00:09:00.520
and if it doesn't, it kicks it back.


00:09:00.520 --> 00:09:03.280
Then it shows you how to deal with all of


00:09:03.280 --> 00:09:07.440
the different configuration that is available with pre-commit.


00:09:07.440 --> 00:09:13.440
I like this. It's a good starter. If you're still quite not on board with pre-commit, this is a good article to read.


00:09:13.440 --> 00:09:20.440
Yeah, pre-commit's pretty cool. And that's a Python package that you install that then manages all the rest, which I think that's great.


00:09:20.440 --> 00:09:27.440
Yeah, this article, there's a little video, and I think it's an animated GIF or something, a little short demo video that runs.


00:09:27.440 --> 00:09:31.440
I don't know how to do this. This is neat. So it shows it in action.


00:09:31.440 --> 00:09:33.720
- Yeah, yeah, that's really cool.


00:09:33.720 --> 00:09:36.840
I like those little auto-play GIFs that'll animate stuff,


00:09:36.840 --> 00:09:38.240
'cause sometimes it's like, you know,


00:09:38.240 --> 00:09:39.640
if you could just see it happening,


00:09:39.640 --> 00:09:41.760
it would be so much more easy to grok


00:09:41.760 --> 00:09:44.080
what this little picture's trying to tell me.


00:09:44.080 --> 00:09:46.160
- Yeah, and I also don't mind,


00:09:46.160 --> 00:09:47.120
something like that is fine


00:09:47.120 --> 00:09:48.840
if it has an actual video to play,


00:09:48.840 --> 00:09:50.640
but don't give me a half hour video.


00:09:50.640 --> 00:09:53.640
A little couple minute video at most is great.


00:09:53.640 --> 00:09:56.760
- Yeah, a half hour GIF, probably not the way to go.


00:09:56.760 --> 00:09:57.600
(laughing)


00:09:57.600 --> 00:09:59.200
- I don't even know if you can do that.


00:10:00.360 --> 00:10:04.800
So the way one way to go that is good though is to check out data dog.


00:10:04.800 --> 00:10:08.300
So this episode sponsored by data dog as I said and I really appreciate them supporting


00:10:08.300 --> 00:10:09.300
the podcast.


00:10:09.300 --> 00:10:14.700
Data dog is a monitoring platform that brings metrics logs request traces all that kind


00:10:14.700 --> 00:10:19.600
of stuff into one place across different systems and computers and all sorts of stuff.


00:10:19.600 --> 00:10:24.320
So you can use their trace search and analysis which lets you break down Python application


00:10:24.320 --> 00:10:29.640
performance using high cardinality attributes like show me what this customer has done across


00:10:29.640 --> 00:10:35.160
my application or show me all the behaviors for this URL and really easy to troubleshoot


00:10:35.160 --> 00:10:36.160
your app.


00:10:36.160 --> 00:10:40.880
So start doing that with your Python apps today with a free trial and Datadog will send


00:10:40.880 --> 00:10:44.200
you a free t-shirt which has a cute little dog on it.


00:10:44.200 --> 00:10:48.120
So visit them at pythonbytes.fm/datadog to get started.


00:10:48.120 --> 00:10:51.560
So you were talking earlier about that cool little GIF thing and I think you can do it


00:10:51.560 --> 00:10:52.560
with Camtasia.


00:10:52.560 --> 00:10:53.560
Like you can record.


00:10:53.560 --> 00:10:54.560
Okay.


00:10:54.560 --> 00:10:55.560
So I think you can do it with Camtasia.


00:10:55.560 --> 00:11:00.560
basically a screencast and export it as a GIF which is already pretty cool.


00:11:00.560 --> 00:11:05.560
But this next item has a really nice little animated GIF thing going on as well


00:11:05.560 --> 00:11:08.560
because it's super good to see it in action.


00:11:08.560 --> 00:11:10.560
So have you heard about PySpy?


00:11:10.560 --> 00:11:11.560
I have not.


00:11:11.560 --> 00:11:14.560
So PySpy is interesting for a couple of reasons.


00:11:14.560 --> 00:11:17.560
It's interesting because it's a cool tool that people can use


00:11:17.560 --> 00:11:20.560
in some places that they could not previously do so.


00:11:20.560 --> 00:11:24.560
It's a Python profiler so you can hook it up to your Python application


00:11:24.560 --> 00:11:28.000
and it'll tell you where your Python app is spending its time,


00:11:28.000 --> 00:11:30.960
what functions and what it's doing and things like that.


00:11:30.960 --> 00:11:33.840
And it acts kind of like the Unix top command,


00:11:33.840 --> 00:11:36.080
which will take over your screen and it'll show you a list


00:11:36.080 --> 00:11:39.120
that's kind of updating every couple of seconds what's happening.


00:11:39.120 --> 00:11:39.760
That's pretty cool.


00:11:39.760 --> 00:11:44.000
So I can hook up this profiler and it'll live show me


00:11:44.000 --> 00:11:46.800
sort of the equivalent of like a process report,


00:11:46.800 --> 00:11:48.000
like a CPU usage report,


00:11:48.000 --> 00:11:50.480
but it'll say right now you have these various functions


00:11:50.480 --> 00:11:51.760
that have run recently and here,


00:11:51.760 --> 00:11:54.320
like we'll put the most expensive ones on top, things like that.


00:11:54.320 --> 00:11:55.320
Oh, neat.


00:11:55.320 --> 00:11:56.320
That's cool, right?


00:11:56.320 --> 00:11:59.720
And so you can watch that little graph, that little GIF thing and see it going.


00:11:59.720 --> 00:12:02.760
This is written by Ben Fredrickson, and it's just taken off.


00:12:02.760 --> 00:12:05.120
I think it was started in July or something like that.


00:12:05.120 --> 00:12:07.740
It's already got 2000 GitHub stars.


00:12:07.740 --> 00:12:12.040
So what's even cooler though, is it'll let you visualize your Python's apps time without


00:12:12.040 --> 00:12:15.360
restarting or modifying your code in any way.


00:12:15.360 --> 00:12:19.360
And it can attach to running processes and then start to profile them.


00:12:19.360 --> 00:12:20.360
Oh, nice.


00:12:20.360 --> 00:12:25.680
Normally profiling happens by I run a profiler which runs my code, which does a bunch of


00:12:25.680 --> 00:12:30.680
stuff or maybe I reverse, I'll write some code like imports cprofile and I'll call a


00:12:30.680 --> 00:12:34.360
function startprofile, saveprofile, export, etc.


00:12:34.360 --> 00:12:35.360
It's really invasive.


00:12:35.360 --> 00:12:40.080
If you do it from the outside, like the profiler runs your app, you can't do it in production,


00:12:40.080 --> 00:12:41.640
it makes it slow, all sorts of stuff.


00:12:41.640 --> 00:12:45.280
If you do it the other way, you're doing all sorts of writing code to change it.


00:12:45.280 --> 00:12:47.800
This you just say, "Hey, there's a random Python program.


00:12:47.800 --> 00:12:50.200
I'm going to go profile that and it'll just attach to it.


00:12:50.200 --> 00:12:51.000
Nice.


00:12:51.000 --> 00:12:51.360
Yeah.


00:12:51.360 --> 00:12:52.920
You can just give it a process ID.


00:12:52.920 --> 00:12:53.560
Yeah, exactly.


00:12:53.560 --> 00:12:54.640
Give it a PID.


00:12:54.640 --> 00:12:58.880
And what's cool is because of that, that means you can use it in production.


00:12:58.880 --> 00:13:00.920
I could log into my web server.


00:13:00.920 --> 00:13:04.680
That's getting pounded on not responding correctly or whatever.


00:13:04.680 --> 00:13:09.880
And I could actually begin to profile it without like wrecking my thing or slowing


00:13:09.880 --> 00:13:11.600
it down or restarting it or whatever.


00:13:11.600 --> 00:13:13.800
Or any long running process.


00:13:13.800 --> 00:13:17.440
Like while the problem is happening, you can just attach to it and figure


00:13:17.440 --> 00:13:20.440
out what's wrong. That's the key thing because maybe restarting it rerunning it


00:13:20.440 --> 00:13:23.400
takes like four hours to get into that weird state you never know right yeah


00:13:23.400 --> 00:13:28.760
oh yeah this is cool sweet that's pretty trick so it's written in rust actually


00:13:28.760 --> 00:13:34.040
but it's pip installable so all sorts of cool things and then he even goes into


00:13:34.040 --> 00:13:38.900
Ben goes into how does it work so here's a section on how does PySpy work so I'll


00:13:38.900 --> 00:13:41.520
just read you this and tell me this sounds like a program you would have


00:13:41.520 --> 00:13:46.800
written it's not what I would have PySpy works by directly reading the memory of


00:13:46.800 --> 00:13:54.000
the Python program using process VM red V system call Linux or VM read on OS 10


00:13:54.000 --> 00:13:59.040
or read process memory on Windows and then it just analyzes the memory over


00:13:59.040 --> 00:14:06.320
and over that's crazy right but it knows enough about Python to go well that


00:14:06.320 --> 00:14:10.960
means X and it just you know off it goes so there's a bunch of more details on


00:14:10.960 --> 00:14:14.480
how he actually makes it work I'll link to that section as well it's a pretty


00:14:14.480 --> 00:14:20.860
cool profiler and I really like the attach to running processes without affecting them.


00:14:20.860 --> 00:14:23.300
That's pretty unique I think and so I wanted to highlight it.


00:14:23.300 --> 00:14:24.300
Yeah, nice.


00:14:24.300 --> 00:14:29.340
And it can do icicle graphs which I don't know why that would be neat but it looks neat.


00:14:29.340 --> 00:14:30.340
Yeah, those are cool.


00:14:30.340 --> 00:14:34.980
I get sometimes you know just visually some things are really out of whack and you're


00:14:34.980 --> 00:14:36.580
like what is that big bar from?


00:14:36.580 --> 00:14:38.140
Oh, that's a radot sort.


00:14:38.140 --> 00:14:40.060
Why are we calling that a thousand times?


00:14:40.060 --> 00:14:41.060
Yeah.


00:14:41.060 --> 00:14:42.060
Things like that.


00:14:42.060 --> 00:14:43.060
Let's just sort it once.


00:14:43.060 --> 00:14:44.340
All right, what do you got first next?


00:14:44.340 --> 00:14:48.780
I've got SimPy, which is just sort of fun.


00:14:48.780 --> 00:14:52.980
SimPy is a, well, I'm just gonna read it a little bit


00:14:52.980 --> 00:14:55.740
here too, symbolic computation.


00:14:55.740 --> 00:14:57.620
So like you're in math class or something,


00:14:57.620 --> 00:15:01.140
we realized early on with programming that you can,


00:15:01.140 --> 00:15:03.300
if you punch things into the calculator too fast,


00:15:03.300 --> 00:15:06.040
it just mucks things up because you have rounding


00:15:06.040 --> 00:15:07.180
and various things like that.


00:15:07.180 --> 00:15:09.940
So symbolic computation deals with the computation


00:15:09.940 --> 00:15:12.340
of mathematical objects symbolically.


00:15:12.340 --> 00:15:16.340
This means that mathematical objects are represented exactly, not approximately.


00:15:16.340 --> 00:15:22.260
And math expressions are with unevaluated variables are left in symbolic form.


00:15:22.260 --> 00:15:29.140
And, SymPy allows you to do that with Python and it's sort of blasted cool.


00:15:29.140 --> 00:15:35.340
I've got a little example of, doing an integration of, of the sign of X


00:15:35.340 --> 00:15:40.780
squared over negative infinity to positive infinity, and it will tell you what the


00:15:40.780 --> 00:15:45.780
The answer is, and these sorts of symbolic math manipulations,


00:15:45.780 --> 00:15:49.440
for a lot of people, boy, if I had to do this by hand,


00:15:49.440 --> 00:15:50.280
I'd be in trouble.


00:15:50.280 --> 00:15:52.240
I did not do that well in math.


00:15:52.240 --> 00:15:55.740
And so being able to do this programmatically is cool.


00:15:55.740 --> 00:15:58.780
And the introduction and the website is pretty awesome too.


00:15:58.780 --> 00:16:01.300
It has a bunch of live,


00:16:01.300 --> 00:16:03.380
it's got engine in the back that runs it.


00:16:03.380 --> 00:16:07.740
So you can try the examples out and pop up a little window


00:16:07.740 --> 00:16:10.160
and do it interactively.


00:16:10.160 --> 00:16:11.080
So this is neat.


00:16:11.080 --> 00:16:14.380
- Yeah, there's a ton of cool stuff that comes out of this.


00:16:14.380 --> 00:16:16.320
So for example, you can say,


00:16:16.320 --> 00:16:18.200
X comma Y equals symbols X and Y.


00:16:18.200 --> 00:16:22.080
And then after that, you can do algebraic expressions,


00:16:22.080 --> 00:16:23.360
like truly algebraically.


00:16:23.360 --> 00:16:26.080
So like expression equals X plus two Y,


00:16:26.080 --> 00:16:26.960
not in quotes or anything,


00:16:26.960 --> 00:16:29.520
just like as if it were regular math.


00:16:29.520 --> 00:16:31.560
And then you could like add one to that expression


00:16:31.560 --> 00:16:35.840
and it'll reform the equation and stuff like that.


00:16:35.840 --> 00:16:37.600
You can ask it to do integration.


00:16:37.600 --> 00:16:39.160
Like the example you have in our show notes


00:16:39.160 --> 00:16:42.560
is to integrate sine of x squared from minus infinity


00:16:42.560 --> 00:16:43.600
to positive infinity.


00:16:43.600 --> 00:16:46.240
Instead of giving you the answer of, oh my gosh,


00:16:46.240 --> 00:16:47.520
what is that like?


00:16:47.520 --> 00:16:49.520
1.5 dot dot dot dot.


00:16:49.520 --> 00:16:54.480
It just says that's square root of 2 pi over 2.


00:16:54.480 --> 00:16:55.440
The exact answer.


00:16:55.440 --> 00:16:56.760
That is pretty awesome.


00:16:56.760 --> 00:16:59.040
We just wrecked the whole math experience


00:16:59.040 --> 00:17:01.360
for so many of our listeners who are students.


00:17:01.360 --> 00:17:02.560
They're like, you know what?


00:17:02.560 --> 00:17:05.680
That calculus class, I just solved that problem.


00:17:05.680 --> 00:17:07.000
- Well, I would have loved this


00:17:07.000 --> 00:17:09.240
while I was taking calculus.


00:17:09.240 --> 00:17:10.460
- Yeah, for sure.


00:17:10.460 --> 00:17:11.780
Yeah, you could totally check your work.


00:17:11.780 --> 00:17:12.900
Like, there's no answers in the book.


00:17:12.900 --> 00:17:13.740
Oh yeah, really?


00:17:13.740 --> 00:17:14.560
Hold on.


00:17:14.560 --> 00:17:16.800
(laughing)


00:17:16.800 --> 00:17:18.400
There's an answer right here.


00:17:18.400 --> 00:17:19.480
That's pretty awesome.


00:17:19.480 --> 00:17:22.480
- So if you can take your laptop to your tests, you're set.


00:17:22.480 --> 00:17:24.120
- Yeah, probably not likely.


00:17:24.120 --> 00:17:25.160
- Probably not.


00:17:25.160 --> 00:17:28.040
- So this next one that I found, Brian, it's pretty cool.


00:17:28.040 --> 00:17:31.540
So something that I've been digging into lately


00:17:31.540 --> 00:17:33.460
behind the scenes, and I'm gonna be talking more and more


00:17:33.460 --> 00:17:37.460
probably in the next few weeks is async programming in Python. Like I've really


00:17:37.460 --> 00:17:40.560
been doing a lot with that lately and we'll have some cool stuff to share


00:17:40.560 --> 00:17:45.940
pretty soon. But that means I'm running across all this cool async stuff. So


00:17:45.940 --> 00:17:50.740
you've heard of WSGI, which is the Web Service Gateway Interface. That's like


00:17:50.740 --> 00:17:55.540
how Pyramid, Flask, Django, all those things work. None of them do a great job


00:17:55.540 --> 00:18:00.940
of supporting async programming because fundamentally this WSGI interface is


00:18:00.940 --> 00:18:03.940
is synchronous and can't be made async.


00:18:03.940 --> 00:18:04.780
- Yeah.


00:18:04.780 --> 00:18:06.800
- So there's this other framework called ASGI


00:18:06.800 --> 00:18:10.000
for async gateway interface, I guess,


00:18:10.000 --> 00:18:13.760
that allows these frameworks to be asynchronous.


00:18:13.760 --> 00:18:17.440
So the thing I'm talking about this week is Starlet,


00:18:17.440 --> 00:18:20.840
which is an ASGI web framework.


00:18:20.840 --> 00:18:22.440
And I like its little subtitle,


00:18:22.440 --> 00:18:25.200
the little ASGI framework that shines.


00:18:25.200 --> 00:18:26.880
(laughing)


00:18:26.880 --> 00:18:28.240
- It's cute.


00:18:28.240 --> 00:18:29.080
- It is cute.


00:18:29.080 --> 00:18:35.340
So it's basically built, intended to build high performance async I/O services.


00:18:35.340 --> 00:18:40.480
So if you have anything that talks to a database, to caches, to file systems, things like that,


00:18:40.480 --> 00:18:45.420
even calls other web services or microservices, super easy to build.


00:18:45.420 --> 00:18:50.680
The API is basically Flask, like a Flask-ish API.


00:18:50.680 --> 00:18:55.920
And you create a web method, you say async def regular view method, and you go do a bunch


00:18:55.920 --> 00:18:56.920
of stuff.


00:18:56.920 --> 00:18:59.840
It has cool support for like response types.


00:18:59.840 --> 00:19:03.620
So you can have a file response object that you just send back to the framework


00:19:03.620 --> 00:19:08.360
that's based on async AIO files, which is an async IO file based thing.


00:19:08.360 --> 00:19:10.320
And there's a lot of nice integration like that.


00:19:10.320 --> 00:19:10.800
Okay.


00:19:10.800 --> 00:19:14.040
You're just interested in this or do you have an application that you're going to try to?


00:19:14.040 --> 00:19:16.200
No, I'm building a course on it.


00:19:16.200 --> 00:19:16.880
Oh, okay.


00:19:16.880 --> 00:19:21.720
Trying to make a nice, well-rounded async concurrent programming Python course.


00:19:21.720 --> 00:19:22.880
Oh, well, yeah.


00:19:22.880 --> 00:19:25.120
So I've been building tons of little apps and stuff.


00:19:25.120 --> 00:19:26.320
So here we go.


00:19:26.320 --> 00:19:26.880
Here's one of them.


00:19:26.880 --> 00:19:29.880
If you want to build an app that is way more scalable,


00:19:29.880 --> 00:19:33.640
you know, 10 times more scalable than regular web apps


00:19:33.640 --> 00:19:35.840
on the same hardware and whatnot,


00:19:35.840 --> 00:19:39.080
it's pretty easy to do if mostly what that web app is doing


00:19:39.080 --> 00:19:40.240
is waiting, right?


00:19:40.240 --> 00:19:44.240
You can just, you know, basically the async IO


00:19:44.240 --> 00:19:46.680
web frameworks can just adapt to that more easily


00:19:46.680 --> 00:19:49.000
'cause they're not blocking while they're waiting.


00:19:49.000 --> 00:19:51.040
Also discovered a couple cool things


00:19:51.040 --> 00:19:52.360
while looking into this.


00:19:52.360 --> 00:19:57.360
One is they say you should install the UltraJSON package,


00:19:57.360 --> 00:20:00.600
which the pip install command was UJSON,


00:20:00.600 --> 00:20:04.140
and that is a basically a drop-in replacement


00:20:04.140 --> 00:20:07.860
for the JSON built-in that is like between 50%


00:20:07.860 --> 00:20:10.360
and three times faster.


00:20:10.360 --> 00:20:11.360
So if you're doing a lot of JSON,


00:20:11.360 --> 00:20:13.720
you can just use UltraJSON and that's pretty awesome.


00:20:13.720 --> 00:20:16.400
- Yeah, okay, I have to check that out too.


00:20:16.400 --> 00:20:19.000
- Yeah, so all you have to do is, you know,


00:20:19.000 --> 00:20:25.000
Import a ujson as json and then that like makes your code faster. Of course it has to be there, right?


00:20:25.000 --> 00:20:29.480
But yeah, that's pretty sweet. The other thing is you've maybe heard of g unicorn for the


00:20:29.480 --> 00:20:35.880
Traditional web frameworks. There's a uveicorn which is based on uv loop and g unicorn


00:20:35.880 --> 00:20:38.840
Which is also pretty awesome for these async web frameworks


00:20:38.840 --> 00:20:48.520
Well, it's cool and I get the name but eventually if if we if everybody starts using that people forget where that came from


00:20:48.600 --> 00:20:50.920
and it's just going to be a weird word, uviacorn.


00:20:50.920 --> 00:20:56.040
I know, uvicorn, no it's uviacorn, you got to understand where the name comes from, come


00:20:56.040 --> 00:20:57.040
on.


00:20:57.040 --> 00:20:58.040
Get it together.


00:20:58.040 --> 00:20:59.040
Yeah.


00:20:59.040 --> 00:21:00.040
Well, that's it for our items.


00:21:00.040 --> 00:21:02.400
I do have some extra stuff to share, how about you?


00:21:02.400 --> 00:21:04.800
Just one thing I wanted to point out, if I remember it.


00:21:04.800 --> 00:21:05.800
Okay, cool.


00:21:05.800 --> 00:21:07.240
I'll go first, you can think.


00:21:07.240 --> 00:21:10.480
So really big news, you and I, we had a good time at PyCon, right?


00:21:10.480 --> 00:21:11.480
Oh yeah.


00:21:11.480 --> 00:21:15.480
I can tell you when we're going to have a good time again.


00:21:15.480 --> 00:21:20.680
It's going to be, if we go to a tutorial, it's May 1st and 2nd.


00:21:20.680 --> 00:21:24.480
If you want to go to talks, it's May 3rd, 4th, and 5th.


00:21:24.480 --> 00:21:27.480
And if you want to do the sprints, it's May 6th, 7th, 8th, and 9th.


00:21:27.480 --> 00:21:30.680
So basically, the announcement is that the PyCon dates are out.


00:21:30.680 --> 00:21:32.640
Yes, and it's not over.


00:21:32.640 --> 00:21:35.160
I don't think it's over Mother's Day this year.


00:21:35.160 --> 00:21:36.160
I hope it's not.


00:21:36.160 --> 00:21:37.160
I hope it's not.


00:21:37.160 --> 00:21:41.120
I also have a quick little follow up.


00:21:41.120 --> 00:21:42.640
You talked about the pre-commit package.


00:21:42.640 --> 00:21:47.800
another listener, Matthew Lehman, sent in some notes about how his team is using it,


00:21:47.800 --> 00:21:54.840
and basically talked about how they're using pre-commit the Python package so that like


00:21:54.840 --> 00:22:00.440
their Flake 8 and Black and other things that automatically run during continuous integration


00:22:00.440 --> 00:22:03.940
also automatically run when people do git commits.


00:22:03.940 --> 00:22:08.120
So they have fewer failing builds, which is pretty awesome, and has a couple of nice links.


00:22:08.120 --> 00:22:10.160
So I threw that in there at the end.


00:22:10.160 --> 00:22:13.680
And then finally, you talked about the Gang of Four patterns last week, right?


00:22:13.680 --> 00:22:14.680
Yeah.


00:22:14.680 --> 00:22:20.480
So, John Tosher, I think is right, sent us a message pointing out another talk from PyCon


00:22:20.480 --> 00:22:24.720
AU called "You Don't Need That," which is pretty cool.


00:22:24.720 --> 00:22:28.920
And it basically talks about how if you study the Gang of Four patterns, a lot of what they


00:22:28.920 --> 00:22:33.520
were doing was because they were using Smalltalk or Java or C++.


00:22:33.520 --> 00:22:37.720
And in Python, here's a new way that you just basically don't need that pattern.


00:22:37.720 --> 00:22:39.360
So pretty cool talk and that was,


00:22:39.360 --> 00:22:40.840
you know, I'll link to the video for that.


00:22:40.840 --> 00:22:42.400
- Yeah, the, yeah.


00:22:42.400 --> 00:22:43.560
(laughs)


00:22:43.560 --> 00:22:45.360
Yeah, if you translated the Gang of Four book


00:22:45.360 --> 00:22:47.880
directly to Python, it would be like a pamphlet.


00:22:47.880 --> 00:22:48.720
- That's right.


00:22:48.720 --> 00:22:50.480
(laughs)


00:22:50.480 --> 00:22:51.720
Nice, do you remember your item?


00:22:51.720 --> 00:22:53.320
- I did not, so.


00:22:53.320 --> 00:22:54.320
- Oh, save it for next week.


00:22:54.320 --> 00:22:56.200
- Yeah, save it for next week.


00:22:56.200 --> 00:22:58.760
- Yeah, we'll do this again next week, right?


00:22:58.760 --> 00:23:00.760
- Yeah, maybe we should just do it every week.


00:23:00.760 --> 00:23:03.160
- Yeah, all right, deal, we'll do it every week.


00:23:03.160 --> 00:23:04.000
- Okay, cool.


00:23:04.000 --> 00:23:05.960
- Cool, all right, well, thanks for doing the show this week.


00:23:05.960 --> 00:23:06.960
- No, thank you.


00:23:06.960 --> 00:23:07.960
>> Bye.


00:23:07.960 --> 00:23:10.680
>> Thank you for listening to Python Bytes.


00:23:10.680 --> 00:23:16.320
Follow the show on Twitter via @PythonBytes, that's Python Bytes as in B-Y-T-E-S.


00:23:16.320 --> 00:23:19.620
And get the full show notes at PythonBytes.fm.


00:23:19.620 --> 00:23:23.320
If you have a news item you want featured, just visit PythonBytes.fm and send it our


00:23:23.320 --> 00:23:24.320
way.


00:23:24.320 --> 00:23:26.840
We're always on the lookout for sharing something cool.


00:23:26.840 --> 00:23:30.280
On behalf of myself and Brian Aukin, this is Michael Kennedy.


00:23:30.280 --> 00:23:33.320
Thank you for listening and sharing this podcast with your friends and colleagues.

