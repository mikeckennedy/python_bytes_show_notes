WEBVTT

00:00:00.001 --> 00:00:04.660
Hello and welcome to Python Bytes, where we deliver Python news and headlines directly to

00:00:04.660 --> 00:00:11.720
your earbuds. This is episode 182, recorded May 13th, 2020. And I am Brian Okken.

00:00:11.720 --> 00:00:12.580
And I'm Michael Kennedy.

00:00:12.580 --> 00:00:15.840
And this episode is brought to you by Datadog.

00:00:15.840 --> 00:00:20.140
There's two surveys that I feel really do a good job of keeping their, you know,

00:00:20.140 --> 00:00:25.760
they have their thumb on the pulse of the community. And I would say one is the PSF

00:00:25.760 --> 00:00:29.360
JetBrains combination. That one's really good for Python in particular.

00:00:29.360 --> 00:00:33.760
The other is the Stack Overflow survey. Well, the Stack Overflow survey recently came out,

00:00:33.760 --> 00:00:38.580
you know, a couple months ago or something like that. So now it's the PSF JetBrains survey.

00:00:38.580 --> 00:00:42.260
And when I first saw this, I thought, oh, this is last year's because it was 2019. But

00:00:42.260 --> 00:00:48.920
they do a ton of analysis on it. And the survey was done in 2019, but it's released now. So anyway,

00:00:48.920 --> 00:00:53.560
I want to talk about some of the results in there because there's some interesting takes. And also,

00:00:53.560 --> 00:00:58.680
I want to say thank you to Jose Nario who sent this in because, like I said, I thought it was last year's.

00:00:58.720 --> 00:01:02.320
I'm still waiting for the 2020 edition. All right. So let's talk about some of the results.

00:01:02.320 --> 00:01:08.840
First of all, one of the first questions asked was, do you primarily use Python as your main language?

00:01:08.840 --> 00:01:13.860
Or are you interested in Python because it's some other, like I also happen to use it in addition

00:01:13.860 --> 00:01:20.700
to JavaScript or something? 84% of the people who took the survey, and that was mostly folks who

00:01:20.700 --> 00:01:28.000
visited Python.org. So 84% said it's my primary language. And that's unchanged from last year.

00:01:28.000 --> 00:01:29.080
Okay. Interesting.

00:01:29.080 --> 00:01:35.200
A lot of the analysis here was, how has this changed over the last year or so? All right. So there's a lot

00:01:35.200 --> 00:01:41.020
of interesting trends to be pulled out from here. They said, what other languages do you use? Well,

00:01:41.020 --> 00:01:46.040
there was JavaScript, which has gone down in usage. There's Bash, which has gone down in usage.

00:01:46.360 --> 00:01:54.320
There's HTML, which has gone down in usage relative to last year. And C++, which has gone down relative

00:01:54.320 --> 00:01:58.860
to last year. So the people who took the survey, the same number of people said they're primarily

00:01:58.860 --> 00:02:03.680
using Python, but the other languages they're employing, all the ones who are, which were popular

00:02:03.680 --> 00:02:09.500
seem to be going down. And I would say this means maybe people are starting to lean more on Python,

00:02:09.500 --> 00:02:12.460
those who use it. I don't know what conclusions we should draw there.

00:02:12.460 --> 00:02:17.860
There's also some growth in some other languages as well. I'm guessing like interesting to see all

00:02:17.860 --> 00:02:18.780
the other ones down.

00:02:18.780 --> 00:02:23.980
Yeah. Well, this is down within the Python community, right? This is not necessarily down overall,

00:02:23.980 --> 00:02:24.420
right?

00:02:24.420 --> 00:02:24.720
Yeah.

00:02:24.720 --> 00:02:29.940
So I would say we should look at the Stack Overflow survey to like really more like even

00:02:29.940 --> 00:02:33.760
Stack Overflow trends. But if you look at that one, it's all the other languages are relatively

00:02:33.760 --> 00:02:41.640
down as well. So interesting. Now, a lot of the divide happens around web versus data science

00:02:41.640 --> 00:02:46.340
here. And so a lot of the questions said, are you a web developer primarily or data scientist

00:02:46.340 --> 00:02:51.660
primarily? And then if you are, what type of tools do you use? So for example, if you're

00:02:51.660 --> 00:02:58.100
a data scientist, use Python, of course, but you also make larger use of C++, Java, R and

00:02:58.100 --> 00:03:03.740
C# as a data scientist. But if you are a web developer, you make more use of SQL, JavaScript

00:03:03.740 --> 00:03:09.360
and HTML, which is, you know, no surprise because it's hard to write the web without HTML and

00:03:09.360 --> 00:03:15.600
JavaScript. So those are pretty interesting. And they said 58% of the people use Python

00:03:15.600 --> 00:03:20.520
for both work and personal projects. And they said, all right, well, what do you use it for?

00:03:20.520 --> 00:03:26.540
Right? So there was a bunch of answers. I'm going to give you the top four because the average

00:03:26.540 --> 00:03:30.940
person who filled this out chose four things that they primarily use Python for, right? It's

00:03:30.940 --> 00:03:35.560
like I could use it for web and DevOps or something like that, right? It's not exclusive.

00:03:35.560 --> 00:03:43.540
So the top four were data analysis, which is exactly the same as last year. 59% of the respondents

00:03:43.540 --> 00:03:49.460
said that web development. This is pretty interesting. 51% of the people said they do web development,

00:03:49.460 --> 00:03:52.340
but this is down 4% year over year.

00:03:52.340 --> 00:03:52.840
Interesting.

00:03:53.000 --> 00:03:57.360
That's a big drop. And I feel like web is a big component of what the Python space is.

00:03:57.360 --> 00:03:57.600
Yeah.

00:03:57.600 --> 00:04:02.700
So I don't really know what to drop from that. Like maybe just more people are sort of backfilling in

00:04:02.700 --> 00:04:08.400
the data science side, maybe. Maybe the tools that they use are better. So things like streamlet and

00:04:08.400 --> 00:04:10.880
stuff, they're like, well, I don't have to do web now. I'm not really sure.

00:04:10.880 --> 00:04:11.200
Yeah.

00:04:11.200 --> 00:04:18.240
Machine learning, 40%. That's up 1%. DevOps, 39%. That's down 4% as well, which is the same number

00:04:18.240 --> 00:04:23.600
as a web development. And these are kind of similar things. So what you use Python for is

00:04:23.600 --> 00:04:28.840
pretty interesting. And then more broadly, it says, what do you use it the most for? Web,

00:04:28.840 --> 00:04:35.020
data analysis, and machine learning. Web is down 1% as the primary thing you use it for. Data analysis

00:04:35.020 --> 00:04:41.720
is up 1%. Machine learning is up 2%. Also, not surprising, I guess, but good news on the Python

00:04:41.720 --> 00:04:47.120
versus legacy Python story, 90% of people are using Python 3.

00:04:47.360 --> 00:04:52.260
That's a huge change from five years ago when it was like, oh yeah, there's that one weird guy that

00:04:52.260 --> 00:05:00.060
uses Python 3. But everyone else, no. More of the data scientists are using Python 3 as a percentage

00:05:00.060 --> 00:05:06.080
over the web developers. And I think that's because data science, the libraries and the tools are

00:05:06.080 --> 00:05:10.500
changing a lot. It's not like you have legacy data science. Like, oh yeah, we're using that machine

00:05:10.500 --> 00:05:14.980
library from machine learning library from like 10 years ago because we just don't want to change it.

00:05:14.980 --> 00:05:19.340
It's like those are fundamentally changed and you just have new tools. Whereas web development,

00:05:19.340 --> 00:05:23.340
I think there's a lot of folks that are like, yeah, we're still got that, you know, Django 1 app

00:05:23.340 --> 00:05:25.080
going on Python 2 or something.

00:05:25.080 --> 00:05:29.020
I'm not surprised there's still some Python 2, but 10% still seems a little high.

00:05:29.020 --> 00:05:33.960
I think it's mostly legacy code. I'm not entirely sure, but you can use your legacy Python for your

00:05:33.960 --> 00:05:41.780
legacy code. All right. And then web frameworks. Flask was kind of neck and neck with Django last year.

00:05:41.780 --> 00:05:47.980
Now it's like totally ahead. So 48% Flask developers and 44% Django developers and everything else is

00:05:47.980 --> 00:05:55.080
pretty small. Data science, 63% of the people are using NumPy, 55% Pandas, 46% Matplotlib.

00:05:55.080 --> 00:06:00.320
Here's one I threw in for you, Brian. Testing, 49% of the people are using pytest.

00:06:00.320 --> 00:06:01.160
Yes.

00:06:01.160 --> 00:06:04.620
Yeah. 30% of the people are using the built-in unit test.

00:06:05.020 --> 00:06:10.500
And 34% are using this other framework I hadn't heard of before. It's called the Nun framework.

00:06:10.500 --> 00:06:15.340
Yeah. That's unfortunately high, but it's funny that it's higher than unit test.

00:06:15.340 --> 00:06:19.560
Yeah, I know. That's what I thought as well. Pretty funny. All right. A couple more and we'll

00:06:19.560 --> 00:06:24.680
be done with this one. So cloud, the cloud platforms people are using, AWS is in the lead. No surprise

00:06:24.680 --> 00:06:33.100
there with 55%. What did surprise me is Google Cloud, GCP and whatnot, is actually number two at 33%.

00:06:33.680 --> 00:06:43.100
DigitalOcean, shout out to them, is at 22%. And then Heroku is 20%. And Azure is 19%. So pretty

00:06:43.100 --> 00:06:48.460
interesting. And then how do you run your code in the cloud in a production environment? Do you run

00:06:48.460 --> 00:06:54.700
in containers, VMs, platforms of service like Heroku or something? So containers, 47%. That's pretty high.

00:06:54.700 --> 00:07:03.460
VMs, 46%. And then platform as a service is 25%. What editor do you use? PyCharm, 33%.

00:07:03.460 --> 00:07:10.320
VS Code, 24%. Vim, 9%. Everything else is like a super small margin after that. Yeah. And that's pretty

00:07:10.320 --> 00:07:16.020
interesting. Yeah. So I threw in an extra one on there at the end. Well, one, the containers, I thought

00:07:16.020 --> 00:07:22.700
containers was number two below VMs last year. And now it's jumped to number one.

00:07:22.880 --> 00:07:31.940
Oh yeah. Like that's probably Kubernetes, like hosted Kubernetes clusters, right? That people are throwing their Docker images into. Oh yeah. What's the last one? Take us to this one.

00:07:32.020 --> 00:07:48.440
And then the tool use. They also listed a handful of things of people using. 90% people using version control. That's good. 80% write their tests. That's good. 80% code linting. And 65% people use type hinting, which actually is a little higher than I.

00:07:48.440 --> 00:07:49.400
Oh yeah. Way to go.

00:07:49.400 --> 00:07:53.880
That's nice. And about half the people using code coverage tools, 52%.

00:07:53.880 --> 00:08:04.700
Yeah. Thanks for adding that. I'm very familiar with legacy code and non-legacy code, which I guess you call modern, but you're going to take it to 11. What's up? What's up with this?

00:08:04.700 --> 00:08:05.060
Yes.

00:08:05.280 --> 00:08:05.820
This level.

00:08:05.820 --> 00:08:06.940
It's hyper modern.

00:08:06.940 --> 00:08:07.460
Woo.

00:08:07.460 --> 00:08:34.120
Yeah. This is from Claudio. Cool name. But anyway, so he wrote a, actually, it's like a book. This is an incredible series of blog posts. And he actually writes them out. They're all linked together called hyper modern Python and sets them up in six chapters. He's got setup, testing, linting, typing, documentation, and then the last chapter is CI, CD. And he just wrapped it up.

00:08:34.120 --> 00:09:02.140
I've been watching this and kind of, I was going to announce it when, when he was done. It's a really fun series to learn about, you know, you've learned some of the basics of Python, but you want to like get some best practices and take it up a notch. And I think this, this is good. It's opinionated. Of course, I actually like opinionated things. And some of the opinions I don't quite follow. Like, he likes, PyE and V. I'm not really a fan of PyE and V, but, but that's all right.

00:09:02.140 --> 00:09:25.560
Uh, also poetry uses poetry. I use flit or usually, but anyway, he does, recommend the source layout, which is good. But, for setup, there's a whole bunch of neat stuff in here. And, some tools that like for linting, he talks about flake eight black import order bug bear, which is fun. I don't know if we've covered that, but there's a whole bunch of tools that I haven't even heard of. Like safety and dessert.

00:09:26.140 --> 00:09:50.240
And, data validation with dessert and marshmallow. So I'll have to look that sort of stuff up. That looks neat. So just a good run through it in the CICD section. He talked about using GitHub actions and, reporting your coverage with code cov uploading to PyPI and using test PyPI servers and documenting on read the docs. I think this is a fairly good representation for modern projects.

00:09:50.240 --> 00:09:57.080
So, yeah, it covers a lot of stuff that people probably should be doing and maybe haven't taken the time to set up or dig into.

00:09:57.080 --> 00:10:18.600
Yeah. And one of the things I want to, highlight also is an incredible use of pictures. The imagery that he uses on these, posts are like the CICD section was, some 1970s, space station or, you know, space, colony images. And they're beautiful. So it's worth it just for the pictures.

00:10:18.660 --> 00:10:21.840
It is worth it just for the pictures. They're great. Yeah. Very nice one.

00:10:21.840 --> 00:10:24.840
Well, another thing that's really nice is Datadog.

00:10:24.840 --> 00:10:25.300
Indeed.

00:10:25.300 --> 00:10:38.480
Yep. This episode is of Python Bytes is brought to you by Datadog. And let me ask you a question. Do you have an app in production that is slower than you like? It's performance all over the place. Sometimes fast, sometimes slow.

00:10:38.760 --> 00:11:02.760
Now here's the important question. Do you know why? Well, with Datadog, you will. You can troubleshoot your app's performance with Datadog's end-to-end tracing. Use the detailed flame graphs to identify bottlenecks and latency in that finicky app of yours. Be the hero that got the app back on track at your company. Get started today with a free trial of Datadog by going to pythonbytes.fm

00:11:02.760 --> 00:11:10.820
slash Datadog. And you even get a free t-shirt. So I really like my purple Datadog t-shirt. I wear it a little too much, probably.

00:11:11.040 --> 00:11:12.920
Yeah, it's a cute one. Awesome. Yeah, thanks, Datadog.

00:11:12.920 --> 00:11:25.780
This next one that I want to cover, Brian, is a little bit just kind of a fun thing. Dan Bader shared this with me the other day. He's like, man, you got to check this out. Look at this thing. And I'm like, what is it? It's called the Open AI Jukebox.

00:11:25.780 --> 00:11:44.200
And so it's this AI that creates music. It doesn't just create music. It creates different genres of music in the styles of certain artists with lyrics and musical accompaniment.

00:11:45.060 --> 00:12:00.080
It's wild, right? I mean, I had you listen to a couple of the samples and folks out there, you should just go click on the Open AI Jukebox link in the show notes and go to the curated samples and play a couple. How would you classify them, Brian?

00:12:00.080 --> 00:12:09.000
I'd classify them as you can tell their music. None of these I would pick up want to go out, rush out and buy the album right away.

00:12:09.000 --> 00:12:22.360
Yeah, neither would I. I mean, to me, they sound like sort of bad recordings of an artist, you know, maybe taking on like a phone at a live concert where you've kind of got like not a good audio setup.

00:12:22.360 --> 00:12:28.100
There's like a little bit of a, I think I remember this song bit to it, even though there's no way.

00:12:28.100 --> 00:12:37.980
Yeah, but it was created by an AI, which is insane. So one, they've got a country song in the style of Alan Jackson, which is a country singer.

00:12:38.080 --> 00:12:47.080
And you could convince me that that was Alan Jackson singing that song if I didn't know better. I'm like, oh, I've never heard that song and I'm not really super familiar with his music, but I kind of know what the guy sounds like.

00:12:47.080 --> 00:12:54.040
That's probably one of his songs because it sounds like he's singing it, which is crazy. It's got Elvis Presley. It's got Katy Perry.

00:12:54.580 --> 00:13:07.400
It's got some heavy metal in the style of Rage. I've not actually familiar with him. You got some other crazy stuff like alternative metal in the style of Disturbed or a jazz like Ella Fitzgerald.

00:13:07.960 --> 00:13:20.400
And it's really interesting how accurate these things reproduce what those artists' style of singing is, their voice, what their voice sounds like, the style of music they write.

00:13:20.400 --> 00:13:29.560
I mean, I would definitely not want to go listen to this to like relax or whatever, but it's as a AI example, it's pretty crazy.

00:13:29.560 --> 00:13:36.580
Yeah. And one of the things I really appreciate is the music while you're listening to it. It kind of, it shows you the words, the lyrics while you're listening to it.

00:13:36.580 --> 00:13:44.180
Yeah. The lyrics highlight because some of them it's easy to understand, but others like the Disturbed one, it's not so much easy to understand.

00:13:44.320 --> 00:13:51.880
It's like a highlighted thing, but my brain wanted to have, see the little bouncy ball, like, I don't know, the kids music.

00:13:51.880 --> 00:13:53.000
Yeah, exactly.

00:13:53.000 --> 00:14:06.460
So the code for this is available on GitHub. The data set they use, they train the model. To train it, they crawled the web and curated a data set of 1.2 million songs.

00:14:06.460 --> 00:14:07.020
Oh, wow.

00:14:07.020 --> 00:14:15.300
That's got to use some bandwidth to get a hold of those. And then 600,000 of those were in English. And then it paired those with lyrics and metadata from Lyric Wiki.

00:14:15.300 --> 00:14:15.780
Okay.

00:14:15.780 --> 00:14:23.760
So it went and found the songs and said, okay, we need the written text so we can teach the model what the words are so that it can make up its own lyrics, I guess.

00:14:23.760 --> 00:14:30.760
Yeah. And then it says the top level Transformers trained on the task of predicting compressed audio tokens.

00:14:31.260 --> 00:14:39.980
And they provide additional information like the artist and genre for each song and said they get two advantages from that. First, it reduces the entropy of the audio prediction.

00:14:39.980 --> 00:14:48.780
So the model's able to get better audio quality for the given style. And at generation time, they're able to guide it in the style of their choosing.

00:14:48.780 --> 00:14:52.660
Like, no, no, we want some like hard rock versus Elvis or whatever.

00:14:52.660 --> 00:14:57.680
Anyway, if you're into AI, this seems like a pretty wild project to check out.

00:14:57.680 --> 00:14:58.460
Yeah, definitely.

00:14:58.460 --> 00:15:00.360
Yeah. I'd say it's even curious.

00:15:00.360 --> 00:15:01.000
Curious.

00:15:01.000 --> 00:15:02.700
Or if you're curious, you should go check it out.

00:15:02.700 --> 00:15:10.360
You should. And you should also check out this next post called The Curious Case of Python's Context Manager.

00:15:10.360 --> 00:15:16.460
So Redewan Deloire went through this because context managers are really important.

00:15:16.460 --> 00:15:23.480
And when you start really making some elegant, really readable code, it's good to make use of context managers.

00:15:23.720 --> 00:15:25.140
If you're not familiar with what they are.

00:15:25.140 --> 00:15:32.840
Anytime you see a width, like with open file as F or something like that, that's a use of a context manager.

00:15:33.080 --> 00:15:35.460
And the file one is probably the most notable one.

00:15:35.460 --> 00:15:44.580
And so when you leave, what it does is it hooks up the keeping track of the data so that when you exit the block, it can clean up after itself.

00:15:45.120 --> 00:15:46.480
And so really handy things.

00:15:46.480 --> 00:15:49.920
I've seen a lot of different tutorials on how to write them.

00:15:49.920 --> 00:15:52.540
And a lot of them also, they go through the class.

00:15:53.040 --> 00:16:02.620
So in general, the punchline is use the context manager, context lib.contextmanager decorator, and use a yield statement in the middle.

00:16:02.620 --> 00:16:04.680
And that will help you out.

00:16:04.680 --> 00:16:07.140
That's really the working way to do it.

00:16:07.520 --> 00:16:14.020
But if you want to write, you write a class-based one with the dunder init, dunder enter, dunder exit.

00:16:14.020 --> 00:16:16.120
I think those are good examples.

00:16:16.120 --> 00:16:20.960
One of the things I liked about this tutorial is that it went through that, and it didn't seem artificial.

00:16:20.960 --> 00:16:23.560
It seemed, it's like, this isn't one way to do it.

00:16:23.560 --> 00:16:26.760
But it went through it pretty quickly, and we went through some other stuff.

00:16:26.760 --> 00:16:28.500
And it's a pretty quick tutorial.

00:16:28.500 --> 00:16:36.680
But then it gets into some really fun stuff that I really appreciated, like context managers as decorators.

00:16:37.240 --> 00:16:38.320
And writing your own.

00:16:38.320 --> 00:16:43.000
And then create, so that you're not using a decorator to make a context manager.

00:16:43.000 --> 00:16:46.320
You're actually creating a decorator that is a context manager.

00:16:46.320 --> 00:16:48.160
And that's a pretty interesting thing.

00:16:48.160 --> 00:16:54.400
And then wrapping things and nesting context managers with block or with statement.

00:16:54.400 --> 00:16:57.820
Yeah, that's cool to have like three of them instead of just one.

00:16:57.820 --> 00:17:00.800
Rather than like having three with blocks, right?

00:17:00.800 --> 00:17:02.140
Somehow I just missed that.

00:17:02.140 --> 00:17:02.600
Yeah.

00:17:02.600 --> 00:17:02.960
Yeah.

00:17:02.960 --> 00:17:05.420
And I've just nested the with blocks.

00:17:05.420 --> 00:17:06.720
But you don't have to do that.

00:17:06.720 --> 00:17:09.720
You can have them all on one line, which is cool.

00:17:09.720 --> 00:17:11.300
Yeah, there's a lot of cool little tips here.

00:17:11.300 --> 00:17:12.420
And then combining them.

00:17:12.420 --> 00:17:18.980
So like creating context manager that's really a combination of two other context managers or more, more than one, which is nice.

00:17:18.980 --> 00:17:21.080
And then you kind of get into this, right?

00:17:21.080 --> 00:17:23.040
And you think, well, what am I going to do with this?

00:17:23.040 --> 00:17:24.160
Where would I use it?

00:17:24.580 --> 00:17:28.000
And so there's three examples that he lists and shows.

00:17:28.000 --> 00:17:34.620
There's context managers with a SQLAlchemy session, which is a really cool idea.

00:17:34.620 --> 00:17:35.120
Yeah.

00:17:35.120 --> 00:17:36.100
I love this one.

00:17:36.100 --> 00:17:36.280
Yeah.

00:17:36.280 --> 00:17:36.660
Yeah.

00:17:36.660 --> 00:17:44.420
How to use rollback and session so that when you're testing and stuff, you can just automatically undo the thing that was in the block.

00:17:44.420 --> 00:17:45.420
Sweet idea.

00:17:45.420 --> 00:17:58.040
Using it for exception handling so that you can end that in combination with using it as a decorator is a neat idea to have a policy for how to deal with certain exceptions during parts of your code.

00:17:58.060 --> 00:18:02.040
And then just decorate those functions with exception handling.

00:18:02.040 --> 00:18:02.780
That's pretty cool.

00:18:02.780 --> 00:18:07.800
And then the last one was talking about persistent parameters across HTTP requests.

00:18:07.800 --> 00:18:15.720
So it goes from very gentle to really deep into using this well pretty quick, but it's really easy to read.

00:18:15.720 --> 00:18:16.020
Yeah.

00:18:16.020 --> 00:18:21.260
Well, you know, I realize reading through this that I've not been using the decorator style nearly enough.

00:18:21.260 --> 00:18:25.060
I'm always like, oh, I'll just add a class with an enter exit type of thing.

00:18:25.200 --> 00:18:29.740
But yeah, the context managers, you just get a function and do, you know, it's pretty clean.

00:18:29.740 --> 00:18:30.060
Yeah.

00:18:30.060 --> 00:18:33.080
It reminds me a lot of pytest fixtures.

00:18:33.080 --> 00:18:33.680
Yeah.

00:18:33.680 --> 00:18:34.460
Yeah, for sure.

00:18:34.460 --> 00:18:35.440
That's a great article.

00:18:35.440 --> 00:18:35.940
I like it.

00:18:35.940 --> 00:18:37.400
I'll definitely have to study that one up.

00:18:37.400 --> 00:18:46.860
So previously we spoke about NB Dev, which takes Jupyter Notebooks and allows you to do a whole bunch of cool things with them, right?

00:18:46.860 --> 00:18:49.920
You can export the stuff into a script.

00:18:50.100 --> 00:18:58.100
You can have it strip out some of the metadata, the saved output, which is like the bane of all GitHub committed notebooks.

00:18:58.100 --> 00:19:03.620
Because every time you rerun it, if it's taking variable input data, it's going to have different metadata.

00:19:03.620 --> 00:19:07.920
So every run is a conflict, a merge conflict, which is no fun.

00:19:08.780 --> 00:19:12.280
So that thing solved a bunch of those types of things.

00:19:12.280 --> 00:19:15.880
But Clement Roberts sent over a message and said, hey, that's really cool.

00:19:15.880 --> 00:19:17.000
And NB Dev is great.

00:19:17.000 --> 00:19:24.060
But if you're looking just to do the stripping of the metadata, there's a project called NB Strip Out, which is pretty clever.

00:19:25.180 --> 00:19:29.500
And yeah, you can just set it up as like a git pre-commit hook.

00:19:29.500 --> 00:19:37.840
And then every time you commit your stuff to GitHub, it automatically just strips it out so that you never run into any of those merge conflicts.

00:19:37.840 --> 00:19:39.380
No, hooking up as a pre-commit hook.

00:19:39.380 --> 00:19:40.120
That's a great idea.

00:19:40.120 --> 00:19:40.460
Yeah.

00:19:40.460 --> 00:19:40.800
Yeah.

00:19:40.800 --> 00:19:50.640
So you can either run it from the command line or once you're in a GitHub repo and you've pip installed NB Strip Out, you just say NB Strip Out --install.

00:19:51.060 --> 00:19:51.440
That's it.

00:19:51.440 --> 00:19:56.240
Now it's a git pre-commit hook and it'll take care of doing all the things for Jupyter Notebooks.

00:19:56.240 --> 00:19:56.860
Oh, nice.

00:19:56.860 --> 00:19:57.160
Yeah.

00:19:57.160 --> 00:20:05.900
So it basically is the same as going to Jupyter saying clear all output in the UI, but it just does it as you try it, you know, only as you save it to GitHub, which is cool.

00:20:05.900 --> 00:20:09.780
And then there's also a YouTube tutorial, right?

00:20:09.780 --> 00:20:14.140
We've said that it's really cool to have screenshots of like UIs.

00:20:14.140 --> 00:20:15.700
Well, this is also really nice.

00:20:15.820 --> 00:20:25.200
So if you go actually to the PyPI listing, there's like a YouTube video right there that shows you like a four minute tutorial of like why you should care about this.

00:20:25.200 --> 00:20:27.120
And I've done that super useful.

00:20:27.120 --> 00:20:28.420
I'm like, oh, this is kind of interesting.

00:20:28.420 --> 00:20:29.000
Let me watch it.

00:20:29.000 --> 00:20:30.200
I'm like, yep, that looks useful.

00:20:30.200 --> 00:20:31.360
We should talk about it.

00:20:31.360 --> 00:20:32.500
Really nice.

00:20:32.500 --> 00:20:32.700
Yeah.

00:20:32.700 --> 00:20:33.020
Nice.

00:20:33.160 --> 00:20:33.300
Yeah.

00:20:33.300 --> 00:20:39.720
Anyway, so if people are working with Notebooks and they're having this merge conflict issue, it's the saved output.

00:20:39.720 --> 00:20:42.320
People forgetting to clear the output before they commit it.

00:20:42.320 --> 00:20:43.720
Don't make them remember.

00:20:43.720 --> 00:20:47.080
Just do mbstrip out --install and you're golden.

00:20:47.080 --> 00:20:50.920
In episode 179, we had Guido on, which was totally a lot of fun.

00:20:50.920 --> 00:20:55.280
One of the things he brought up was the 2020 Python Language Summit.

00:20:56.260 --> 00:20:58.500
And it was really interesting to listen about that.

00:20:58.500 --> 00:21:04.860
But if you want to read more about it, there's a pretty good write up of all the topics I talked about.

00:21:04.860 --> 00:21:08.500
So we're linking to a post that has links to other posts.

00:21:08.500 --> 00:21:18.500
We've got things like should all strings become f strings and using the peg parser and replacing CPython's parser with the peg parser and different things like that.

00:21:18.600 --> 00:21:28.140
And even some of the lightning talks, just little snippets of kind of what was talked about and kind of like a news article feed of what's going on.

00:21:28.140 --> 00:21:38.600
And I found it really interesting and helpful to be able to kind of pay attention to what's going on at the Language Summit and what's going on with the language going forward to keep up with everything.

00:21:39.120 --> 00:21:49.740
I also wanted to bring up that there's been notifications recently about there's a voting coming up for the board of directors for the Python Software Foundation.

00:21:49.740 --> 00:21:56.320
And so the PSF and some of the board of directors did a video on what this feels like and what does it mean to do that.

00:21:56.320 --> 00:22:05.920
So we're linking to the video and a link to the information about nominations because nominations are open for new board members up until the 31st of May.

00:22:05.920 --> 00:22:06.560
Oh, that's cool.

00:22:06.560 --> 00:22:11.740
Yeah, it is a little bit mysterious to me what the PSF board of director folks do.

00:22:11.740 --> 00:22:14.680
I mean, I can imagine, but I don't really know for sure.

00:22:14.680 --> 00:22:17.740
So it's cool that they've got a video on talking about that.

00:22:17.740 --> 00:22:20.160
Yeah, if you know people who should be part of it, nominate them.

00:22:20.160 --> 00:22:21.240
That's cool.

00:22:21.240 --> 00:22:21.520
Yeah.

00:22:21.520 --> 00:22:22.720
Assuming they want to be nominated.

00:22:22.720 --> 00:22:25.020
Awesome.

00:22:25.020 --> 00:22:25.380
All right.

00:22:25.380 --> 00:22:27.040
Well, I guess that's it for all our items.

00:22:27.040 --> 00:22:27.920
You got anything extra, Brian?

00:22:27.920 --> 00:22:28.680
I don't.

00:22:28.680 --> 00:22:29.980
I've just been working along.

00:22:29.980 --> 00:22:30.640
How about you?

00:22:30.640 --> 00:22:31.640
Two quick things.

00:22:31.640 --> 00:22:32.660
Follow up.

00:22:32.660 --> 00:22:37.140
We talked about Austin, the profiler, which is awesome.

00:22:37.140 --> 00:22:40.980
Does CPU profiling, also memory profiling.

00:22:40.980 --> 00:22:42.140
Remember, it had the TUI.

00:22:42.140 --> 00:22:43.780
It had the web GUI.

00:22:43.780 --> 00:22:45.700
It had all the different user interfaces.

00:22:46.420 --> 00:22:50.440
And one of the ways you could view it, one of the many ways you could view it was through

00:22:50.440 --> 00:22:51.340
SpeedScope.

00:22:51.340 --> 00:22:52.480
It's cool.

00:22:53.140 --> 00:23:00.740
So Wendell Bauman sent in a script that he'd created called PySpeedScope, which will let

00:23:00.740 --> 00:23:06.140
you generate one of these SpeedScope files that you can then visualize from Python, from running

00:23:06.140 --> 00:23:06.380
Python.

00:23:06.380 --> 00:23:11.780
So anyway, I'll just link over to his GitHub repo for PySpeedScope, which looks pretty cool.

00:23:11.780 --> 00:23:14.460
Also, I updated our search engine.

00:23:14.860 --> 00:23:19.980
I realized that when you search for stuff over at Python Bytes, it would give you good results,

00:23:19.980 --> 00:23:24.160
but it would just present them kind of as if they were all equal.

00:23:24.160 --> 00:23:25.580
So now it ranks things.

00:23:25.580 --> 00:23:27.380
So I added ranking to our little search engine.

00:23:27.380 --> 00:23:31.780
So now if you search for stuff, it's more likely to give you good results.

00:23:31.780 --> 00:23:34.420
Well, that's cool.

00:23:34.420 --> 00:23:37.920
Without ranking, isn't it just pulling up random lists of things?

00:23:37.920 --> 00:23:40.600
Well, I mean, everything fit in there, right?

00:23:40.600 --> 00:23:45.440
If you search for everything that came up had, like if you search for, I don't know,

00:23:45.440 --> 00:23:49.200
Jupyter, it would have to have Jupyter in it if it came up as a result.

00:23:49.200 --> 00:23:54.540
But for example, if Jupyter was in the title or just like a random, and here's an example,

00:23:54.540 --> 00:23:57.320
Jupyter notebook versus the topic is about Jupyter.

00:23:57.320 --> 00:23:59.960
Like they would show up in whatever order they just came back.

00:23:59.960 --> 00:24:03.420
Now it's like the stuff that's about it more specifically shows up first.

00:24:03.420 --> 00:24:04.380
Oh, very helpful.

00:24:04.380 --> 00:24:05.320
Yeah, indeed.

00:24:05.320 --> 00:24:06.740
So hopefully that's a little bit helpful.

00:24:06.740 --> 00:24:07.880
I use that all the time.

00:24:07.880 --> 00:24:08.340
I know.

00:24:08.940 --> 00:24:09.840
That's why I did it.

00:24:09.840 --> 00:24:11.000
I'm like, there's this thing.

00:24:11.000 --> 00:24:11.840
I know it's in here.

00:24:11.840 --> 00:24:13.360
And why are there so many results?

00:24:13.360 --> 00:24:16.280
It should be right at the top because the title is basically what I search for.

00:24:16.280 --> 00:24:17.060
Yeah, exactly.

00:24:17.060 --> 00:24:19.820
So this is for us, but people can benefit as well.

00:24:19.820 --> 00:24:20.260
Definitely.

00:24:20.260 --> 00:24:20.740
All right.

00:24:20.740 --> 00:24:21.440
You got some jokes?

00:24:21.440 --> 00:24:27.260
Yeah, these are definitely groaners, but they're submitted by friends of the show on Twitter.

00:24:27.260 --> 00:24:28.600
So I appreciate this.

00:24:28.600 --> 00:24:30.420
So a couple of them.

00:24:30.420 --> 00:24:36.960
Due to social distancing, I wonder how many projects are migrating to UDP and away from TLS

00:24:36.960 --> 00:24:38.420
to avoid all the handshakes.

00:24:38.720 --> 00:24:40.320
Well, we have to, right?

00:24:40.320 --> 00:24:41.120
Yeah.

00:24:41.120 --> 00:24:43.460
You don't want to get a computer virus.

00:24:43.460 --> 00:24:45.940
Next, a chef and a vagrant walk into a bar.

00:24:45.940 --> 00:24:49.800
Within a few seconds, it was identical to the last bar they went into.

00:24:49.800 --> 00:24:52.680
I got it.

00:24:52.680 --> 00:24:58.860
So vagrant manages virtual machines and chefs helps set up, configure those environments.

00:24:58.860 --> 00:24:59.320
Got it.

00:24:59.320 --> 00:25:00.540
Okay.

00:25:00.540 --> 00:25:01.100
Anyway.

00:25:01.100 --> 00:25:01.760
So.

00:25:01.760 --> 00:25:02.420
Yeah.

00:25:02.420 --> 00:25:07.680
I like how the, you're leaving somewhat understanding these as an exercise of the reader.

00:25:07.680 --> 00:25:10.980
And partially I'm ruining their joy of solving the problem.

00:25:11.480 --> 00:25:11.960
Yeah.

00:25:11.960 --> 00:25:14.800
No, it's all good.

00:25:14.800 --> 00:25:18.620
I took me, both of these took me a little bit of Googling to understand.

00:25:18.620 --> 00:25:18.980
Beautiful.

00:25:18.980 --> 00:25:19.640
I like them.

00:25:19.640 --> 00:25:22.940
They're, they're definitely groaners, but they do kind of make you think for a second as

00:25:22.940 --> 00:25:23.620
well, which is great.

00:25:23.620 --> 00:25:23.940
Yeah.

00:25:24.300 --> 00:25:25.260
So thanks a lot.

00:25:25.260 --> 00:25:25.520
Yeah.

00:25:25.520 --> 00:25:25.960
You bet.

00:25:25.960 --> 00:25:26.560
I think we're done.

00:25:26.560 --> 00:25:26.840
Thanks.

00:25:26.840 --> 00:25:27.320
See ya.

00:25:27.320 --> 00:25:27.540
Bye.

00:25:27.540 --> 00:25:29.580
Thank you for listening to Python Bytes.

00:25:29.580 --> 00:25:32.040
Follow the show on Twitter at Python Bytes.

00:25:32.040 --> 00:25:35.080
That's Python Bytes as in B-Y-T-E-S.

00:25:35.080 --> 00:25:37.960
And get the full show notes at pythonbytes.fm.

00:25:37.960 --> 00:25:43.040
If you have a news item you want featured, just visit pythonbytes.fm and send it our way.

00:25:43.040 --> 00:25:45.080
We're always on the lookout for sharing something cool.

00:25:45.080 --> 00:25:46.260
This is Brian Okken.

00:25:46.480 --> 00:25:50.440
And on behalf of myself and Michael Kennedy, thank you for listening and sharing this podcast

00:25:50.440 --> 00:25:51.520
with your friends and colleagues.

