00:00:00 Hello, and welcome to python bytes where we deliver Python news and headlines directly to your earbuds. This is Episode 296, recorded August 9 2022. I'm Michael Kennedy.

00:00:10 And I'm Brian rockin, Hey, Brian,

00:00:12 we have a new sponsor, I just want to say thank you to Mozilla and the IRL podcast for sponsoring the show. I used to check them out by them by side FM slash IRL. And more on that later. Now I want to hear what you've discovered to share with us. Can you constrain your excitement?

00:00:28 Yeah. I want to talk about PIP constraints. So there's a I think I knew about PIP constraints, but I kind of forgot about them. But there's an article called pics PIP constraints files by somebody named luminous min. So this is what so that they're kind of neat. So one of the things, I was just using Pip requirements.in file recently, in a course that I'm taking, and I like we're using requirements that in to generate my requirements, that txt file. But there's and then there's, there's a yeah, anyway, that uses PIP tools. So you have to get PIP tools. But so there's that. And then there's also pinning, so if, especially with applications, we see it more in applications, less in less than libraries of pinning the application, but you can, even in libraries, there's a there's regularly sort of constraints around stuff to say, hey, for this library, I need this this range of versions, or it has to be greater than this or something, because I'm depending, and that's fine. But this is a way to say not what libraries I want to want to use. But if I use a library, which version so we're considering changing the version without saying I want the library. So and in the actually in the PIP documentation. It says constraint files or requirement files that only control which version, not whether or not it's installed. So how would you use this? So this, this article talks about it, and it basically says you kind of use it normally, pip install requirements. txt, but you might have, if you do like a freeze, for instance, or something, or you just pin everything, you might have all of the versions, but you might only want like, constraints on like one of them, say, let's say you want your including pandas, but you want a certain version of pandas or our you want a certain version of NumPy, even though pandas requires NumPy, or something like you can have constraints file that lists, this just looks like a pip freeze file. But you can, you can put like less than or less than equal if you want, or in you don't have to have everything. So you could just pin one of the things. And that way, like let's say you were doing pandas, and you wanted to constrain NumPy to be a certain version of NumPy, you can do that with the constraints file and not have it not have to specify everything, just have it be separate. And the kind of the article talks about actually just sticking the constraints specifying your constraint file within the requirements file. And that way, they're separate. And, and I was thinking about that. And that's an interesting thing to say that dependencies of my application don't change. But the constraints might because of testing or whatever. And this, this separating of these two files would help with like, you know, when you have the two files of version control, you've changed your constraints, but you haven't changed really what you're depending on just the versions of those. So it's kind of neat to have that separate possibility. So

00:03:29 yeah, so for people who are listening, literally, the first line of the requirements dot txt file is dash dash constraint constraints that txt, which I had never considered doing that that's interesting.

00:03:39 And then one of the things I thought is, but I'm not in this works if your handwriting your requirements file, but what if you're, what if you're not what if you're, you're using requirements that in instead, and this article doesn't go into it, but I tried to just instead of putting that constraint thing in a in a requirements dot txt file, putting it in requirements done in and using PIP compile to generate it, and it the PIP compile seems to also watch the Look at this. So it this constraint works does PIP compile as well? Okay, so that's, that's cool. Yeah. So kind of a neat thing to check out. The usage of it's pretty easy. Just, yeah, anyway, pinning your requirements is good, but don't pin them too tight. If especially for applicate for for libraries, and then for applications. Yeah, I kind of like this, because there's a lot of times where I know there's a bug in something, or I've heard about it, or it or I haven't gotten around to fixing my code to deal with the new version yet. So I'm gonna pin something and I don't necessarily need to pin everything, I just need to pin certain parts of it. So that's kind of neat.

00:04:49 I like this. Just also a little bit of a sidebar with the PIP compile from PIP tools. You know, you give it the end file and it generates the TXT file and it basically obliterates that exe file whatever is there previously. Yeah. And that can be a hassle, especially if you want to have like a requirements dot dash Dev, and then a production requirements. And if you install the the dev, the dev one, you want to also pick up like a dash R on the main ones. And the PIP tools blows that away. So what I ended up doing a lot for my workflows is having PIP tools generate some base txt file, and then having like requirements, dot txt, just have a dash, our requirements production, and then the dev, AV dash our requirements that, you know, broad, like sort of like put those commands just in real simple and have it actually generate a separate file. So it kind of makes it a little bit messy, but it gives you lots of flexibility.

00:05:41 Cool. Yeah, yeah. That's neat.

00:05:45 Yeah, maybe I should actually blog something like in the last three years blog. Yeah. What is that? Is that with words, written words, not spoken words, painful on the audience says, Does it take over requirements? Like if PIP would resolve NumPy to one dot 19? And you say at 120? It sounds to me like it does. But what do you think Brian?

00:06:04 Well, like I tried it with typer. So I knew I know, typer pulls in, click, for instance. And they're both command line things. Yep. And so then I said, Okay, well, well, the TypeR has a broad range of like things they can do. And if I constrain clicked to be a lower number, will it work? And I blew everything away and tried it again. And sure enough, it it did it like add those extra constraints on top of even like, so I was, I was only declaring typer. But type was specifying click, and I could specify which version of click I wanted. So yeah, this is cool. Yeah. It's, I guess, what? Adding one more complexity to your packaging, workflow. So but it's useful if you'd like stability?

00:06:48 Yes. Good flexibility. All right. Well, I'll cover something simple async caching simple. It is simple, in a sense. Okay, we've had, we have some nice stuff built into Python, like async, sorry, with like func tools, and the LRU, cache and whatnot. But from what I understand, those are synchronous, only. Basically they're decorators, those decorators, wrapped functions. And the decorators themselves are synchronous. And so it only makes sense for them to wrap sync functions. Yeah. Okay. And so if you have an async function, but you want to do the LRU cache, where you just put the decorator LRU cache, and then if it gets called with the same arguments, again, it doesn't even call the function, it just goes, You know what you already call it with that? Here's the answer. So like, if you're in a tight loop, and you're pulling in some values, and you got to compute something with it through a function, but there's a good chance of repeat of those values, you can put an LRU cache in long as that pretty deterministic, and you call it again, you expect the same output, you can make it fly by just adding one of those caches on it, right. So short version of this is, this is the same idea, but for async functions. So I can have some function, I want to call and I just say at LRU cache, and this will give it a maximum size of results that it's willing, you know, inputs and matched up results, it's willing to cash up. And then if you call it with the same arguments, it'll give the same response back. So that's pretty cool. That's the last used version. And then you also have time to live a time to live an async TTL. So you can say any results, I don't care how many I've used, but just within the last 60 seconds. And one thing that's really, really nice about that is it will expire results. So maybe you're calling an API, and you want to do rate limiting, but you know, you only want to be called maybe once a minute, right? That will both make your code faster, but also not overrun your rate limiting that you might have with your API key, and so on. So here's a real simple way to add rate limiting is just a time to live, I guess you've got to have the same input arguments, but you know, assuming that you have the same arguments. That's that's one way to do it. And you can also specify the max size, which is pretty cool. Yeah. Or

00:09:02 if you're grabbing something off of a service, like, what's the, what's the temperature out? I don't really care if it fluctuates every second, but every minute, I might check it sort of thing.

00:09:14 Yep, yep. Precisely. And I don't there's not a TTL and all those kinds of things.

00:09:18 So there's not a TTL on the normal LRU cache. Is there? I don't believe so. Yeah, so that's actually cool. I like it.

00:09:28 I do too. I like that that really resonates with me. The other thing that's pretty cool here is you can pass a war M objects and pass request objects, you can pass custom classes, even if the classes are not hashable. It will still go through and actually so one of the problems you can run into is if you have say if you've got a customer object or product object or something, you call it once you've created this object, maybe you got it from the database, and you say call the function with LRU cache and it says well, what object is this? Have I seen it before? Maybe yes or no. And then you call it again, it might have the same effective value, but it's not actually the same object. But you might get it from the database again. So it has a different pointer, a different ID and so on that I'm not sure what the behavior there is. But this one will actually look and see, oh, is it actually a class? Well, then let's just get the dictionary and use the dictionary, the underlying field Dictionary of the class to use as the match to see if I'm calling it again. So there's some really cool functionality here. Simple little class. But if you want to quickly add some performance boost async functions, you can add this.

00:10:38 Oh, nice. Okay,

00:10:39 this is neat. Yeah, yeah, that's right. Yeah, thanks. Also, it's entirely possible. I don't think it does. But it's entirely possible to add async and synchronous support to a single decorator. If if you need to write, for example, I have the what was it called the Emilian templates, fast API, one that I created. Let's see, look at that. Number one result, what a search search thing. So there's. So there's this fast API chameleon framework or library that I created that allows you to just do a decorator and say dot template and put a HTML template in the chameleon language on a fast API response. And it returns a dictionary that just turns it into an HTML response. Okay, this one in fast API, you can both have synchronous and asynchronous functions. So this thing has to look and see if the inbound thing is a ko routine and async co routine, and it will dynamically generate the right wrapper, an async one or a synchronous one, based on so it's not super hard. It's it's also not super easy, but I did it so it can be done. Cool. Anyway, that's a little bit of a diversions, but this async cash versus a non async cash. I feel like you know, it could just be it could be one thing if it really, really wanted to be, but I feel like the person who created it prize just like I need this for async methods. Let's go.

00:12:00 Yeah, it's almost kind of too bad that the normal LRU cache doesn't just do it. Oh,

00:12:05 yeah. And, you know, maybe it's been updated to and I don't know, but I don't believe it does.

00:12:09 I don't think so right now. Currently.

00:12:11 Yeah. Yeah. Not that I know of people can write us if we're wrong. And we'll let people know next time be great to great to do it. I'm never wrong. Oh, amen. Because like I said, it's because it's a decorator like you could you could make it start working that way. That's a feature that cool before. Yeah. Before we move on, Brian, let me tell you about AI in real life. Yeah. So this week's sponsor, this episode of Python bytes is brought to you by the IRL podcast, an original podcast from Zillow. So take URL and Mozilla for supporting the show. If you're like us, you care about the ideas behind technology and not just the tech itself. Obviously, we do podcasts on these things all the time. So we love talking about it, thinking about it. And everyone out there knows that Tech has an enormous influence on society. Many of these effects are hugely beneficial. Just think about walking around with your cell phone, you have basically the entire sum of human knowledge just constantly with you. Other influences can have you know, negative effects, and I really appreciate that Mozilla is always looking out for and working to mitigate these types of negative influences tech hasn't always all of us. So if these ideas resonate with you, you should definitely check out their podcast IRL. The IRL podcast is hosted by Bridget Todd and in this season, IRL looks at AI in real life. Who can AI help? Who can add harm? The show features fascinating conversations with people who are working to build more trustworthy AI. So just some of the examples of episodes, there's an episode about how our world is mapped like Google map style map with AI. And what's really interesting is the data that's missing from those maps tells as much of the story as the data that's there. So also an episode about gig workers who depend on apps for their livelihood. And it looks at how they're pushing back against algorithms that control how much they get paid, seeking new ways to gain power, autonomy over data and creating better working conditions. And finally, for political junkies, there's an episode on the role that AI plays when it comes to the spread of disinformation around elections, a huge concern for democracies. You hear a lot about us democracies, but more broadly, absolutely. Across the world. And I just listened to the first episode, the tech that we won't build, which explores when developers and data scientists should consider saying no to projects that can be harmful or strongly against their beliefs, even though sure you could technically build them. Just because you can, you should do anyway, if this sounds like an interesting show, try and observe for yourself. Just search for IRL in your podcast player or visit Python bytes.fm/irl links in your podcast player show notes and thank you to IRL and Mozilla for supporting our show was strong.

00:14:52 Yes, thanks. So I want to talk about organizing your code to actually organizing your Python code. Pain of structure structuring projects and everything. But there's more than that. So I ran across this article called organized Python code like a pro. And yes, it's got a lot of great advice. And it's opinionated. It's by one person, of course, but but I think it's, it's, for the most part, really good stuff. And also, a couple of things that I don't normally see in these kinds of articles. And there's not too much weird stuff. So sometimes, it's, sometimes it's a little too opinionated. But this is obviously where you can see where some of the opinions are hold held. So take a look at it talks about structuring your project. For instance, one of the first things is use a source directory SRC. And so I tried to do this, and I used to do it because there was a, there was an article about, about having your tests be seen. So basically, if I, if I'm doing a pack installable package, I'd like to have my tests, see the installed package, not the local files. And that happens sometimes if you're running like, say, pi test or unit test from the top level directory, and it might, it might see the top level module, and you don't want to do so as sources a way to hide that. But there's ways to get around that and testing. So I don't, I don't really, it's not really a solid solid argument as it used to be this argument really is just, it looks nice. In your, in your code editor that you if you if you like, here's an example of a non non source project where you have a couple of modules within the project. And but alphabetically, they fall below there around your your, you've got your test directory in your pipe project at tamo. And your source codes on both top and bottom of that, that's confusing. So I actually kind of love this simple argument of just combine all the sources in one place. It's nice. So they, I feel like that's you. I know, the first reaction to this though, is you're gonna put a package all the directory anyway, and having a package level directory in there instead of your, if you have a package instead of this, you know, source or something that works too. But anyway, it's kind of interesting. The one thing that that kind of gets me and it shows up here is this. This, this author is considering what I, we have a problem in Python of what what a package is a package is something I install from pi pi. But it's also within this Python documentation. Sometimes it's just a directory with an init file in it. I don't know how you So Python or Michael, you teach people about that? Do you ever, like do stumble with this part, or just

00:17:36 seems complicated and overly simplistic? For me? I think one of the challenges really I often run into is, how do I organize my files? If I want like a sub module? I want simple import statements. You know, so Okay, so do you think I don't have? Yeah, what

00:17:54 do you think of directories? With stuff directories within a net as a module or as a package? Or do you use do

00:18:01 I too, but often I, I tried to dodge that bullet and just not not talking about really good. Yeah, well, honestly not talking about it. If you're building a library, this matters very, very much. If you're building an application, a web app, or CLI app or something, often it doesn't matter. Because you just running the top level, some top level like main or app.pi, or something in it, it'll just pick it up, whether it's a module or a package, or just a directory.

00:18:29 So I guess, um, regardless of like, what we call directories, whether we call them modules, or packages, this, this article calls the module. So then it goes on to talk about some other cool stuff. Let's let's go down naming things. So it talks about, there's really no files, there's, there's modules. So it also also there's no directories, they're all modules, but the that's okay. So this is some of the opinion stuff that you can, it's interesting, you can skip over it. But the the thing that I thought was interesting is these module names, they should be the could be plural names. And I never thought about that. And that it kind of makes sense. Like, if you have it gives an example, like drivers, drivers will be a module. Yeah, you'd probably be the s on there make sense? So it says, you know, keep it keep config and main as as single. But most things have an S on the end. I never really thought about that before. But it does make sense of like, from crawler storages import gets storage or something. I don't Yeah, yeah. It's just a nice little extra thing. Then talks about naming functions and stuff. So functions, I this is something people get wrong all the time. So it's good to talk about it. Name your functions with verbs. It makes your code a lot clearer if your functions or methods or verbs and unless you have to jump through giant hoops to make it work. But if you have to jump through hoops to make a verb work, maybe it's not really one function, maybe it should be two or three, but we'll see it Do

00:20:00 ya or property instead of Yeah,

00:20:02 or property and right. And then class names, one of the things I never thought about also was class names should be singular. So classes should be singular unless it says it unless it's really a container. So don't name don't name a class orders, because it's going to describe multiple orders. It's It's an order. It's an order class, not an orders class. So that's a, it's a good thing, that one of the things I loved about this article also is there's two things that we kind of talked about, we use a lot, but nobody, I don't think very many people talk about it too much. And well, it's the Dunder init thing, I'm going to pop down the not the Dunder name equals Dunder main, that's used all the time. And so it's good to talk about that of if you want to execute a module itself, use that. But the if you one of the things I tried to do recently that I kind of didn't know how to do right off the bat is a directory within a net, if it also has a Dunder main, then you can use the dash m thing on it. So if you include like Dunder main, then you can use like, Python Dasha him module name,

00:21:11 when you're interesting. So okay.

00:21:14 Because I had a, I had a library I was working with, and it was like, I'm, I'm using dash M for everything else. I'd like to have the entry point for my application be usable if I do dash m also, how do I do that? And this is how you do it. So it's kind of neat to have this in right away, because I don't know if it's really a beginner thing, but it's still kind of cool.

00:21:35 Yeah, I like it a lot. It's like entry points, but simpler. Yeah.

00:21:39 Anyway, so decent, decent article. There's some some opinions there. But that's okay. We like opinions.

00:21:45 Absolutely. We do we do. Alright, well. Do you know what else we like Brian? Follow up?

00:21:50 Yeah, I was gonna do this. I'm glad you're doing it. Too late.

00:21:53 I grabbed it. I grabbed it, because this one is a good one. So remember, last week, you spoke about CLI apps and doing o auth. And you've got to remember the tokens you get the example you gave us from Twitter, but it could be from all over the place. So different, we got to multiple pieces of feedback, one about encrypting the stuff that goes into your user profile. I can't remember who would apologize about forgetting the name. But someone sent in a message that says, well, the AWS CLI just puts your token straight there unencrypted. So there's that. I said, Maybe we should encrypt them somehow. And I agree with that. Still, but Trencin in this project called key ring, and key ring is earring or vault vaults, those types of things through ways sort of more managed Central Stores of this type of information. Right on Mac OS, you hear it, put it in your OS X keychain, right? You probably heard that, or the Windows Credential store or those those things that the actual operating system is protecting from other apps to go look at it. But it's basically just encrypted. Yeah, login password, or tokens, yeah, to this hearing thing that just did was is something like that. But it works to Python library. It works across platform, and it works with different backends based on both what platform you're on and other things you might decide. So it's a library that gives you access to system carrying services from Python, which I think is fantastic. So on Mac OS, that's keychain. On Linux, it's the Secret Service, or the KDE four or 5k. Wallets. And then on Windows, it's the Windows Credential Locker. Okay, right. And so in there, you can just call set password and get password. And off it goes. And that's pretty much it, right? But it's storing it in a nice encrypted, not just encrypted, but protected access way for the OS.

00:23:49 Yeah, so I actually forgot about this, where I actually use this for testing all the time. But I never thought I didn't think about using it for a command line application.

00:24:00 It's okay to use it for testing.

00:24:02 So we have kept some of the issues that are we have, we have different devices that we're testing against that are password protected devices. And so you have to in order to access them, you need to log in and password to run run commands against them. And then so to be able to do that we need the like the if you're SSH into something or something like that, as part of your process. You've got to you've got a you have to have those credentials somewhere. And we don't want them in our source code. That's the gist of it is we don't want to we don't want them just to be Yeah, we don't want them in the source code and checked in to get lab and to have the whole company be able to read them. It's still protected it internal thing but maybe you're on GitLab or GitHub or something and it's a public repo, you don't want your passwords right there, but you can have them stored on your local machine and then pull them out with Geary. Right it's surprised me a little bit that they're just that good passwords of thing. I kind of expected it to be like a, like, get the get the password hash or something. But I have to remember, this isn't this isn't verifying passwords, it's having them to be able to send them to another system.

00:25:16 And ideally, that one is storing the hash, not the real. Yeah, exactly. So yeah, yeah. I don't know where to see.

00:25:23 So I don't know if this would be. This is still cool. And I'm glad we're covering it. But I was my original question was around is this, what's a reasonable thing to store passwords for sessions for command line application? And I don't know if keyring would work, but I haven't tried it yet. And maybe if you have a set password, maybe it will work. Maybe it stores something locally. So off to try it.

00:25:44 Yeah, I think that it will. Okay. The question that I was wondering is, what about the get password? You know, is that restricted to the process that put it in there? Yeah, there's anything running on yet? Yeah, exactly. Okay. Can you just start arbitrarily asking for stuff, probably some restrictions there, but I don't know exactly what they are. hinfo out in the audience says, I'm not mistaken. Poetry is using its fits installed. So that's where your peipsi credentials get installed. And you can check out issue 210 from poetry. And here somewhere says, they talk about ways in which you could store and it says why not just make key ring a dependency? Okay. If this approach, why not simply make hearing intervention and so on. And so yeah, it talks about basically using this to store your IPI credentials. And that's the CLI up perfect, then we have it sounds like a good match. Yeah. Nice, simple. Yeah, you can just follow along what they're doing there. So thank you, Penfold for pointing that out. Yeah. Well, anyway, I don't currently have any use for this. I think it might be useful. Even outside of I have this interactive application, for example, storing secrets, you know, if you want to have the database connection string to your app, right, this might be a good way to do it. And one other thing that's interesting is you can have third party back ends. So you could have just encrypted text files could have the D bus API for Linux. Google seats, I don't know about this, but for use with IPython secrets of maybe encrypts them. But more realistically, we've talked about bit Warden before open source Password Manager, which is really nice. I use that for a few things. So that has a CLI aspect. So you can have bit Warden as a back end, you can write your own as well. And one password has a CLI option as well for storing SSH keys even so you could even put your SSH keys in there. And we might not know if this would pull it back correctly. But there's a lot of ways to store things and say one password and then access it with a CLI and maybe you could plug this in. So it just it's another provider, which is cool. Yeah, yeah. Anyway, seems really nice to me. If I have a use for it, I'll definitely look into it more. Cool. Nice. Yep. All right. Hey, that might be all of our topics for the day, huh? I think so. Yeah. Have you got any extras?

00:28:03 I just, I just wanted to say that I am. I'm working on a couple things. I'm editing my PI test course, of course. Still working on that. But the other thing that I just started, which I'm super excited about is I just started taking a fast API course. Oh, yeah. It's really neat. The instructors awesome. Yeah.

00:28:23 Awesome. Yeah. Thank you that yeah, that's the fast API course, this live course that I'm doing this week and next week, right?

00:28:29 Yeah. Yeah. So I'm taking it from Michael. And if anybody if anybody is, you've never taken, taken one of the online courses with Michael or a live course. Just really excellent. He's a good instructor. So it's good.

00:28:42 Thank you very much. Yeah. I love it. We're having a good time just playing with code as a group. Yeah. How about you have? I think I have some extras just really quickly here. Brian skin who's been a co host before, send us a tweet and said attention Python bytes. And that went over to this message from Jeff, Jeff Huntley, and it says, a Git lab, are you alright? And this is a link to an article from the register and says git lab plans to delete Dorot projects and free accounts hoping to save a quarter of the hosting costs by bidding repos that haven't been touched for a year. Thanks that that's a little nerve racking, because just because it hasn't been changed, doesn't mean it's not useful. Yeah, yes.

00:29:24 Oh, maybe I keep my recipes up there. And I haven't added any recipes lately.

00:29:28 Yeah, maybe nothing's changed or whatever. So a couple of things. PSA, if you have a Git lab, get Lab project, you know, baby, just touch just add a period to some text file or something and check that in

00:29:42 your own repo with like, trivial prs. Yeah,

00:29:46 exactly. I fixed this misspelling here by changing the word and Thermore Almario Munia. It says they may be reverting this. Okay, so this was just from four or five days ago. And Penfield says yes, they did okay, well, okay, it sounds like we had the same face. Many people had the same reaction that we are going. Oh, boy, this seems like a bad idea. I'm glad this was changed. Yeah. Painful says because of the huge backlash I can imagine. Yeah. I guess I'll have to continue to pay the million dollars extra per year to host things that people put up on there where they said they would host it. Yeah. Well,

00:30:22 hopefully they okay. Even if he did that, hopefully they would like email people at least. Hopefully you're Yeah, exactly.

00:30:28 Yeah. I like Google Voice. Please log in with the next within the next 30 days to keep your phone number or whatever it is, they always did to me. Okay, well, with that, I think, brings us to some jokes. You got some jokes to tell. And I brought a quick one as well.

00:30:43 Okay, go first. Sure. Um, I'm not going to read the ones up here. But I got them. I got a couple of jokes from a place called from a GitHub repo. That's Dad style programming, programming jokes, which is perfect for me. So I got a couple. How do programming pirates pass method parameters?

00:31:01 I don't know with VRR. Awesome.

00:31:05 Okay. Second one. How do you get code? How do you get the code of your bank vault, right? So you can break into the band. Now, you check out their branch has a bad night. So love it. And then one of the things I liked on the top of this, it says Unfortunately, these jokes only work if you get them bad. Oh, so good. And it's a GitHub repo. So that's actually fitting. So anyway, it's very

00:31:31 self referential. very meta.

00:31:32 Okay, how about you?

00:31:34 Here's a quick one. Before I put it up on screen, you know how there's this constant not built here syndrome? Like sure this key ring is cool. But did we build it know that we could build a better keyring than that? And like, we'll get a team together to build key ring, right. So here's a picture of normal people acting like developers. So there's these two construction workers with their hard hats on and there's a screwdriver with a $2 peg on it because it was just purchased. And one guy's outraged. What did you buy a screwdriver instead of building your own from scratch? Exactly. Yeah. Yeah. Pretty good.

00:32:09 Why you're using Hugo, why didn't you build your own blog engine?

00:32:13 Exactly. First, I'm gonna build my own markdown. parser. So I can have better tables. Let's go. Exactly. Yeah, yes, indeed. So all right. Well, excellent podcast, as always, thanks for being here. Thank you. Yeah, you bet. And thank you everyone for listening. Watching. How have you've been part of this?

00:32:30 Yeah. Thanks a lot.

