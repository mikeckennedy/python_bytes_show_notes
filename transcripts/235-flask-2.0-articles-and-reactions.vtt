WEBVTT

00:00:00.001 --> 00:00:04.600
Hello and welcome to Python Bytes, where we deliver Python news and headlines directly to

00:00:04.600 --> 00:00:11.320
your earbuds. This is episode 235, recorded May 26, 2021. And I'm Brian Okken.

00:00:11.320 --> 00:00:12.360
I'm Michael Kennedy.

00:00:12.360 --> 00:00:13.900
And I'm Vincent Wormadam.

00:00:13.900 --> 00:00:19.300
We talked about Vincent a while ago and got his name wrong. And he told us a story that was good,

00:00:19.300 --> 00:00:25.500
that we accidentally pronounced his name, what, Wonderman.

00:00:25.500 --> 00:00:26.320
Yes.

00:00:26.320 --> 00:00:28.640
So sorry about that.

00:00:28.760 --> 00:00:32.680
That's fine. It's fine. I was bragging to my wife that I was on a podcast and then

00:00:32.680 --> 00:00:36.820
I was announced as Vincent Wonderman and she's still kind of philosophical about the whole thing.

00:00:36.820 --> 00:00:42.140
But it was a fun introduction. It's the best mispronunciation of my life. Let me put it that

00:00:42.140 --> 00:00:42.320
way.

00:00:42.320 --> 00:00:45.540
It's your alter ego. It's like your spy name.

00:00:45.540 --> 00:00:47.440
I'll take it.

00:00:47.440 --> 00:00:49.840
Well, thanks for joining us today.

00:00:49.840 --> 00:00:50.640
My pleasure.

00:00:50.640 --> 00:00:52.660
Should we jump into the first topic?

00:00:52.660 --> 00:00:53.780
Sure.

00:00:53.780 --> 00:00:57.200
Okay. Well, I think we covered, we mentioned

00:00:57.520 --> 00:01:04.660
last time that Flask 2.0 was out. And then Michael had, you talked with somebody, didn't you?

00:01:04.660 --> 00:01:16.580
I did. I had David Lord and also Philip Jones on Talk Python to basically announce Flask 2.0 and talk about all their features.

00:01:17.040 --> 00:01:22.220
Yeah. And that was a great episode. I listened to both those. I listened to that. It was great.

00:01:22.220 --> 00:01:45.620
What I wanted to cover was a couple articles or an article and a video. So first off, we've got a link to the change list. So if I actually lost the change list. Yeah, there it is. So you can read through that. And maybe that's exciting to you. But I like a couple other ways. So there's an article by Patrick Kennedy.

00:01:45.800 --> 00:02:10.000
I think that's a good thing. I like a couple other ways. So I like a couple other ways. So I like that. And then a description of the ASGI and why we don't need it yet.

00:02:10.400 --> 00:02:22.500
And I'm not sure that may, I'm not sure what the framework, the timeline is for Flask, if they're going to do it more. But there is a discussion of that. It's not completely ASAC yet.

00:02:22.960 --> 00:02:45.620
There was a lot of discussion with David and Phillip that they may be leaving court to take the place of full-on ASGI Flask. And the idea being that there's a lot of stuff that kind of has to change, especially around the extensions. And you get nearly that, but not exactly that, by using the gevent async stuff that's in regular Flask.

00:02:45.620 --> 00:03:03.500
And that integrates in, if you just do an async def method in your regular Flask. But if you want true asyncio integration, then they basically were saying for the foreseeable future, instead of import Flask and go in that, just import court. And wherever you see Flask, replace it with the word court.

00:03:03.620 --> 00:03:17.080
Okay. But there's other cool stuff other than the async that's coming into Flask 2.0. So I appreciate it. There's also a video from, we don't want it to play, from Miguel Grinberg.

00:03:17.620 --> 00:03:29.860
And talking about some of the new stuff in Flask. And I really like this. One of the things that he covers right away is the new route decorators.

00:03:29.860 --> 00:03:31.640
Yeah, those are nice.

00:03:31.640 --> 00:03:43.100
Might be just a syntax thing, but it's really nice. So you used to have to say app route, and then methods equals post, or list the method. And now you can just say app post. That's nice.

00:03:43.100 --> 00:04:03.020
And then a really clean discussion of the WebSocket support with Flask. And then he goes in to talk about the async. And with that also does a little demo timing it. And I was actually surprised at how easy it was to set up this demo of timing.

00:04:03.580 --> 00:04:21.280
And showing that he showed that you could increase the users and then still get, it doesn't really increase your response time or how many users per request per second doesn't increase because of the way that Flask 2.0 was done.

00:04:21.280 --> 00:04:30.960
But it was nice. And then he also talked about some of the extensions that he wrote to that work with Flask 2.0 and stuff. So it was definitely worth the listen.

00:04:31.080 --> 00:04:41.280
Oh, that's always cool. That's always the thing when you get like, Flask is like a pretty big project. So when there's like a new upgrade of that, one of the things that people sometimes forget is like, oh, like all the plugins, do they kind of still work?

00:04:41.280 --> 00:04:46.600
So it's nice if someone does a little bit of the homework there and says, well, here's a list of stuff that I've checked and that's at least compatible.

00:04:47.120 --> 00:04:58.640
Well, he's mostly doing some, so for instance, one of the things is around which, I don't know, which, just some of the WebSocket stuff has changed and some of the other things have changed.

00:04:59.020 --> 00:05:07.900
And he has like some more, some different shims that he was recommending some things before, but now you don't have to do, you don't have to swap out some things.

00:05:07.900 --> 00:05:17.020
So like, for instance, some of the extensions we're allowing for WebSockets required you to swap out the server for a different server and you don't have to anymore.

00:05:17.020 --> 00:05:18.360
So like that.

00:05:18.360 --> 00:05:19.680
Okay.

00:05:19.680 --> 00:05:20.480
All right, cool.

00:05:20.480 --> 00:05:20.720
Yeah.

00:05:20.720 --> 00:05:23.520
A couple of big other things that come to mind.

00:05:23.520 --> 00:05:27.600
One, they've dropped Python to support and even 3.5 and below.

00:05:27.600 --> 00:05:32.060
I mean, we're at this point where 3.5 is like old school legacy, which surprises me.

00:05:32.060 --> 00:05:32.840
That still feels new.

00:05:32.840 --> 00:05:33.400
Yeah.

00:05:33.400 --> 00:05:34.960
I remember when it came out.

00:05:34.960 --> 00:05:36.040
Yeah.

00:05:36.040 --> 00:05:36.260
Yeah.

00:05:36.260 --> 00:05:38.520
Well, that was when async and await arrived.

00:05:38.520 --> 00:05:38.820
Right.

00:05:38.820 --> 00:05:41.800
So that was a big, the big deal there, but it doesn't have F string.

00:05:41.800 --> 00:05:42.440
So it's.

00:05:42.440 --> 00:05:42.780
Yeah.

00:05:42.780 --> 00:05:43.620
That's the killer feature.

00:05:43.620 --> 00:05:44.540
Yeah.

00:05:44.540 --> 00:05:46.840
Yeah.

00:05:46.840 --> 00:05:47.960
So there's that.

00:05:47.960 --> 00:05:52.340
And they also said that you are not going to need to change your deployment infrastructure.

00:05:52.340 --> 00:05:57.360
If you want to run async flask, you can just push a new version and it's good to go.

00:05:57.360 --> 00:05:59.240
So yeah, a lot, a lot of neat things there.

00:05:59.240 --> 00:06:00.200
Very good.

00:06:00.200 --> 00:06:01.280
Nice.

00:06:01.280 --> 00:06:02.980
What do we got next, Michael?

00:06:02.980 --> 00:06:06.680
Well, what if Python were faster?

00:06:06.680 --> 00:06:07.740
That would be nice.

00:06:07.740 --> 00:06:08.560
That's always good.

00:06:08.560 --> 00:06:10.320
We actually talked about Cinder.

00:06:10.320 --> 00:06:11.440
Remember Cinder?

00:06:11.440 --> 00:06:11.960
Yeah.

00:06:11.960 --> 00:06:14.440
From the Facebook world.

00:06:14.580 --> 00:06:19.460
So that's one really interesting thing that is happening around Python.

00:06:19.460 --> 00:06:21.080
And there's a lot of cool stuff here.

00:06:21.080 --> 00:06:22.700
But remember, this is not supported.

00:06:22.700 --> 00:06:25.560
It's not meant to be a new runtime.

00:06:25.560 --> 00:06:31.040
Just there to give ideas and motivation and examples and basically to run Instagram.

00:06:31.420 --> 00:06:38.260
On the other hand, Mike Driscoll tweeted out, hey, Python might get a two-time speedup of the next version of Python.

00:06:38.260 --> 00:06:43.800
And you might want to check out Guido's slides from the Python language summit at the virtual PyCon.

00:06:43.800 --> 00:06:44.940
That's exciting, right?

00:06:44.940 --> 00:06:45.620
Yes.

00:06:46.620 --> 00:06:52.000
If Guido is saying it, then odds of it happening increase, right?

00:06:52.000 --> 00:06:52.940
Exactly.

00:06:52.940 --> 00:06:53.500
Exactly.

00:06:53.500 --> 00:07:06.960
So a while ago, we actually covered what has now become known as the Shannon plan for making Python faster a little bit each time over five years, over the next four, at least, I guess, four years at that point.

00:07:07.260 --> 00:07:08.360
And how to make that happen.

00:07:08.360 --> 00:07:10.880
So some of these ideas come from there.

00:07:10.880 --> 00:07:12.880
And so here I'm pulling up the slides.

00:07:12.880 --> 00:07:16.320
And Guido says, can we make CPython faster?

00:07:16.320 --> 00:07:17.680
If so, by how much?

00:07:17.680 --> 00:07:18.760
Could it be a factor of two?

00:07:18.760 --> 00:07:20.020
Could it be a factor of 10?

00:07:20.020 --> 00:07:22.900
And do we break people if we do things like this?

00:07:22.900 --> 00:07:32.120
So the Shannon plan, which was posted last October and we covered, talks about how do we make it 1.5 times faster each year, but do that four times.

00:07:32.120 --> 00:07:36.780
And because of compounding performance, I guess, that's five times faster.

00:07:36.780 --> 00:07:37.380
All right.

00:07:37.380 --> 00:07:38.200
So there's that.

00:07:38.200 --> 00:07:40.740
Guido said, thank you to the pandemic.

00:07:40.740 --> 00:07:42.140
Thank you to boredom.

00:07:42.140 --> 00:07:43.740
I decided to apply at Microsoft.

00:07:43.740 --> 00:07:45.800
And shocker, they hired him.

00:07:45.800 --> 00:07:50.960
So as part of that, it's kind of just like, hey, we think you're awesome.

00:07:51.420 --> 00:07:54.300
Why don't you just pick something to work on that will contribute back?

00:07:54.300 --> 00:07:55.000
That'd be really cool.

00:07:55.000 --> 00:08:00.280
So his project at Microsoft is around making Python faster, which I think is great.

00:08:00.280 --> 00:08:00.840
Cool.

00:08:00.840 --> 00:08:01.760
So, yeah.

00:08:01.760 --> 00:08:11.960
So there's a team of folks, Mark Shannon, Eric Snow, and Guido, and possibly others, who are working with the core devs at Microsoft to make it faster.

00:08:11.960 --> 00:08:12.880
It's really cool.

00:08:12.880 --> 00:08:16.400
Everything will be done on the public GitHub repo.

00:08:16.400 --> 00:08:19.700
There's not like a secret branch that will be then dropped on it.

00:08:19.700 --> 00:08:27.260
So it's all just going to be PRs to GitHub.com slash Python slash CPython, whatever the URL is, the public spot.

00:08:27.260 --> 00:08:31.240
And one of the main things they want to do is not break compatibility.

00:08:31.240 --> 00:08:33.160
So that's important.

00:08:33.160 --> 00:08:36.880
Also said, what things could we change?

00:08:36.960 --> 00:08:41.820
Well, you can't change the base object like piobj.

00:08:41.820 --> 00:08:44.080
Basically, the base class, right?

00:08:44.080 --> 00:08:44.880
Pi object pointer.

00:08:44.880 --> 00:08:45.480
That's it.

00:08:45.480 --> 00:08:46.300
The pi object class.

00:08:46.820 --> 00:08:48.920
So that thing has to stay the same.

00:08:48.920 --> 00:08:52.640
And it really needs to keep reference counting semantics because so much is built on that.

00:08:52.640 --> 00:09:03.700
But they could change the bytecode that exists, the stack frame layout, the compiler, the interpreter, maybe make it a JIT compiler to JIT compile the bytecode, all of those types of things.

00:09:03.700 --> 00:09:04.900
So that's pretty cool.

00:09:05.280 --> 00:09:07.800
And they said, how are we going to reach two times speed up in 3.11?

00:09:07.800 --> 00:09:23.080
An adaptive, specialized bytecode interpreter that will be more performant around certain operations, optimized frame stacks, faster calls, zero overhead exception handling, and things like integral internals.

00:09:23.580 --> 00:09:26.940
So maybe treating numbers differently, changing how PYC files.

00:09:26.940 --> 00:09:28.360
So there's a lot of stuff going on.

00:09:28.360 --> 00:09:40.120
Also, putting the dunderdick for a class always at a certain known location because anytime you access a field, you have to go to the dunderdick, get the value out, and then read it.

00:09:40.120 --> 00:09:47.220
And I suspect the first thing that happens is, well, go find the dunderdick pointer and then go get the element out of it.

00:09:47.300 --> 00:09:57.160
So if every access could just go, nope, it's always one certain byte off in memory from where the class starts, that would save that sort of traversal there.

00:09:57.160 --> 00:09:58.980
So some pretty neat things.

00:09:58.980 --> 00:10:02.880
Yeah, I'm glad you explained that because I read it before and I'm like, why would that help at all?

00:10:02.880 --> 00:10:06.800
I think you can traverse one fewer pointers.

00:10:06.800 --> 00:10:07.560
Yeah.

00:10:07.560 --> 00:10:14.820
In general, it doesn't matter, but literally everything you ever touch, ever, if you could cut in half the number of pointers, you got to follow, that'd be good.

00:10:14.820 --> 00:10:15.260
Yeah.

00:10:15.600 --> 00:10:15.880
Yeah.

00:10:15.880 --> 00:10:21.380
This is always one of those things that always struck me with, when you're using Python, you don't think about these sorts of things.

00:10:21.380 --> 00:10:27.900
It's when you're doing something in Rust or something, then you are confronted with the fact that you really have to keep track of where's the pointer pointing and memory and all that.

00:10:27.900 --> 00:10:29.400
And you take a lot of this stuff for granted.

00:10:29.400 --> 00:10:33.600
So it's great that people are still sort of going at it and looking for things to improve there.

00:10:33.600 --> 00:10:34.540
Yeah, absolutely.

00:10:34.540 --> 00:10:39.260
You know, in C, you do the arrow, you know, dash greater than sort of thing.

00:10:39.260 --> 00:10:39.900
Every pointer.

00:10:39.900 --> 00:10:40.940
So you're like, I'm following a pointer.

00:10:40.940 --> 00:10:41.520
I'm following a pointer.

00:10:41.520 --> 00:10:42.440
You know it, right?

00:10:42.760 --> 00:10:45.920
Here you just, you write nice, clean code and magic happens.

00:10:45.920 --> 00:10:49.360
So let me round this out with who will benefit.

00:10:49.360 --> 00:10:50.020
So who will benefit?

00:10:50.020 --> 00:10:56.820
If you're running CPU intensive pure Python code, that will get faster because the Python execution should be faster.

00:10:58.100 --> 00:11:02.180
should be faster because a lot of that code is running in the Python space.

00:11:02.180 --> 00:11:04.180
And what does that happen to use Python?

00:11:04.180 --> 00:11:05.820
Who will not benefit so much?

00:11:05.820 --> 00:11:11.600
NumPy, TensorFlow, Pandas, all the code that's written at C, things that are IO bound.

00:11:11.600 --> 00:11:16.400
So if you're waiting on something else, speeding up the part that goes to wait, really matter.

00:11:16.400 --> 00:11:19.280
Multithreaded code because of the GIL at this point.

00:11:19.760 --> 00:11:23.940
But Eric Snow is also working on the subinterpreters, which may fix that and so on.

00:11:23.940 --> 00:11:25.600
So I like the last bullet.

00:11:25.600 --> 00:11:26.460
Pretty neat stuff.

00:11:26.460 --> 00:11:27.580
There's some peps out there.

00:11:27.580 --> 00:11:37.360
I'll link to, I link to the tweet by Mike Driscoll, but that'll take you straight to the GitHub repo, which has the PDF of the slides.

00:11:37.360 --> 00:11:38.860
And people can check that out if they're interested.

00:11:38.860 --> 00:11:43.700
I like the last bullet for the previous slide of things, people that will not benefit.

00:11:43.700 --> 00:11:45.880
Code that's algorithmically inefficient.

00:11:45.880 --> 00:11:49.540
Otherwise, if your code already sucks, it's not going to be better.

00:11:49.540 --> 00:11:52.760
It may be better, but it could be better.

00:11:52.760 --> 00:11:57.120
I was going to say, like, theoretically, it actually would go faster and just...

00:11:57.120 --> 00:11:59.640
Just not as much better as it could, right?

00:11:59.640 --> 00:12:05.120
Yeah, it would still be like n to the power of three or something like that, but it would be faster n to the power of three.

00:12:05.760 --> 00:12:06.140
Yeah, yeah.

00:12:06.140 --> 00:12:10.760
It won't change the big O notation, but it might make it run quicker on wall time.

00:12:10.760 --> 00:12:11.120
That's right.

00:12:11.120 --> 00:12:11.380
Yeah.

00:12:11.380 --> 00:12:12.020
Yeah.

00:12:12.020 --> 00:12:18.500
And Christopher Tyler out there in the live stream says, I know I still need to improve my code, but this would be great, right?

00:12:18.500 --> 00:12:21.860
I mean, it used to be that we could just wait six months.

00:12:21.860 --> 00:12:25.360
A new CPU would come out that's like twice as fast as what we ran on before.

00:12:25.360 --> 00:12:26.360
Like, oh, now it's fast enough.

00:12:26.360 --> 00:12:26.780
We're good.

00:12:26.780 --> 00:12:28.460
That doesn't happen as much these days.

00:12:28.460 --> 00:12:30.520
So it's cool that the runtimes are getting faster.

00:12:30.520 --> 00:12:31.140
Yeah.

00:12:31.140 --> 00:12:32.440
And I mean, let's be honest.

00:12:32.440 --> 00:12:35.400
Python is also still used for like just lots of script tasks.

00:12:35.400 --> 00:12:38.140
Like, hey, I just need this thing on the command line that does the thing.

00:12:38.140 --> 00:12:42.600
And I put that in Chrome and like a lot of that will be nice if that just gets a little bit faster.

00:12:42.600 --> 00:12:45.240
And it sounds like this will just be right up that alley.

00:12:45.240 --> 00:12:45.820
Yeah.

00:12:45.820 --> 00:12:54.600
And one of the things that I know has been holding certain types of changes back has been concern about slowing down the startup time.

00:12:54.600 --> 00:13:05.560
Because if all you want to do is run Python to make a very small thing happen, but like there's a big JIT overhead and all sorts of stuff, and it takes two seconds to start and a nanosecond and microsecond to run, right?

00:13:05.560 --> 00:13:09.400
They don't want to put those kinds of limitations and heal that use case either.

00:13:09.400 --> 00:13:11.300
So yeah, it's good to point that out.

00:13:11.300 --> 00:13:12.660
All right, Vincent, you're up next.

00:13:12.660 --> 00:13:13.460
Cool.

00:13:13.460 --> 00:13:13.820
Yeah.

00:13:13.880 --> 00:13:17.260
So I dabble a little bit in fairness algorithms.

00:13:17.260 --> 00:13:18.980
It's a big, important thing.

00:13:18.980 --> 00:13:24.220
So I get a lot of questions from people like, hey, if I want to do like machine learning and fairness, where should I start?

00:13:24.220 --> 00:13:26.220
And I don't think you should start with algorithms.

00:13:26.220 --> 00:13:30.640
Instead, what you should do is you should go check out this Python project called Deon.

00:13:30.640 --> 00:13:32.360
And the project's really minimal.

00:13:32.360 --> 00:13:41.960
The main thing that it really just does is it gives you a checklist of just stuff to check before you do like a big data science project at a big company or an enterprise or something like that.

00:13:41.960 --> 00:13:44.120
And they're really sensible things.

00:13:44.120 --> 00:13:46.080
They're sort of grouped together.

00:13:46.080 --> 00:13:50.700
So like, hey, can I check off that I have informed consent and collection bias?

00:13:50.700 --> 00:13:52.380
Can I check all these things off?

00:13:52.380 --> 00:13:53.560
The main themes are...

00:13:53.560 --> 00:13:54.760
And it's literally a checkbox.

00:13:54.760 --> 00:13:57.360
You can check them off in the page to sort of get the feel of it.

00:13:57.360 --> 00:13:58.760
Like, oh yeah, these are good.

00:13:58.760 --> 00:13:59.480
It goes further.

00:13:59.480 --> 00:14:01.160
So the thing is, this is an actual Python project.

00:14:01.160 --> 00:14:03.560
You can generate this as YAML for your GitHub profile.

00:14:03.560 --> 00:14:07.360
So like for your GitHub project, you actually have this checklist that has to be checked in Git.

00:14:07.360 --> 00:14:09.400
So you know that people signed off on it.

00:14:09.400 --> 00:14:10.940
Like you can actually see the checklist.

00:14:10.940 --> 00:14:13.660
You can even maybe in your Git log see who checked it off.

00:14:13.660 --> 00:14:16.220
But what's really cool is two things.

00:14:16.220 --> 00:14:17.560
Like one, you can generate this checklist.

00:14:17.560 --> 00:14:20.320
Two, you can also customize the checklist.

00:14:20.320 --> 00:14:27.540
So if you are at a specific company of certain legal requirements, this tool actually kind of makes it easy to customize a very specific checklist for data projects.

00:14:27.540 --> 00:14:30.520
But the real killer feature, if you ask me, like again,

00:14:30.580 --> 00:14:31.940
all of these comments are good.

00:14:31.940 --> 00:14:34.980
Like, is the data security well done?

00:14:34.980 --> 00:14:36.440
Is the analysis reproducible?

00:14:36.440 --> 00:14:38.100
How do we do deployment?

00:14:38.100 --> 00:14:41.800
Like all of these things that are usually like things that go wrong and were obvious in hindsight.

00:14:42.000 --> 00:14:46.040
But the real killer feature is usually you have to convince people to take this serious.

00:14:46.040 --> 00:14:49.080
So what the website offers is like an example list.

00:14:49.640 --> 00:14:53.740
So for every single item that is on this checklist, they have one or two examples.

00:14:53.740 --> 00:14:59.100
Typically, these are like newspaper articles of places where this has actually gone wrong in the past.

00:14:59.280 --> 00:15:03.800
So if you need like a really good argument for your boss, like, hey, we got to take this serious.

00:15:03.800 --> 00:15:06.460
There's a newspaper article you can just send along as well.

00:15:06.460 --> 00:15:08.460
Oh, that's interesting.

00:15:08.460 --> 00:15:08.900
Yeah.

00:15:08.900 --> 00:15:09.860
I like it.

00:15:09.860 --> 00:15:13.460
And the fact you can also generate Jupyter notebooks with this.

00:15:13.460 --> 00:15:14.860
You can customize it a little bit.

00:15:14.860 --> 00:15:18.180
The people that made this, the company I think is called Driven Data.

00:15:18.560 --> 00:15:20.660
They host Kaggle competitions for like good causes.

00:15:20.660 --> 00:15:21.940
That's sort of a thing that they do there.

00:15:21.940 --> 00:15:23.920
But Deon is just a really cool project.

00:15:23.920 --> 00:15:31.860
Like I think if more people would just start with a sensible checklist and work from there, a lot of projects would immediately be better for it.

00:15:31.860 --> 00:15:33.460
Yeah, this is really cool.

00:15:33.460 --> 00:15:37.080
So things are, can you go to the very bottom of that page that you're on?

00:15:37.080 --> 00:15:37.980
Yeah.

00:15:37.980 --> 00:15:39.360
Sorry, just the checklist.

00:15:39.360 --> 00:15:39.980
Oh, right.

00:15:39.980 --> 00:15:40.320
Yeah, yeah.

00:15:40.320 --> 00:15:45.480
So there's some examples like make sure that you've accounted for unintended use.

00:15:45.620 --> 00:15:49.260
Have you taken steps to identify and prevent unintended uses and abuse?

00:15:49.260 --> 00:15:53.080
So like if you created a find my friends in pictures.

00:15:53.080 --> 00:15:55.360
So like I want to find pictures my friends have taken to me.

00:15:55.360 --> 00:15:57.780
You could put it up and it would show you all the pictures your friends took.

00:15:57.780 --> 00:16:02.240
But maybe someone else is going to use that to, I don't know, try to fish you.

00:16:02.240 --> 00:16:06.200
Like here's the picture of us together or I don't know, some weird thing.

00:16:06.200 --> 00:16:10.500
Use it for like facial recognition and tracking when it had no such intent.

00:16:10.500 --> 00:16:10.700
Right.

00:16:10.700 --> 00:16:11.360
Things like that.

00:16:11.360 --> 00:16:13.620
I think for and I might be.

00:16:13.920 --> 00:16:15.880
So it doesn't have this example.

00:16:15.880 --> 00:16:17.680
The best example of unintended use.

00:16:17.680 --> 00:16:21.680
There used to be this geo lookup company where you could give an IP address and give you like

00:16:21.680 --> 00:16:22.520
an actual address.

00:16:22.520 --> 00:16:25.280
However, sometimes you don't know where the IP address actually is.

00:16:25.280 --> 00:16:28.040
So just give like the center point of like a US state or the country.

00:16:28.040 --> 00:16:31.680
So there used to be this house in the middle of Kansas, I think.

00:16:31.680 --> 00:16:34.420
It was like the center point.

00:16:34.480 --> 00:16:39.860
But the thing is, they will get like FBI trucks driving by and like doing raids and stuff because

00:16:39.860 --> 00:16:43.140
they thought there were criminals there because the geo lookup servers would always say like,

00:16:43.140 --> 00:16:46.120
ah, the crooks at that IP address, that's this latitude longitude place.

00:16:46.120 --> 00:16:46.760
Right, right.

00:16:46.760 --> 00:16:48.040
We had a cyber attack.

00:16:48.040 --> 00:16:49.620
It was from this IP address.

00:16:49.620 --> 00:16:51.140
Raid them, boys.

00:16:51.480 --> 00:16:58.680
Of course, it was just some poor farmer in the Midwest going, you know, just the geographic

00:16:58.680 --> 00:16:59.040
center.

00:16:59.040 --> 00:17:00.660
Please stop raiding my farm.

00:17:00.660 --> 00:17:03.780
Yeah, but the story was actually quite serious.

00:17:03.780 --> 00:17:07.100
Like, I think the person who lived there could like death threats at some point as well because

00:17:07.100 --> 00:17:07.760
of the same mistake.

00:17:07.760 --> 00:17:09.840
So like this is stuff that takes serious.

00:17:09.840 --> 00:17:12.220
The one thing that I did like is the solution.

00:17:12.220 --> 00:17:17.580
I think now the, the, the, the, instead of it pointing to the house in Kansas, I think

00:17:17.580 --> 00:17:21.880
it points to like the center of the three big lakes in Michigan.

00:17:21.880 --> 00:17:25.920
I think it's just the middle of a puddle of water, basically, just to make it like obvious

00:17:25.920 --> 00:17:28.740
to the FBI squads that like, nah, it's not a person living there.

00:17:28.740 --> 00:17:29.280
Yeah, that's good.

00:17:29.280 --> 00:17:32.600
They're like, darn, these submarines are, they've moved underwater.

00:17:32.600 --> 00:17:33.940
Or, or whatever.

00:17:33.940 --> 00:17:36.360
But I mean, but that's why you want to have a checklist like this.

00:17:36.360 --> 00:17:39.680
Like you're not going to, the thing with unintended use is you, it's unintended.

00:17:39.680 --> 00:17:43.140
So you cannot really imagine it, but you at least should do the exercise.

00:17:43.140 --> 00:17:46.380
And that's what this list does in a very sensible way.

00:17:46.380 --> 00:17:47.520
And more people should just do it.

00:17:47.520 --> 00:17:49.440
And there's interesting examples too.

00:17:49.440 --> 00:17:50.320
You should just have a look.

00:17:50.320 --> 00:17:51.580
And there's also a little community.

00:17:51.580 --> 00:17:54.980
There's a little community around it as well of like collecting these examples.

00:17:54.980 --> 00:17:58.040
And they have like a wiki page with examples that didn't make the front page cut.

00:17:58.040 --> 00:18:00.820
So definitely recommend anyone interested in fairness.

00:18:00.820 --> 00:18:01.700
Start here.

00:18:01.700 --> 00:18:03.160
I was curious.

00:18:03.160 --> 00:18:08.680
You brushed by fairly quickly of fairness analysis, fairness analysis.

00:18:08.680 --> 00:18:09.600
Is that what you do?

00:18:09.600 --> 00:18:12.880
I just don't know what that means.

00:18:12.880 --> 00:18:13.620
So could you?

00:18:13.620 --> 00:18:14.220
Yeah.

00:18:14.220 --> 00:18:18.780
So, oh man, this is a longer, like this topic deserves more time than I'll give it.

00:18:18.780 --> 00:18:23.780
But the idea is that you might be able, we know that models aren't always fair, right?

00:18:23.780 --> 00:18:30.720
It can be that you have models that, for example, the Amazon was a nice example.

00:18:30.720 --> 00:18:36.280
So they had like a resume parsing algorithm that basically favored men because they hired

00:18:36.280 --> 00:18:37.180
more men historically.

00:18:37.180 --> 00:18:38.700
So the algorithm would prefer men.

00:18:38.700 --> 00:18:39.620
Oh, okay.

00:18:39.620 --> 00:18:39.900
Stuff like that.

00:18:39.900 --> 00:18:40.520
That kind of fairness.

00:18:40.520 --> 00:18:40.940
Okay.

00:18:40.940 --> 00:18:41.360
Got it.

00:18:41.360 --> 00:18:41.500
Yeah.

00:18:41.500 --> 00:18:41.980
Historical.

00:18:41.980 --> 00:18:43.480
These have been our good employees.

00:18:43.480 --> 00:18:44.880
Let's find more like them.

00:18:44.880 --> 00:18:45.260
Exactly.

00:18:45.260 --> 00:18:46.300
Something like that.

00:18:46.460 --> 00:18:48.580
And the thing is, you don't get an algorithm that's unfair.

00:18:48.580 --> 00:18:52.440
So there are these machine learning techniques and there's this community of researchers that

00:18:52.440 --> 00:18:55.940
try to look for ways like, can we improve the fairness of these systems?

00:18:55.940 --> 00:18:57.720
So we don't just optimize for accuracy.

00:18:57.720 --> 00:19:01.800
We also say, well, we want to make sure that subgroups are treated fairly and equally and

00:19:01.800 --> 00:19:02.440
stuff like that.

00:19:02.800 --> 00:19:04.200
So I dabble a little bit in this.

00:19:04.200 --> 00:19:06.320
There's this project I like to collaborate with.

00:19:06.320 --> 00:19:08.960
I put my open source a couple of things with these people.

00:19:08.960 --> 00:19:10.120
It's called FairLearn.

00:19:10.120 --> 00:19:14.240
The main thing that I really like about the package is that it starts by saying fairness

00:19:14.240 --> 00:19:17.080
of AI systems is more than just running a few lines of code.

00:19:17.080 --> 00:19:19.280
Like it starts by acknowledging that.

00:19:19.280 --> 00:19:24.000
But they have mitigation techniques and algorithms and like tools to help you measure the unfairness.

00:19:24.000 --> 00:19:25.860
It's scikit-learn compatible as well.

00:19:25.860 --> 00:19:26.860
Stuff to like.

00:19:26.860 --> 00:19:29.260
Having said all that, start here.

00:19:29.260 --> 00:19:30.880
Start with a checklist.

00:19:30.880 --> 00:19:32.520
Don't worry about the machine learning stuff just yet.

00:19:32.640 --> 00:19:33.080
Start here.

00:19:33.080 --> 00:19:34.140
But yeah.

00:19:34.140 --> 00:19:34.620
Very cool.

00:19:34.620 --> 00:19:40.080
Before we move on, Connor Furster in the live chat says, I'm glad the conversation of ethics

00:19:40.080 --> 00:19:41.420
and data science is enlarging.

00:19:41.420 --> 00:19:43.840
I think it's important about what we make.

00:19:43.840 --> 00:19:44.280
Yeah.

00:19:44.280 --> 00:19:44.760
I agree.

00:19:44.760 --> 00:19:45.540
Totally.

00:19:45.540 --> 00:19:50.660
Now, before we do move on though, let me tell you all about our sponsor for this episode,

00:19:50.660 --> 00:19:51.480
Sentry.

00:19:51.480 --> 00:19:53.340
So this episode is brought to you by Sentry.

00:19:53.340 --> 00:19:54.220
Thank you, Sentry.

00:19:54.220 --> 00:19:57.220
How would you like to remove a little bit of stress from your life?

00:19:57.220 --> 00:20:02.400
Do you worry that users may be having difficulties or encountering errors with your app right now?

00:20:02.480 --> 00:20:05.240
And would you even know it until they sent you that support email?

00:20:05.240 --> 00:20:09.720
How much better would it be to have the errors and performance details immediately sent to you,

00:20:09.720 --> 00:20:14.060
including the call stack and values of local variables and the active user recorded right

00:20:14.060 --> 00:20:14.560
in the report?

00:20:14.560 --> 00:20:17.340
With Sentry, it's not only possible, it's simple.

00:20:17.880 --> 00:20:19.760
We actually use Sentry on our websites.

00:20:19.760 --> 00:20:21.040
It's on pythonbytes.fm.

00:20:21.040 --> 00:20:23.020
It's on Talk Python Training, all those things.

00:20:23.020 --> 00:20:30.320
And we've actually fixed a bug triggered by a user and had the upgrade ready to roll out as we got the support email.

00:20:30.320 --> 00:20:32.140
They said, hey, I'm having a problem with the site.

00:20:32.140 --> 00:20:33.580
I can't do this or that.

00:20:33.580 --> 00:20:35.140
I said, actually, I already saw the error.

00:20:35.140 --> 00:20:36.660
I just pushed the fix to production.

00:20:36.820 --> 00:20:37.760
So just try it again.

00:20:37.760 --> 00:20:39.200
Imagine their surprise.

00:20:39.200 --> 00:20:41.120
So surprise and delight your users.

00:20:41.120 --> 00:20:44.780
Get your Sentry account at pythonbytes.fm/Sentry.

00:20:44.780 --> 00:20:47.120
And when you sign up, there's a got a promo code.

00:20:47.120 --> 00:20:47.500
Redeem it.

00:20:47.500 --> 00:20:52.100
Make sure you put Python Bytes in that section or you won't get two months of free Sentry team

00:20:52.100 --> 00:20:53.180
plans and other features.

00:20:53.180 --> 00:20:54.740
And they won't know it came from us.

00:20:54.840 --> 00:20:57.860
So use the promo code at pythonbytes.fm/Sentry.

00:20:57.860 --> 00:20:58.500
Yeah.

00:20:58.500 --> 00:20:58.820
Thanks.

00:20:58.820 --> 00:21:00.520
Thanks for supporting the show, Brian.

00:21:00.520 --> 00:21:01.320
Yeah.

00:21:01.320 --> 00:21:02.460
I like this one that you picked here.

00:21:02.460 --> 00:21:03.280
You like this?

00:21:03.280 --> 00:21:04.260
I like it a lot.

00:21:04.260 --> 00:21:04.880
It's very good.

00:21:04.880 --> 00:21:09.020
It has pictures, little animated things, and great looking tools.

00:21:09.020 --> 00:21:09.600
Yeah.

00:21:09.600 --> 00:21:11.020
So there's an article.

00:21:11.020 --> 00:21:11.820
It was sent to us.

00:21:11.820 --> 00:21:12.760
I can't remember who sent it.

00:21:12.760 --> 00:21:13.480
So apologies.

00:21:13.480 --> 00:21:19.860
But it's an article called Three Tools to Track and Visualize the Execution of Your Python Code.

00:21:19.860 --> 00:21:22.720
And I don't know why.

00:21:23.260 --> 00:21:25.260
Executing your code just seems funny to me.

00:21:25.260 --> 00:21:29.880
I know it just means run it, but, you know, chop its head off or something.

00:21:29.880 --> 00:21:38.300
Anyway, so the three tools, the three tools it covers are, we don't cover this very much

00:21:38.300 --> 00:21:39.820
because I don't know how to pronounce it.

00:21:39.820 --> 00:21:41.720
L-O-G-U-R-U.

00:21:41.720 --> 00:21:43.660
It's LogGuru or LogGuru?

00:21:43.660 --> 00:21:44.240
Not sure.

00:21:44.240 --> 00:21:49.260
And then, so LogGuru is a pretty printer with better exceptions.

00:21:49.260 --> 00:21:52.140
So let's go and look at that.

00:21:52.140 --> 00:21:54.320
So it does exceptions like this.

00:21:54.320 --> 00:21:56.900
It breaks out your exceptions into colors.

00:21:56.900 --> 00:22:00.580
And it's just kind of a really great way to visualize it.

00:22:00.580 --> 00:22:05.900
And I would totally use this for if I was teaching, like if I was teaching a class or something,

00:22:05.900 --> 00:22:12.020
this might be a good way to teach people how to look at trace logs and error logs.

00:22:12.020 --> 00:22:13.100
That is fantastic.

00:22:13.200 --> 00:22:19.300
And if you're out there listening and not seeing it, you should definitely pull up this site because the pictures really are what you need to tell quickly.

00:22:19.300 --> 00:22:19.760
Yeah.

00:22:19.760 --> 00:22:20.740
Yeah.

00:22:20.740 --> 00:22:25.000
That's one of the things I like about this article is that lots of great pictures.

00:22:25.000 --> 00:22:26.720
So one thing out of curiosity.

00:22:26.880 --> 00:22:30.960
So what I'm seeing here is that, for example, it says return number one divided by number two.

00:22:30.960 --> 00:22:33.400
And then you actually see the numbers that were in those variables.

00:22:33.400 --> 00:22:36.740
Do you have to add like a decorator or something to get this output?

00:22:36.740 --> 00:22:38.060
Or how does that work?

00:22:38.060 --> 00:22:40.180
That's explained later, maybe.

00:22:40.180 --> 00:22:42.460
I don't remember where.

00:22:43.140 --> 00:22:44.280
Yeah, it's explained later, I think.

00:22:44.280 --> 00:22:44.560
Yeah.

00:22:44.560 --> 00:22:45.240
Yeah.

00:22:45.240 --> 00:22:48.360
I think you just pull it in and it just does it, but I'm not sure.

00:22:48.360 --> 00:22:48.920
Okay.

00:22:48.920 --> 00:22:49.620
Interesting.

00:22:49.620 --> 00:22:49.940
Anyway.

00:22:49.940 --> 00:22:53.660
So that's LogGuru.

00:22:53.660 --> 00:22:57.360
Then there's Snoop, which is kind of fun.

00:22:57.360 --> 00:23:01.020
That has a hold down to Snoop.

00:23:01.020 --> 00:23:02.040
Should have had this already.

00:23:02.040 --> 00:23:08.120
Anyway, with Snoop, you can see it prints lines of code being executed in a function.

00:23:08.120 --> 00:23:14.840
So it just runs your code and then prints out each line in real time as it's going through it.

00:23:14.840 --> 00:23:17.740
You would hardly ever want this, I think.

00:23:17.740 --> 00:23:22.800
But when you do want it, I think it might be kind of cool to watch it go along.

00:23:22.800 --> 00:23:25.900
And you could also do this in a debugger.

00:23:25.900 --> 00:23:27.780
But if you didn't want a debugger, do a debugger.

00:23:27.780 --> 00:23:28.980
You can do this on the command line.

00:23:28.980 --> 00:23:36.260
Well, one of the things that most debuggers have that is a little challenging is you'll see the state and you'll see the state change.

00:23:36.260 --> 00:23:37.560
And you'll see it change again.

00:23:38.100 --> 00:23:40.920
But in your mind, you've got to remember, okay, that was a seven.

00:23:40.920 --> 00:23:42.160
And then it was a five.

00:23:42.160 --> 00:23:43.280
And then it was a three.

00:23:43.280 --> 00:23:44.340
Oh, right.

00:23:44.340 --> 00:23:44.580
Yeah.

00:23:44.580 --> 00:23:44.940
Right.

00:23:44.940 --> 00:23:50.800
And here it'll actually reproduce each line, each block of code with the values over.

00:23:50.800 --> 00:23:55.620
If you're in a loop three times, it'll show like going through the loop three times with all the values set.

00:23:55.620 --> 00:23:57.020
And that's pretty neat.

00:23:57.020 --> 00:23:57.560
Yeah.

00:23:57.560 --> 00:24:04.580
I would also argue just for teaching recursion, I think this visualization is kind of nice because you see that you actually see like the indentation and the depth appear.

00:24:04.780 --> 00:24:09.340
So you can actually see like this function is called inside of this other function and there's a timestamp.

00:24:09.400 --> 00:24:12.400
So I would also argue this one's pretty good for teaching.

00:24:12.400 --> 00:24:13.640
I like it.

00:24:13.680 --> 00:24:17.640
And in fact, Connor on the live stream says, I'm teaching my first Python course tomorrow.

00:24:17.640 --> 00:24:18.460
So, yeah.

00:24:18.460 --> 00:24:19.800
Thanks for the timely article.

00:24:19.800 --> 00:24:30.580
And a real-time follow-up for the log guru, you have to import logger and then you've got to put a decorator on the function and then it'll capture like that super detailed output.

00:24:30.580 --> 00:24:36.620
And that's probably exactly what you want because you don't really want to do that for everything probably.

00:24:36.620 --> 00:24:39.700
So there'll be something you're working on that you want to trace.

00:24:39.700 --> 00:24:43.360
So heart rate is the last tool that we want to talk about.

00:24:43.360 --> 00:24:48.080
And it's a way to visualize the execution of a Python program in real time.

00:24:48.420 --> 00:24:53.260
So this is something we have not covered before, but it's, I thought there was a little video.

00:24:53.260 --> 00:24:53.960
Yeah.

00:24:53.960 --> 00:25:02.360
It kind of goes through and does a little like a heat map sort of thing on the side of your code.

00:25:03.080 --> 00:25:08.300
So when it's running, you can kind of see that different things get hit more than others.

00:25:08.300 --> 00:25:10.600
So that's, that's fast.

00:25:10.600 --> 00:25:13.780
Almost like a profiler sort of not speed though.

00:25:13.780 --> 00:25:14.680
It's just number of hits.

00:25:14.680 --> 00:25:15.280
Yeah.

00:25:15.280 --> 00:25:16.060
Yeah.

00:25:16.060 --> 00:25:19.200
I'm, I'm, I'm kind of on the fence about this, but it's pretty.

00:25:19.200 --> 00:25:21.460
So yeah, same.

00:25:21.460 --> 00:25:23.840
But, the logger one looks amazing.

00:25:23.840 --> 00:25:26.900
I thought logger was also like a general logging tool.

00:25:26.900 --> 00:25:31.940
Like it does more, I think, than just, things for, for debugging.

00:25:32.260 --> 00:25:32.620
Yeah.

00:25:32.620 --> 00:25:34.420
I think it's a general logging tool as well.

00:25:34.420 --> 00:25:34.920
Okay.

00:25:34.920 --> 00:25:35.560
Okay.

00:25:35.560 --> 00:25:37.660
But I guess it logs errors really good.

00:25:37.660 --> 00:25:42.160
Uh, so logger dot catch decorator.

00:25:42.160 --> 00:25:42.420
Okay.

00:25:42.420 --> 00:25:45.700
Well, you could probably do other things with the logger then as well, but having a good

00:25:45.700 --> 00:25:48.360
logging debugger catcher is always welcome.

00:25:48.360 --> 00:25:49.560
Yeah, absolutely.

00:25:49.560 --> 00:25:50.480
All right.

00:25:50.480 --> 00:25:51.900
Uh, let's talk about ducks.

00:25:51.900 --> 00:25:53.660
I mean, Brian, you and I are in Oregon.

00:25:53.660 --> 00:25:54.680
Go ducks.

00:25:54.680 --> 00:25:56.840
Is that a, well, I know your daughter goes there.

00:25:56.840 --> 00:25:59.100
My, my daughter goes to OS, OSU.

00:25:59.100 --> 00:26:00.680
So go, go be use, I guess.

00:26:00.680 --> 00:26:01.660
Whatever ducks.

00:26:01.660 --> 00:26:03.120
We're gonna talk duck databases anyway.

00:26:03.120 --> 00:26:04.400
And data science.

00:26:04.400 --> 00:26:10.880
So Alex Monahan sent over to us saying, Hey, you should check out this article about duck

00:26:10.880 --> 00:26:13.300
DB, which is the thing I'm now learning about.

00:26:13.300 --> 00:26:14.480
And it's integration.

00:26:14.480 --> 00:26:16.480
It's direct integration with pandas.

00:26:16.660 --> 00:26:23.160
So instead of taking data from a database loaded into a pandas data frame, doing stuff on it,

00:26:23.160 --> 00:26:27.680
and then getting the answer out, you basically put it into this embedded database duck DB,

00:26:27.680 --> 00:26:32.720
which is SQL light like, and then, you know, sorry, you put it into a pandas data frame,

00:26:32.820 --> 00:26:41.100
but then the query engine of duck DB can query it directly without any data exchange, without transferring it back and forth between the two systems or formats.

00:26:41.100 --> 00:26:42.000
That's pretty cool.

00:26:42.000 --> 00:26:42.220
Right?

00:26:42.360 --> 00:26:43.820
So let me pull this.

00:26:43.820 --> 00:26:45.020
Oh, that's honest.

00:26:45.020 --> 00:26:45.800
I know him.

00:26:45.800 --> 00:26:46.660
Nice.

00:26:46.660 --> 00:26:47.080
Yeah.

00:26:47.080 --> 00:26:47.620
He's from master them.

00:26:47.620 --> 00:26:48.620
Yeah.

00:26:48.620 --> 00:26:49.020
Very cool.

00:26:49.020 --> 00:26:50.640
So here's the idea.

00:26:50.640 --> 00:26:53.740
We've got a SQL on pandas.

00:26:53.740 --> 00:26:54.180
Basically.

00:26:54.580 --> 00:27:02.460
So if we had a data frame here, they have a really simple data frame, but just, you know, a single array, but it could be a very complex data frame.

00:27:02.460 --> 00:27:07.240
And then what you can do is you can import duck DB and you can say duck DB dot query.

00:27:07.240 --> 00:27:12.840
And then you write something like, so one of the columns is called a in the data frame.

00:27:12.840 --> 00:27:17.420
And you could say, select some of a from the data frame.

00:27:17.420 --> 00:27:18.380
How cool is that?

00:27:18.380 --> 00:27:19.140
I don't know.

00:27:19.140 --> 00:27:19.740
Is it cool?

00:27:19.740 --> 00:27:21.220
It's very cool.

00:27:21.340 --> 00:27:24.880
So then you can also, there's also a two data frame on the result.

00:27:24.880 --> 00:27:37.220
So what happens here is this is parsed by duck DB, which has an advanced query optimizer for things like joins and filtering and indexes and all that kind of stuff.

00:27:37.220 --> 00:27:38.940
And then it says, oh, okay.

00:27:38.940 --> 00:27:47.600
So you said there's a thing called my DF, which I'll just go look in the locals of my current call stack and see if I can find that.

00:27:47.600 --> 00:27:49.360
Oh, yeah, that is neat.

00:27:49.700 --> 00:27:51.260
So you can write arbitrary SQL.

00:27:51.260 --> 00:27:52.380
And this one looks pretty straightforward.

00:27:52.380 --> 00:27:53.080
You're like, yeah, yeah.

00:27:53.080 --> 00:27:53.420
Okay.

00:27:53.420 --> 00:27:53.940
Interesting.

00:27:53.940 --> 00:27:54.380
Interesting.

00:27:54.380 --> 00:27:58.160
But you can come down here and do more interesting things.

00:27:58.160 --> 00:27:59.320
Let's see.

00:27:59.320 --> 00:28:00.260
I'll pull up some examples.

00:28:00.260 --> 00:28:04.720
So they do a select aggregation group by thing.

00:28:04.720 --> 00:28:11.240
So select these two things and then also do a sum min max and average on some part of the data frame.

00:28:11.400 --> 00:28:15.480
And then you pull it out of the data frame and you group by two of the elements.

00:28:15.480 --> 00:28:16.020
Right.

00:28:16.020 --> 00:28:20.320
And they show also what that would look like if you did that in true pandas format.

00:28:20.320 --> 00:28:21.040
That's cool.

00:28:21.040 --> 00:28:26.140
And they say, well, it's about two to three times faster in the duck DB version.

00:28:26.580 --> 00:28:27.140
That is interesting.

00:28:27.140 --> 00:28:28.300
That's interesting.

00:28:28.300 --> 00:28:28.580
Right.

00:28:28.580 --> 00:28:33.440
But then they say, well, what if we wanted not to just group by, but we wanted a filter?

00:28:33.440 --> 00:28:34.660
Seems real simple.

00:28:34.660 --> 00:28:36.980
Like where the ship date is less than 1998.

00:28:36.980 --> 00:28:37.960
No big deal.

00:28:38.140 --> 00:28:46.380
But because the way that this be really officially figured out by the query optimizer, it turns out to be much faster.

00:28:46.380 --> 00:28:52.240
So 0.6 seconds on single threaded or it actually supports parallel execution as well.

00:28:52.240 --> 00:28:53.780
So multi-threaded.

00:28:53.780 --> 00:28:57.820
They tested on a system that only had two cores, but it can be many, many cores.

00:28:57.820 --> 00:29:03.200
So it's faster 0.4 seconds when threaded versus 2.2 seconds.

00:29:03.200 --> 00:29:06.280
Sorry, 3.5 seconds on regular pandas.

00:29:06.360 --> 00:29:16.240
But there's this more complicated, non-obvious thing you can do called a manual pushdown in pandas, which will help drive some of the efficiency before other work happens.

00:29:16.240 --> 00:29:22.200
And then they finally show one at the very end where there's more stuff going on that query optimizer does.

00:29:22.200 --> 00:29:24.240
So the threaded one's 0.5 seconds.

00:29:24.240 --> 00:29:26.320
Regular pandas is 15 seconds.

00:29:26.320 --> 00:29:27.920
So all that's cool.

00:29:27.920 --> 00:29:30.460
And what's really neat is it all just happens like on the data frame.

00:29:30.460 --> 00:29:32.600
Yeah, there's two things about that that are pretty interesting.

00:29:32.600 --> 00:29:36.900
Like one is we should underestimate how many people are still new to pandas, but do understand SQL.

00:29:36.900 --> 00:29:41.680
So just for that use case, I can imagine, you know, you're going to get a lot of people on board.

00:29:41.680 --> 00:29:47.120
But the fact that there's a query optimizer in there that's able to work on top of pandas, that's also pretty neat.

00:29:47.120 --> 00:29:50.620
Because I'm assuming it's doing clever things like, oh, I need to filter data.

00:29:50.620 --> 00:29:53.220
I should do that as early on as possible in my query plan.

00:29:53.220 --> 00:29:54.640
It's doing some of that logic internally.

00:29:55.260 --> 00:29:59.680
And the fact is you can paralyze it because pandas doesn't paralyze easily.

00:29:59.680 --> 00:30:00.560
It's also something.

00:30:00.560 --> 00:30:02.540
Yeah, I don't know that it paralyzes at all.

00:30:02.540 --> 00:30:04.160
You've got to go to something like Dask.

00:30:04.160 --> 00:30:04.760
Yeah.

00:30:04.760 --> 00:30:08.780
I mean, so there are these, there are some, there are some, some tricks that you could do, but they're tricks.

00:30:08.780 --> 00:30:10.140
They're not really natively supported.

00:30:10.140 --> 00:30:11.100
Right.

00:30:11.100 --> 00:30:11.520
Right.

00:30:11.520 --> 00:30:13.780
But just having a SQL interface is neat.

00:30:13.780 --> 00:30:14.840
Yeah.

00:30:14.840 --> 00:30:15.360
Yeah.

00:30:15.360 --> 00:30:15.960
This is pretty neat.

00:30:15.960 --> 00:30:17.800
And also now I learned about DuckDB.

00:30:17.800 --> 00:30:20.860
So apparently that's a thing, which is pretty awesome.

00:30:21.340 --> 00:30:27.000
So it's, it's in process, just like SQLite's written in C++ 11 with no dependencies.

00:30:27.000 --> 00:30:28.020
Ooh.

00:30:28.020 --> 00:30:29.160
Supposed to be super fast.

00:30:29.160 --> 00:30:33.320
So this is also a cool thing that, you know, maybe I'll check out unrelated to query and pandas,

00:30:33.320 --> 00:30:35.360
but the fact that you can think is pretty cool.

00:30:35.360 --> 00:30:36.560
It's got a great name.

00:30:36.560 --> 00:30:37.760
Yeah.

00:30:37.760 --> 00:30:42.400
You know, another database out there I hear a lot about, but I've never used to have really

00:30:42.400 --> 00:30:44.460
an opinion about is CockroachDB.

00:30:44.460 --> 00:30:47.740
I'm not a huge fan of just on the name.

00:30:47.740 --> 00:30:49.240
Although it has some interesting ideas.

00:30:49.400 --> 00:30:53.860
I think it's like meant to communicate resiliency and it can't be killed because it's like geolocated

00:30:53.860 --> 00:30:55.100
and it's just going to survive.

00:30:55.100 --> 00:30:55.800
But yeah.

00:30:55.800 --> 00:30:56.340
Ducks.

00:30:56.340 --> 00:30:57.380
I'll go with ducks.

00:30:57.380 --> 00:30:58.140
Yeah.

00:30:58.140 --> 00:30:59.120
I would agree.

00:30:59.120 --> 00:30:59.700
Yeah.

00:30:59.700 --> 00:31:04.100
And then chat out in the, out in the live stream chat, Christopher says, so DuckDB is

00:31:04.100 --> 00:31:09.100
worrying on pandas data frames or can you load the data method chain with DuckDB and reduce

00:31:09.100 --> 00:31:09.400
memories?

00:31:09.400 --> 00:31:11.700
I believe you could do either.

00:31:11.700 --> 00:31:16.160
Like you could load data into it and then there's a two data frame option that probably

00:31:16.160 --> 00:31:17.000
could come out of it.

00:31:17.000 --> 00:31:19.120
But I think, I think just very briefly.

00:31:19.120 --> 00:31:19.840
It's right on it.

00:31:19.840 --> 00:31:20.260
Yeah.

00:31:20.260 --> 00:31:24.560
Doesn't, I might've just seen it briefly while, while you were scrolling in the blog post,

00:31:24.560 --> 00:31:27.420
but I believe it also said that it supports the parquet file format.

00:31:27.420 --> 00:31:28.240
It does.

00:31:28.460 --> 00:31:32.280
So the nice thing about parquet is you can kind of index your data cleverly.

00:31:32.280 --> 00:31:34.500
Like you can index it by date on the file system.

00:31:34.500 --> 00:31:39.000
And then presumably if you were to write the SQL query in DuckDB, it would only read the

00:31:39.000 --> 00:31:41.520
files of the appropriate date if you put a filter in there.

00:31:41.520 --> 00:31:46.700
So I can imagine just because of that reason, DuckDB on its own might be more memory performance

00:31:46.700 --> 00:31:47.500
than pandas, I guess.

00:31:47.500 --> 00:31:48.220
Yeah.

00:31:48.220 --> 00:31:48.700
Perhaps.

00:31:48.700 --> 00:31:49.700
That's very cool.

00:31:49.700 --> 00:31:50.780
Stuff like that you could do.

00:31:50.780 --> 00:31:51.300
Yeah.

00:31:51.380 --> 00:31:55.840
And then Nick Harvey also says, I wonder if it's read only, if you can insert or update.

00:31:55.840 --> 00:32:02.000
I don't know for sure, but you can see in some of the places they are doing like projections.

00:32:02.000 --> 00:32:05.920
So for example, they're doing a select sum min max average.

00:32:06.080 --> 00:32:07.940
Like that's generating data that goes into it.

00:32:07.940 --> 00:32:10.000
And then the result is a data frame.

00:32:10.000 --> 00:32:14.000
So you can just add into the data frame afterwards if you want to be more manual about it.

00:32:14.000 --> 00:32:14.420
Yeah.

00:32:14.420 --> 00:32:15.080
All right.

00:32:15.080 --> 00:32:16.360
Vincent, you got the last one.

00:32:16.360 --> 00:32:17.000
Yeah.

00:32:17.000 --> 00:32:20.440
So the thing is, I work for a company called Raza.

00:32:20.440 --> 00:32:25.620
We make software with Python to make virtual assistants easier to make in Python.

00:32:25.620 --> 00:32:30.320
And I was looking in our community showcase and I just found this project that just made me

00:32:30.320 --> 00:32:31.200
kind of feel hopeful.

00:32:31.200 --> 00:32:33.540
So this is a personal project, I think.

00:32:33.860 --> 00:32:38.860
So we have a name here, Amit and I'm hoping I'm pronouncing it correctly, Arvind.

00:32:38.860 --> 00:32:44.740
But what they did is they used Raza kind of like a Lego brick, but they made this assistant,

00:32:44.740 --> 00:32:46.720
if you will, that you can send a text message to.

00:32:46.720 --> 00:32:51.160
Now what it does, I'll zoom in a little bit for people on YouTube that they might be able

00:32:51.160 --> 00:32:56.060
to see the GIF, but every 10 minutes, it scrapes the weather information, the fire hazard

00:32:56.060 --> 00:33:01.280
information, and I think evacuation information from local government in California meant to help

00:33:01.280 --> 00:33:02.640
people during wildfire season.

00:33:02.640 --> 00:33:05.540
And they completely open source this project as well.

00:33:05.540 --> 00:33:09.400
So there's a linked GitHub project where you can just see how they implemented it.

00:33:09.400 --> 00:33:11.660
And it's a fairly simple implementation.

00:33:11.660 --> 00:33:14.040
They use Raza with a Twilio API.

00:33:14.040 --> 00:33:19.620
They're doing some neat little clever things here with like, if you misspelled your city,

00:33:19.620 --> 00:33:23.960
they're using like a fuzzy string matching library to make sure that even if you misspell your

00:33:23.960 --> 00:33:26.500
city, they can still try to give you like accurate information.

00:33:27.100 --> 00:33:30.880
But what they do is they just have this endpoint where you can send the text message to like,

00:33:30.880 --> 00:33:32.320
give me the update of San Francisco.

00:33:32.320 --> 00:33:36.520
And then it will tell you all the weather information, air quality information, and that sort of thing.

00:33:36.520 --> 00:33:38.680
And if you need to evacuate, they will also be able to tell you that.

00:33:38.680 --> 00:33:43.480
And what I just loved about this, if you look at the way that they described it,

00:33:44.160 --> 00:33:49.400
this was just two people who knew Python who were a little bit disappointed with the communication

00:33:49.400 --> 00:33:50.000
that was happening.

00:33:50.000 --> 00:33:52.720
But because the APIs were open, they just built their own solution.

00:33:52.720 --> 00:33:55.420
And like thousands of people use this.

00:33:55.420 --> 00:34:01.300
And what's even greater is that, you know, if your mobile coverage isn't great, watching a YouTube

00:34:01.300 --> 00:34:03.600
video or like trying to get audio in can be tricky.

00:34:03.600 --> 00:34:05.640
But a text message is really low bandwidth.

00:34:05.640 --> 00:34:08.260
So for a lot of people, this is like a great way to communicate.

00:34:08.260 --> 00:34:11.180
And of course, I'm a little bit biased because I work for Raza.

00:34:11.180 --> 00:34:13.220
And I think it's awesome that they use Raza to build this.

00:34:13.220 --> 00:34:15.960
But again, the whole thing is just open source.

00:34:15.960 --> 00:34:22.840
You can go to their GitHub and you can just, if I'm not mistaken, there's like the scraping job

00:34:22.840 --> 00:34:25.020
of the endpoints actually in here as well.

00:34:25.020 --> 00:34:27.220
But this is like exactly what you want.

00:34:27.220 --> 00:34:30.940
Just a couple of open APIs and sort of citizen science, building something that's useful for the

00:34:30.940 --> 00:34:31.220
community.

00:34:31.220 --> 00:34:31.620
It's great.

00:34:32.060 --> 00:34:33.000
Yeah, I like it.

00:34:33.000 --> 00:34:36.900
And text message is probably a really good way to communicate for disasters, right?

00:34:36.900 --> 00:34:37.280
Yes.

00:34:37.280 --> 00:34:43.600
Possibly in a place where, you know, LTE is crashed, Wi-Fi is out, right?

00:34:43.600 --> 00:34:47.280
Like if even if you're on edge, you know, text should still get there.

00:34:47.280 --> 00:34:47.860
Exactly.

00:34:47.860 --> 00:34:49.800
Unless you're on iMessage, then you're out of luck.

00:34:49.800 --> 00:34:50.540
No, I don't know.

00:34:50.540 --> 00:34:51.520
Sort of.

00:34:51.520 --> 00:34:52.440
Well, yeah.

00:34:52.440 --> 00:34:55.140
I live in Europe, so I cannot comment on that, of course.

00:34:55.140 --> 00:34:57.200
But it's a little bit different here.

00:34:57.200 --> 00:35:00.120
But no, but like the data service, you can just look in here.

00:35:00.120 --> 00:35:04.220
And this is like, again, I like these little projects that don't need anyone's permission

00:35:04.220 --> 00:35:05.280
to help people.

00:35:05.280 --> 00:35:07.080
Like that stuff, like, this is good stuff.

00:35:07.080 --> 00:35:08.100
Yeah.

00:35:08.100 --> 00:35:12.460
And the thing that I also really like about it is it's really just sending you a text message

00:35:12.460 --> 00:35:14.980
with like air quality information and like enough information.

00:35:14.980 --> 00:35:15.540
And that's good.

00:35:15.540 --> 00:35:19.580
It's not like they're trying to make like a giant predictive model on top of this or anything

00:35:19.580 --> 00:35:20.020
like that.

00:35:20.020 --> 00:35:22.500
But just really doing enough and enough is plenty.

00:35:22.500 --> 00:35:24.540
Like that's the thing I really love about this little demo.

00:35:24.980 --> 00:35:26.720
And of course, using Raza, which is great.

00:35:26.720 --> 00:35:32.880
But this is the kind of stuff that this is why I get up in the morning projects like this.

00:35:32.880 --> 00:35:34.160
That's fantastic.

00:35:34.160 --> 00:35:36.180
Yeah, I love it.

00:35:36.180 --> 00:35:36.880
That's a really good one.

00:35:36.880 --> 00:35:37.840
Brian, is that it?

00:35:37.840 --> 00:35:39.200
Yeah, that's it.

00:35:39.200 --> 00:35:41.040
It's our six items.

00:35:41.040 --> 00:35:43.660
Any extras that you want to talk about?

00:35:43.660 --> 00:35:44.860
I might have one.

00:35:44.860 --> 00:35:45.480
Okay.

00:35:45.480 --> 00:35:46.000
Yeah.

00:35:46.420 --> 00:35:46.780
Okay.

00:35:46.780 --> 00:35:51.640
So I'm totally tooting my own horn here, but this is a project I made a little while

00:35:51.640 --> 00:35:52.000
ago.

00:35:52.000 --> 00:35:54.580
But I think people might like it.

00:35:54.580 --> 00:35:58.900
So at some point, it kind of struck me that people are making these machine learning algorithms

00:35:58.900 --> 00:36:03.480
and they're trying to like on a two dimensional plane, trying to separate the green dots from

00:36:03.480 --> 00:36:04.920
the red ones from the blue ones.

00:36:04.920 --> 00:36:10.400
And I just started wondering, well, why do you need an algorithm if you can just maybe draw

00:36:10.400 --> 00:36:10.820
one?

00:36:10.960 --> 00:36:14.820
So very typically you got these like clusters of red points and clusters of blue points.

00:36:14.820 --> 00:36:19.040
And I just started wondering, maybe all we need is like this little user interface element

00:36:19.040 --> 00:36:20.800
that you can load from a Jupyter notebook.

00:36:20.800 --> 00:36:25.040
And maybe once you've made a drawing, it'd be nice if we can just turn it into a scikit-learn

00:36:25.040 --> 00:36:25.340
model.

00:36:25.340 --> 00:36:29.700
So there's this project called Human Learn that does exactly this.

00:36:29.700 --> 00:36:35.280
It's a tool of little buttons and like widgets that I've made to just make it easier for you

00:36:35.280 --> 00:36:37.960
to like do your domain knowledge thing and turn it into a model.

00:36:38.080 --> 00:36:42.580
So one of the things that it currently features is like the ability to draw a model, which

00:36:42.580 --> 00:36:45.800
is great because domain experts can just sort of put their knowledge in here.

00:36:45.800 --> 00:36:50.300
It can do outlier detection as well, because if a point falls outside of one of your drawn

00:36:50.300 --> 00:36:52.180
circles, that also means that it's probably an outlier.

00:36:52.180 --> 00:36:57.740
But it also has a tool in there that allows you to turn any Python function, like any like

00:36:57.740 --> 00:37:01.520
custom Python written function into a scikit-learn compatible tool as well.

00:37:01.520 --> 00:37:05.520
So if you can just declare your logic in a Python function, that can also be a machine learning

00:37:05.520 --> 00:37:06.300
model from now on.

00:37:07.000 --> 00:37:09.380
There's an extra fancy thing if people are interested.

00:37:09.380 --> 00:37:16.640
I just made a little blog post about that, where I'm using a very advanced coloring technique

00:37:16.640 --> 00:37:17.960
using parallel coordinates.

00:37:17.960 --> 00:37:20.200
Very fancy technique.

00:37:20.200 --> 00:37:22.060
I won't go into too much depth there.

00:37:22.060 --> 00:37:27.780
But what's really cool is that you can basically show that a drawn model cannot perform the model

00:37:27.780 --> 00:37:32.400
that's on the Keras deep learning blog, which I just thought was a very cool little feature

00:37:32.400 --> 00:37:32.820
as well.

00:37:33.300 --> 00:37:35.000
The project's called Human Learn.

00:37:35.000 --> 00:37:40.080
It's just components for inside of Jupyter Notebook to make sort of domain knowledge and

00:37:40.080 --> 00:37:42.340
human learning and all that good stuff better.

00:37:42.340 --> 00:37:47.300
And also with the fairness thing in mind, I really like the idea that people sort of can

00:37:47.300 --> 00:37:51.980
do the exploratory data analysis bit and at the same time also work on their first machine

00:37:51.980 --> 00:37:52.900
learning model as a benchmark.

00:37:52.900 --> 00:37:54.460
That's what Human Learn does.

00:37:54.540 --> 00:37:57.820
So if people are sort of curious to play around with that, please do.

00:37:57.820 --> 00:37:58.580
It's open source.

00:37:58.580 --> 00:37:59.100
PIV install.

00:37:59.100 --> 00:37:59.960
Please use it.

00:37:59.960 --> 00:38:00.720
I'm impressed.

00:38:00.720 --> 00:38:01.300
This is cool.

00:38:01.300 --> 00:38:02.120
It is, right?

00:38:02.120 --> 00:38:02.200
It is, right?

00:38:02.200 --> 00:38:02.780
Yeah.

00:38:03.460 --> 00:38:07.260
Matty out in the live stream asks, how does it handle ND data?

00:38:07.260 --> 00:38:08.020
So-

00:38:08.020 --> 00:38:09.360
And I guess it's three or larger.

00:38:09.360 --> 00:38:09.920
Yeah.

00:38:09.920 --> 00:38:14.880
So you can make like, so if you have four columns, you can make two charts with two dimensions.

00:38:14.880 --> 00:38:15.980
That's one way of dealing with it.

00:38:15.980 --> 00:38:19.080
And there's like a little trick where you can combine all of your drawings into one thing.

00:38:19.080 --> 00:38:23.620
If you go to the examples though, the parallel coordinates chart that you see here, that has

00:38:23.620 --> 00:38:25.380
30 columns and it works just fine.

00:38:25.740 --> 00:38:30.160
I do think like 30 is probably like the limit, but the parallel coordinates chart, I mean,

00:38:30.160 --> 00:38:32.940
you can make a subselection across multiple dimensions.

00:38:32.940 --> 00:38:33.800
That just works.

00:38:33.800 --> 00:38:37.460
It's really hard to explain a parallel coordinates chart on a podcast though.

00:38:37.460 --> 00:38:39.680
I'm sorry.

00:38:39.680 --> 00:38:40.460
Yeah.

00:38:40.460 --> 00:38:44.640
So this is like a super interactive visualization thing with lots of colors and stuff happening.

00:38:44.640 --> 00:38:45.180
I'm sorry.

00:38:45.180 --> 00:38:47.260
You have to go to the docs to fully experience that, I guess.

00:38:47.260 --> 00:38:54.280
But again, also, like if you, let's say you work for a fraud office and someone asks you like,

00:38:54.360 --> 00:38:56.700
Hey, without looking at any data, can you come up with rules?

00:38:56.700 --> 00:38:57.600
That's probably fraud.

00:38:57.600 --> 00:39:01.460
And you can kind of go, yeah, if you're 12 and you earn over a million dollars, that's probably

00:39:01.460 --> 00:39:01.780
weird.

00:39:01.780 --> 00:39:03.120
Someone should just look at that.

00:39:03.120 --> 00:39:05.660
And the thing is you can just write down rules that way.

00:39:05.660 --> 00:39:08.860
And that should already be, can already be turned into a machine learning model.

00:39:08.860 --> 00:39:09.720
You don't always need data.

00:39:09.720 --> 00:39:11.920
And that's the thing I'm trying to cover here.

00:39:11.920 --> 00:39:14.560
Like just make it easier for you to declare stuff like that.

00:39:14.560 --> 00:39:15.960
It's a more human approach.

00:39:15.960 --> 00:39:16.580
Nice.

00:39:16.580 --> 00:39:17.620
Brian, I cut you off.

00:39:17.620 --> 00:39:18.240
Were you going to say something?

00:39:18.240 --> 00:39:23.100
Oh, one of the things, I don't know if we've covered this already, but we've talked about

00:39:23.100 --> 00:39:26.060
comcode.io a lot on this podcast.

00:39:26.060 --> 00:39:29.120
And you're the person behind it, right?

00:39:29.120 --> 00:39:30.140
Yeah, I am.

00:39:30.140 --> 00:39:30.420
Yeah.

00:39:30.420 --> 00:39:33.800
It's been a fun little side project that I've been doing for a year now.

00:39:33.800 --> 00:39:34.080
Yeah.

00:39:34.080 --> 00:39:34.640
Yeah.

00:39:34.640 --> 00:39:35.720
So nice videos.

00:39:35.720 --> 00:39:37.000
I like how short they are.

00:39:37.000 --> 00:39:37.780
Thanks.

00:39:37.780 --> 00:39:41.780
No, so I like to hear, like people tell me that, and that's also the thing that I was

00:39:41.780 --> 00:39:42.480
kind of going for.

00:39:42.480 --> 00:39:46.620
Like I love the, you know, when you watch a video, it was like a lightning talk and you

00:39:46.620 --> 00:39:47.900
learn something in five minutes.

00:39:47.900 --> 00:39:48.440
Yeah.

00:39:48.780 --> 00:39:50.140
Oh, that's an amazing feeling.

00:39:50.140 --> 00:39:52.060
Like that's the thing I'm trying to capture there a little bit.

00:39:52.060 --> 00:39:57.180
Like if, if it takes more than five minutes to get a point across, then I should go on

00:39:57.180 --> 00:39:59.180
to a different topic, but I'm happy to hear you like it.

00:39:59.180 --> 00:39:59.340
Cool.

00:39:59.340 --> 00:39:59.620
Yes.

00:39:59.620 --> 00:40:00.100
Very cool.

00:40:00.100 --> 00:40:01.420
How about you, Michael?

00:40:01.420 --> 00:40:02.220
Anything extras?

00:40:02.220 --> 00:40:04.200
Well, I had two.

00:40:04.200 --> 00:40:10.120
Now I have three because I was reading the source code of one of Vincent's projects there.

00:40:10.120 --> 00:40:13.560
And as we were talking and I learned about fuzzy wuzzy.

00:40:13.560 --> 00:40:21.480
So fuzzy wuzzy was being used in that emergency disaster recovery awareness thing.

00:40:21.480 --> 00:40:24.080
And it's fuzzy string matching in Python.

00:40:24.080 --> 00:40:28.380
And it says fuzzy string matching like a boss, which you got to love.

00:40:28.380 --> 00:40:32.260
So it was like slight misspellings and plural versus not plural and whatnot.

00:40:32.260 --> 00:40:36.500
And Brian even uses hypothesis, which is kind of interesting.

00:40:36.500 --> 00:40:37.120
Yeah.

00:40:37.120 --> 00:40:37.800
And pytest.

00:40:37.800 --> 00:40:38.260
Yeah.

00:40:38.260 --> 00:40:38.980
And pytest, of course.

00:40:38.980 --> 00:40:39.440
Yeah.

00:40:39.460 --> 00:40:40.600
Anyway, that, that's pretty cool.

00:40:40.600 --> 00:40:41.740
I just, I just discovered that.

00:40:41.740 --> 00:40:44.940
So fuzzy wuzzy is a pretty cool tool.

00:40:44.940 --> 00:40:46.540
The only thing I don't like about it.

00:40:46.540 --> 00:40:47.940
And it's the one thing I do have to mention.

00:40:47.940 --> 00:40:52.640
It's, it is my understanding that fuzzy wuzzy is a slur in certain regions of the world.

00:40:52.640 --> 00:40:55.580
That's so in terms of naming a package, they could have done better there, but I think

00:40:55.580 --> 00:40:56.600
they only realized that in hindsight.

00:40:56.600 --> 00:40:58.580
Other than that, there's some cool stuff in there.

00:40:58.580 --> 00:40:59.020
Definitely.

00:40:59.020 --> 00:41:03.380
Just when I learned about this, I did make the comments to myself like, okay, I should always

00:41:03.380 --> 00:41:04.780
acknowledge it whenever I talk about the package.

00:41:04.780 --> 00:41:07.700
But yeah, it's a, it's definitely useful stuff in there.

00:41:07.700 --> 00:41:09.300
Fuzzy string matching is a useful.

00:41:09.300 --> 00:41:10.640
It's a useful problem to have a tool for.

00:41:10.640 --> 00:41:11.120
Yeah.

00:41:11.120 --> 00:41:11.640
Very cool.

00:41:12.080 --> 00:41:18.140
And PyCon way out in the future, 2024, 2025 announcement is out.

00:41:18.520 --> 00:41:23.140
So the next two PyCons are already theoretically in Salt Lake City.

00:41:23.140 --> 00:41:28.420
So hopefully we actually go to Salt Lake City and not just go and we'll virtually imagine

00:41:28.420 --> 00:41:29.280
it was there, right?

00:41:29.280 --> 00:41:29.940
Like this year.

00:41:29.940 --> 00:41:36.360
But last two years, because of the pandemic, Pittsburgh lost its opportunity to have PyCon.

00:41:36.360 --> 00:41:37.940
So not just once, but twice.

00:41:37.940 --> 00:41:41.440
So they are rescheduling the next one back into Pittsburgh.

00:41:41.440 --> 00:41:43.960
So folks there will be able to go and part of PyCon.

00:41:43.960 --> 00:41:45.000
That's pretty cool.

00:41:45.000 --> 00:41:49.120
Because of Corona, they've now been able to plan four years ahead of the way.

00:41:49.120 --> 00:41:50.340
Exactly.

00:41:50.340 --> 00:41:52.900
Everything's upside down now.

00:41:53.320 --> 00:41:57.300
And then also, I just want to give a quick shout out to an episode that I think is coming

00:41:57.300 --> 00:41:58.720
out this week on Talk Python.

00:41:58.720 --> 00:42:02.160
I'm pretty sure that's the schedule called CodeCarbon.io.

00:42:02.160 --> 00:42:04.680
And it is a, let me pull it up here.

00:42:04.680 --> 00:42:11.520
It is both a dashboard that lets you look at the carbon generation, the CO2 footprint of your

00:42:11.520 --> 00:42:16.340
machine learning models as you specifically around the training of the models.

00:42:16.480 --> 00:42:21.620
So what you do is you pip install someone here, you pip install this emission tracker,

00:42:21.620 --> 00:42:24.780
and then you just say, start tracking, train, stop tracking.

00:42:24.780 --> 00:42:30.420
And it uses your location, your data center, the local energy grid, the sources of energy

00:42:30.420 --> 00:42:31.140
from all that.

00:42:31.140 --> 00:42:37.660
And it'll say like, oh, if you actually switch to say the Oregon AWS data center from Virginia,

00:42:37.660 --> 00:42:42.920
you'd be using more, you would be using more hydroelectric rather than, I don't know,

00:42:42.920 --> 00:42:44.020
gas or whatever, right?

00:42:44.080 --> 00:42:48.300
So just, we were talking about some of the ethics and cool things that we should be paying

00:42:48.300 --> 00:42:48.780
attention to.

00:42:48.780 --> 00:42:53.360
And I feel like the sort of energy impact of model training might be worth looking at as

00:42:53.360 --> 00:42:53.520
well.

00:42:53.520 --> 00:42:56.160
So I totally agree with model training.

00:42:56.160 --> 00:42:59.160
I've been wondering about this other thing though, and that's testing on GitHub.

00:42:59.160 --> 00:43:02.720
Like if you think about some of these CI pipelines, they can be big too.

00:43:02.720 --> 00:43:05.340
Like I've heard projects that take like an hour on every commit.

00:43:05.340 --> 00:43:08.020
I'd be curious to run this on that stuff as well.

00:43:08.020 --> 00:43:08.640
Yeah.

00:43:08.640 --> 00:43:13.840
Well, you could turn on, you could employ this as part of your CI CD.

00:43:13.840 --> 00:43:19.300
It doesn't really have to do with model training per se, but it does things like when you train

00:43:19.300 --> 00:43:23.860
models that use a GPU, it'll actually ask the GPU for the electrical current.

00:43:23.860 --> 00:43:25.120
Ah, right.

00:43:25.120 --> 00:43:25.380
Right.

00:43:25.380 --> 00:43:26.920
So it goes down into the hardware.

00:43:26.920 --> 00:43:28.260
That's a fancy feature.

00:43:28.260 --> 00:43:29.440
That's a fancy feature.

00:43:29.440 --> 00:43:34.060
And it goes down to like the CPU level, the CPU level voltage and all sorts of like low.

00:43:34.060 --> 00:43:35.720
It's not just, well, it ran for this long.

00:43:35.720 --> 00:43:36.940
So it's this, right?

00:43:36.940 --> 00:43:38.560
That's like really detailed.

00:43:38.560 --> 00:43:44.300
That said, I suspect you could actually answer the same question on a CI, right?

00:43:44.300 --> 00:43:46.420
It would just say, well, it looks like you're training on a CPU.

00:43:46.420 --> 00:43:47.960
Yeah.

00:43:47.960 --> 00:43:48.920
Yeah.

00:43:48.920 --> 00:43:49.500
True.

00:43:49.500 --> 00:43:53.200
But so it's a nice way to be conscious about compute times and stuff.

00:43:53.200 --> 00:43:53.580
So that's.

00:43:53.580 --> 00:43:54.040
Yeah.

00:43:54.040 --> 00:43:58.360
And what's cool is it has the dashboard that like actually lets you explore like, well,

00:43:58.360 --> 00:44:02.300
if I were to shift it to Europe rather than train in the US, which who really cares where

00:44:02.300 --> 00:44:04.660
it trains with that, what difference would that have?

00:44:04.660 --> 00:44:07.700
Look at how green Paraguay is where you're hosting.

00:44:07.700 --> 00:44:08.460
Yeah.

00:44:08.460 --> 00:44:09.140
That's incredible.

00:44:09.140 --> 00:44:11.720
I suspect a lot of waterfalls.

00:44:11.720 --> 00:44:12.340
Yeah.

00:44:12.340 --> 00:44:13.020
Hydro.

00:44:13.020 --> 00:44:15.200
Countries down there have insane amounts of hydro.

00:44:15.200 --> 00:44:16.100
Yeah.

00:44:16.100 --> 00:44:17.060
Like Chile.

00:44:17.060 --> 00:44:19.280
Maybe I can't remember exactly, but yeah, it's a lot of hydro.

00:44:19.280 --> 00:44:20.920
And you see, and you see Iceland as well.

00:44:20.920 --> 00:44:22.980
And it's probably because of the volcanoes and warmth and heat.

00:44:22.980 --> 00:44:23.400
And yeah.

00:44:23.400 --> 00:44:23.660
Yeah.

00:44:23.660 --> 00:44:24.040
The geo.

00:44:24.040 --> 00:44:24.260
Yeah.

00:44:24.260 --> 00:44:24.820
Okay.

00:44:24.820 --> 00:44:25.140
Interesting.

00:44:25.140 --> 00:44:25.860
All right.

00:44:25.860 --> 00:44:26.580
Nice.

00:44:26.580 --> 00:44:27.420
Brian, you got anything?

00:44:27.420 --> 00:44:28.640
Not this week.

00:44:28.640 --> 00:44:29.980
How about we do a joke?

00:44:29.980 --> 00:44:30.860
Sounds good.

00:44:30.860 --> 00:44:31.800
So.

00:44:32.100 --> 00:44:36.760
It's been a while since I've been to a strongest man competition, world's strongest

00:44:36.760 --> 00:44:37.160
man.

00:44:37.160 --> 00:44:40.840
You know, like maybe one of those things where you pick up like a telephone pole and you have

00:44:40.840 --> 00:44:44.640
to carry this throat as far as you can, or you lift like the heaviest barbells or like

00:44:44.640 --> 00:44:46.460
you carry huge rocks some distance.

00:44:46.460 --> 00:44:48.200
So here's one of those things.

00:44:48.200 --> 00:44:53.160
There's like three judges, a bunch of people who look way over pumped.

00:44:53.160 --> 00:44:55.300
They're all flexing, getting ready.

00:44:55.300 --> 00:45:00.120
The first one is this person carrying a huge rock, sweating clearly.

00:45:00.120 --> 00:45:02.060
And the judges are, they're not super impressed.

00:45:02.060 --> 00:45:03.860
They give a five, a two and a six.

00:45:03.860 --> 00:45:07.700
Then there's another one lifting this, you know, 500 pound barbell over his head.

00:45:07.700 --> 00:45:09.920
Does eight, seven, a six is their score.

00:45:09.920 --> 00:45:14.540
And then there's this particularly not overly strong looking person here.

00:45:14.540 --> 00:45:15.860
It says, I don't code.

00:45:15.860 --> 00:45:17.240
I don't use Google when coding.

00:45:17.240 --> 00:45:18.100
Wow.

00:45:18.100 --> 00:45:19.120
So strong.

00:45:19.120 --> 00:45:20.740
The judges give them straight tens.

00:45:21.900 --> 00:45:24.580
And he's, he's also being like really sincere.

00:45:24.580 --> 00:45:25.820
Like his hand over his heart.

00:45:25.820 --> 00:45:26.900
Oh yeah.

00:45:26.900 --> 00:45:28.480
Like it's very humble.

00:45:28.480 --> 00:45:29.300
Yeah, exactly.

00:45:29.300 --> 00:45:31.320
All right.

00:45:31.320 --> 00:45:32.940
Well, that's what I got for you.

00:45:32.940 --> 00:45:34.700
Take it, take it for what you will.

00:45:34.700 --> 00:45:35.620
That's pretty good.

00:45:35.620 --> 00:45:36.720
Just stack overflow.

00:45:36.720 --> 00:45:37.340
Yeah.

00:45:37.340 --> 00:45:37.680
Yeah.

00:45:37.700 --> 00:45:41.060
Well, I feel like stack overflow would be, we give them, take it to 11.

00:45:41.060 --> 00:45:45.120
Honestly, I don't use stack overflow now.

00:45:45.120 --> 00:45:45.700
Yeah.

00:45:45.700 --> 00:45:46.080
You're the winner.

00:45:46.080 --> 00:45:48.180
Definitely.

00:45:48.180 --> 00:45:48.800
That's funny.

00:45:48.800 --> 00:45:50.460
Well, thanks for that.

00:45:50.460 --> 00:45:53.180
Um, you're usually pretty good about finding our jokes.

00:45:53.180 --> 00:45:54.540
I appreciate it.

00:45:54.540 --> 00:45:57.160
And, thanks for coming on the show.

00:45:57.160 --> 00:45:59.360
Uh, thanks for having me.

00:45:59.360 --> 00:46:00.000
It's fun.

00:46:00.000 --> 00:46:00.980
I think that's a wrap.

00:46:00.980 --> 00:46:01.940
Yeah, that is.

00:46:01.940 --> 00:46:02.780
Thanks, Brian.

00:46:02.780 --> 00:46:03.440
Thank you.

00:46:03.440 --> 00:46:03.860
Bye Vincent.

