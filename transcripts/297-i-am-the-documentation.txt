00:00:00 Hello, and welcome to python bytes where we deliver Python news and headlines directly to your earbuds. This is Episode 297, recorded August 16 2022. And I am Brian nock. And I'm Michael Kennedy. It's good to get to be back and be with you, Michael. Yeah, it's great to be back. Not in the usual location today, you may hear some nature sound from I apologize if animals go crazy. But there's construction, which is guaranteed to be a problem in my office. So I'm sitting in the backyard. We'll see how it goes. Yeah, for anyone

00:00:30 listening on the podcast, the livestream, people get to see his lovely view from his backyard. Some nice trees. Yeah, same big trees. It's all it's all Oregon backyard here. Nice. But also, I also want to say this episode is brought to you by IRL podcast from Mozilla. So we'll tell you more about that later. But thanks to Mozilla and the IRL podcast for supporting the show. Thank you. Let's talk about writing code. By not writing code. Does that sound like a good idea? Well, okay. Not in the low code, no code sense. There's actually some pretty cool tools in that space. But that's not what I'm talking about. Imagine, Brian, somebody says, we used to be a dotnet sharp, and we have this huge database. And all of our code to talk to it isn't some other language or it's Ruby, or it's Java or whatever. It's not Python. And you decide the best way to talk to this database is with some flavor of SQL, Alchemy, SQL alchemy straight, or if you prefer, you could have it with data classes. Or you could even mix in a little sprinkling of sequel model, if you're doing async and fast API and Pydantic. And whatever choice you want to make from that perspective, if you're looking at a database with 150, tables, and all sorts of gnarly relationships, you might say, Well, I'm gonna have to spend the next week planning out how to model those out so I get them to exactly match the database. Is it a VAR char is that a VAR char with a limit? Like var Char 10? Or, you know what? That doesn't sound fun, does it? No, no, not it. I mean, at least for me, maybe some people that's a special kind of fun for them. But Josh Thurston sent over this project called sequel, a sequel alchemy code Gen. So I'm taking it he doesn't think it sounds like fun. I certainly don't think that it does, either. So people can check this out. It's, it's looks really cool. And what you do is it's an automatic model generator for SQL alchemy, this, what is it generated from? So what you do is you go through, and you pointed at some database, okay, just a sequel, a code Gen, and you give it your connection string, for example, Postgres SQL colon, triple slash, some database, connection string. And then magic happens. And you have a whole bunch of Python classes that are attempted to look handwritten. Yeah. So instead of taking all your time, like a week, to model out the database, and the relationships and all that stuff in Python, you run this one command line thing. And then you have all the classes and then you can tweak them a tiny bit if you see fit. Okay, so this is okay. You probably said this, and I missed it. But so you're already have data in a database, and you're trying to hook up an application to yours. Yeah. Which is why I went to my theoretical theoretical example, I've have a database, I have code that talks to it, but it's not Python. And so there's not really something to work from. But I've got a really complicated database that's been around for a while. It doesn't have to be complicated, but the more gnarly the database, the more you will appreciate this tool making doing it for you. I think I have this situation. Okay. Anyone use this? Yeah, yeah. Yeah. So it does a bunch of neat things. It's written to read the structure of an existing database and generate the appropriate SQL alchemy model code, using the declarative style, if possible, so deriving from SQL alchemy declarative base. It's also there was some other tool called SQL Autocode, which apparently has some limitations, such as, for example, it doesn't support python three, or recent versions of SQL alchemy. That seems like a pretty large limitation, but whatever.

00:04:05 So this supports the newest version, it produces Pepe compliant code tries to make it look like you're writing code by hand so it doesn't look auto generated, it automatically automatically detects join table inheritance and all kinds of things. So by scroll down here, it's got these different generators, so you can generate table objects for people who don't want to use the ORM. Because sequel alchemy has these two flavors, like a low level, slightly above just raw SQL, and then the ORM, which is the one that I use all the time. By default, it uses the RM one, but you can also use, like I said, data classes, which is pretty excellent. Instead of, you know, case, that's what you want your code to look like. Or even better than that. You can use SQL model models for using SQL model, which is the project I'm sure we've discussed it before by Sebastian. It's based on Pydantic and async. But then it's built really on top

00:05:00 of SQL alchemy. So you're looking to do the newer version of that, you get this, by the way, just thinking about it. While I'm looking at this, maybe I have actually a sequel alchemy generated database. But it's written in the older style of SQL alchemy. And it's not using SQL model, and I want to just upgrade to SQL model, you might be able to use the database, just go rewrite it for me again, but in this in this flavor, you know, or use it to generate the data class version that actually looks pretty cool. Or do all of them and look at it and see which one he looks looks like. It's more fun to maintain. Yeah, exactly. So there's a whole bunch of options and stuff that you can use. But you can basically pass a pass a bunch of command line arguments and stuff to change how it works, like, change how it names objects, or change out names fields, that are etc. People they really want to look into it and use it. I think they all got the idea from this. Okay, cool. Cool. Yeah, looks really cool. Yeah. Anytime you've got a database, they're so hard to model because you've got to get the sequel alchemy code to match it just right, or it won't work at all. And yet, you know, you do really want to do that behind by hand. No, I don't. And so, Sequel A kojin. Thanks, Josh. Well, I'm going to talk about package. I mean, my headspace is in packaging lately, because I'm preparing a talk for next month, and it is going to have some packaging stuff in it. So this is really exciting. With I heard from Juan Luis canto Rodriguez, Rodriguez, sorry, setup tool. 660 4.00 is out. and it ships with PEP 660 editable installs. So this the the big headline is not that although that's really cool. It's that most projects don't need to setup.pi or setup dot CFG anymore. Those Those can be gone. So and not that setup.pi was evil, but it kind of was evil. Because what it does is it runs Python runs Python while you install something like when used normally, it's fine. When but it has this tremendous gaping hole for abusing things at different levels. Yeah, and the the Okay, so the the caveat on this is, the reason why it has that is sometimes it goes out and compile stuff if it's not just pure Python stuff. But you don't need that for that you use a lot of product. Most projects don't need that anymore, because they're not really compiling stuff they're on during pip install. They're they're compiling stuff ahead of time, and they have their separate wheels for different architectures. So I like that model better. So anyway, the I'm like, pretty excited about that. So there's a so yeah, congrats to the pipe VA for getting that done. We've got, there's an article called development mode, editable installs. So here you've got pip install editable, that works with setup tools without a setup.pi used to have to have a shim. So everything can be in pipe Project dot Tamil now, and, and so one of the cool things, and I actually discovered this also at the same time I was researching packaging stuff, the pipe EA has this really cool guide packaging Python projects. And they, what's neat is they keep it up to date fairly well. And this whole tutorial, it's simple. So you got a simple Python project and you want to try to learn how to package they have this this page here. It's nice. There's no mention of setup.pi or setup dot cfg. It's all Pi project at home. Oh, wow. That's awesome. Here's how you do it. And you don't even talk about the older more. You have trouble some way. Yeah. And since setup tools and PIP are not part of Python proper, they're separate things. Well, I mean, you get Python, Pip when you when you download Python, but you get a version you and you usually upgrade anyway. But sub tools is separate. So they can move at a faster pace than Python itself. So Oh, right. Okay, excellent. Well, this is great news. Anything that makes the supply chain side of Python stronger? Is it? Yep, indeed. Well, before we move on to the next thing, brain, let me tell you about our sponsor. All right. So this episode of Python bytes is brought to you by the IRL podcast in original podcast from Mozilla. If you're like me, and Brian, we care about ideas behind technology, not just the tech itself. So we know that Tech has an enormous influence on society. Many of these effects are hugely beneficial. Just think about carrying all of the world's information in our pocket sort of thing. But other tech influences can have negative effects. And I really appreciate that Mozilla is always on the lookout for and working to mitigate negative influences of tech on all of us all the tracking stuff they're doing, but a bunch of awareness things as well. And so if these ideas resonate with you, you should definitely check out the RL podcast. It's hosted by Bridget Todd and this season is very much in the focus of Python. It's AI in real life.

00:10:00 So who can add? Who can AI help? Who can it harm? The show features fascinating conversations with people are working on building more trustworthy AI, for example, there's an episode about how our world is mapped with AI. And it's the data that's missing from those maps that tells as much of the story as the maps himself or another one's about gig workers and how they're pushing back on algorithms to create better working style. And for political junkies. There's an episode about how that the role of AI plays when it comes to spreading disinformation about elections, obviously, huge concern as just across the world for all the democracies, I also just listened to the tech we won't build which will, which explores, when developers and data scientists should consider pushing back on projects that can be harmful to society, even though the machine learning can easily be turned on them. If this sounds interesting, and train upset for yourself, just check out just search for RL and your podcast player or visit Python bytes FM slash IRL. The link is in your podcast player show notes. Thank you so much to IRL, on Zillow for supporting the show. I've been listening to it. It's really great show. Yeah, yeah, I enjoy it as well. It's it's not super, super technical, where it's all about API's and stuff. You can kind of just kick back and enjoy. Not like this podcast where we assume non technical. Exactly. Yeah, we talk about a bunch of technical things sometimes not too deeply, huh? No, I like I like our level. Yeah, I do too. I do too. Before we get on to the next topic. I just want to do a quick audience. Comment from Anna here says hello from London UK SQL. cogent sounds like it could save a lot of headaches. Yeah, I think it's gonna be great. Yeah. And feedback for the tutorial that you highlighted Brian on python.org. Yep. Henry Shriner says it took around six months for my rewrite of that page to get accepted. Well, thank you for all the hard work. And that's awesome. It great job. That's it looks great. So yeah, very, very cool. Previously, I had talked about async cash, remember that where it's like the func tools, LRU cache, but a little bit more. However, you can apply to async methods. Oh, and Lamont said, you may also be interested in a IO cache. What this one does is this lets you use proper distributed backends for caching. So, for example, if you're on a web app, you might have five 610, a many more worker processes, either on one machine using the supervisor mode of like G unicorn, or it could be even across different computers. If you're using that in memory version of cash, every time the request goes to a different part of your site, or different run time different process running your site, you've got to recompute it right? Well, this one also supports Redis and memcached. Oh, sweet, or memcache D. And it has a common API across all of them, which is pretty fantastic. And they're all async and await a bowl, which is cool. So it aims for simplicity, rather than trying to highlight all the nuances of that's particular say to Redis versus the others. So it has an add a get a set multi gate if you need to say give me the values corresponding to these four IDs, or does this thing exist or not delete, clear, even incremented value, like how many people viewed this page, increment that in the cache, and it's shared across, like I said, 10 Worker processes across machines instantly. Of course, that's pretty cool. Yeah, so super easy to work with, you can install it, but then you should also reference probably the specialization that you're using or the back end that you're using. So for example, you can say pip install aIIow cache, but if you want to use Redis, it's bracket Redis. If you want to use Redis, and Memcache, D might say, you know, bracket, Redis, Memcache D, they have message pack in different formatting. So depending on how you're using it, you might have to install some dependencies. Okay, the optional install mechanism of PEP is pretty cool, though, like it is, it's pretty cool. So you just import async IO easy. And then import EO cash, and you got to just basically run, run your loop somewhere or using something like fast API, just bad things generated or managing the loop race, you don't have to worry about it. So you can just say await cash dot Set Key comma, value await cash dot get key pounds, pretty straightforward, right? You can even use it as a decorator. So if you put apt cache on a function, and give it time to live the target, which is Redis, the key to use for that particular thing and so on, and then off, it goes to serializer pickles, or you have message pack or JSON, and then you go pretty cool, huh? So does okay. So for a function does it cache the input and output of that function then think it caches the output? Okay.

00:14:37 But it doesn't Ness, it doesn't look like it varies, okay, by

00:14:42 using this example is not very big. Yeah. And I don't see how you would like this key is the lookup value, right? So you might call that Cashcall key result or something. I don't see how you dynamically do that. It's got to be like a void but you know, a lot of times that's just like show me all the product

00:15:00 Send this right database or whatever. So yeah, yeah. Cool. Yeah. Pretty neat.

00:15:05 Very neat. Yeah. And then your different three basic ideas to think about, you have these back end. So you have Redis, backed by aIIow Redis, you have Memcache, backed by aIIow, Memcache. And then serializers. Like you can serialize to string pickle JSON message pack, but you can also build your own. And you can also plug in, there's a bunch of examples and documentation people can check out. So this looks really neat to me. Yeah, it's nice. Not quite something that I need. But if I did need it, I would definitely go. I know, I I'd be all over it. Yeah. Regarding the level of level of detail we have in our podcast, as he Steve says, I only listened to podcasts about API's.

00:15:48 So nice. What's your last one, Brian? My last one is? Well, the Python packaging project packaging Python project. Same thing. No, ever new one. But I got it from this. So when I was reading this article, or this tutorial again, I came across something I wasn't familiar with. So I had to go check it out. So down with creating a Pi project tamo. One of the options is hatchling. Have you heard? Yeah. Have you heard of hatch? Is this somehow related to hatch? Yeah, it is hatch. So have we already covered? Actually, no, I don't think we have here but I love the idea of it. Okay, so. So hatch is a modern extensible Python project manager with a whole bunch of cool features like a standardized build systems, build system and reproducible builds by default. And environment match management, which, you know, okay, so with so I'm not sure if this is similar to poetries, environment manager or not, I haven't played with it much. But but you don't actually have to care, which is nice. Because poetry, you have to care about it, because that's part of the whole thing. Anyway, publishing is easy to pi pi and other sources, version management, project generation with sane defaults, which I haven't tried that. So I want to try that. And supposedly a responsive CLI that's two to three times faster than equivalent tools. So this I definitely need to try. So this is ISE. I would think it's similar on line of flit, I think, but with some extra things thrown in, because and one of the reasons why I love for lit now is because even though setup tools does now support pipe project tamo properly completely flips, like twice as fast for building stuff. But but so I definitely want to try out hatch and try this. I did try one little small project, just converting a flip project to hatch. And it took me like five minutes, just using the documentation here is great. So the excellent documentation here about how to use the different pieces of it. So it's pretty neat. Have you tried it? I have not tried it. I've looked at it. And it it looks neat to me. I don't make many packages, I more build applications and web apps and stuff. So I I'm less in the what's the right tool to build packages properly. You know, and I know you're doing that a little bit more. So yeah, yeah. So we're in from you. I guess good mix, I do more packages and less applications and you do more applications. So yeah, some live feedback. Henry Shriner says, you can use any PEP 61 back end hatchling PDM, blitt core and so on with hatch or with PDM? Two, one of the fantastic results of standardization. And that actually does a much better job of getting source files, right than flit core. Okay. Interesting. Yeah, there's, there's, there was a lot of cool options with the hatch that you could specify exactly which modules and packages to pick up if you need to. That's one of the things that's a little bit mysterious with let him how to figure it out. Because it, it just sort of knows, somehow, I think it's the the stuff that's in Git, but it's interesting. So the main thing is, is I really like with the standardization, that hatches possible, the Flitz possible that PDM is possible that we can do new things. And they're not that different. Like the it's kind of the back end of packaging. The front end is the pipe project at Tom. That's a better world to be in. So yeah, that separation, let's let there be a lot more exploration a lot more variation. Alright, well, that's it for our items. I think so yeah. You got any extras?

00:19:28 No, but hopefully I will soon. So I've got something on Wow. Right on. Yes, I know. I think I know what you're alluding to very exciting stuff coming quite soon. Yeah, I bet you have. I have one extra. This one's quick, but quite cool. So I'm sitting here on my MacBook Pro with the M one MacBook Pro, the and one max. And until recently, I wasn't able to use pi pi. Now, high pi is the JIT compiled, often faster version of Python. Sometimes you'll hear people say pi pi

00:20:00 When they are referring to pi pi, but all the people who work on pi pi, pronounce it that way. And it leaves space for pi pi to be pronounced like it should. So pi pi is the fast JIT compiled version of Python. And the big news is it couple weeks ago, they announced support for M one spirit. Cool. So if you're on Apple silicon, you can now use pi pi. That's very cool natively. Yeah, it was done by Fidel and supported by contributions from the open collective, which is pretty cool. And it's based on support for a Arch 64, which is arm 64, and Linux with some variations on how this works. So they've got three and three, nine working on macOS arm 64 platform, which is pretty cool. So if you're using that, and you've been waiting for this, it should make your code run faster, maybe use less memory, that kind of thing. Very cool. And people interested in pi pi, testing code on episode 190. I interviewed Carl Friedrich Bowles, about testing pipelines, so Oh, cool. Yeah, there's a lot of testing. I mean, it's the entire Python runtime. Basically, it's like in much of the standard library. That's a lot of work. Yeah. It's interesting story. So

00:21:14 would you say that testing and documentation are often really good things to add to your project that go along together? In some ways? Well, hopefully, you're doing it at the same time. But yes, yes. You know, we've all worked with different types of team dynamics, the sort of flat hierarchy, people will just take over the projects and parts of the project that they seem best suited for. And there might be more hierarchical

00:21:38 version. So our joke this week is about a somewhat dominate dominate.

00:21:45 Senior Developer here. And there's a junior developer just hired onto the scene team that, you know, this is a picture people can check it out. Just follow the link in the show notes. The junior ask, Where's the documentation in a very stern face? The team this is I am the documentation.

00:22:01 Yes.

00:22:03 Hopefully, you're not currently working in this situation. But it's pretty funny.

00:22:08 You know, there's always bits. There's always pieces of the system that like, well, well, how does this work? Oh, you've got to ask that guy. He's not even on our team before anymore. Yeah. But he's the one that wrote it. And luckily, he's still with the company. So go talk to him. Exactly. No one understands that we don't touch it anymore. It seems to still work. Yeah, exactly. All right. Well, what seems to still be working as our podcast, Brian, it does. Yeah. Thanks for your thank you. Yeah. Thanks for everyone who listen to y'all later. Bye.

