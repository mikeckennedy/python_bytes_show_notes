WEBVTT

00:00:00.001 --> 00:00:04.140
This is Python Bytes, Python headlines and news delivered directly to your earbuds.

00:00:04.140 --> 00:00:07.940
It's episode 16, recorded March 6, 2017.

00:00:07.940 --> 00:00:13.020
And this is your host, Michael Kennedy, here with my co-host, Brian Okken.

00:00:13.020 --> 00:00:13.420
Hey, Brian.

00:00:13.420 --> 00:00:13.940
Hello.

00:00:13.940 --> 00:00:14.460
Hello, hello.

00:00:14.460 --> 00:00:18.240
Well, I'm excited to talk about another week's worth of Python news.

00:00:18.240 --> 00:00:20.080
But before I do, I want to say thank you.

00:00:20.080 --> 00:00:21.880
Thanks to Rollbar for sponsoring this episode.

00:00:21.880 --> 00:00:22.660
Yes, thank you.

00:00:22.660 --> 00:00:22.940
Yeah.

00:00:22.940 --> 00:00:28.620
So you've got the first item, and it's kind of an artistic, postmodern type of thing,

00:00:28.620 --> 00:00:29.980
but with error handling, huh?

00:00:30.040 --> 00:00:30.240
Yeah.

00:00:30.240 --> 00:00:36.280
So there's an article on Journal Panic, and I've got to say that's a cool name for a website.

00:00:36.280 --> 00:00:40.980
But it was called Postmodern Error Handling in Python 3.6.

00:00:40.980 --> 00:00:46.120
And it's actually, it's not really, I guess you could consider it error handling.

00:00:46.120 --> 00:00:53.620
It's mostly like how to structure your code so that you don't make mistakes and let the language help you out.

00:00:53.620 --> 00:00:59.000
The examples are, I highly recommend the read because the examples are hilarious.

00:00:59.800 --> 00:01:09.240
And it goes through some error prevention, looking at using enum classes and the named tuple class,

00:01:09.240 --> 00:01:15.320
which I have to admit, I just like learned about, I've used named tuples, but I've only learned about the class recently.

00:01:15.320 --> 00:01:20.860
And using type hints in mypy to help avoid errors in your code.

00:01:21.100 --> 00:01:22.620
Yeah, I think it's really nice.

00:01:22.620 --> 00:01:25.820
Some of these are 3.4 only, right?

00:01:25.820 --> 00:01:29.380
Like enum support was added in Python 3.4, which is pretty cool.

00:01:29.380 --> 00:01:36.240
Yeah, there's somebody who commented, basically the idea was they were talking on some message board, like Cora or something,

00:01:36.720 --> 00:01:39.220
about like how would you handle this kind of error.

00:01:39.220 --> 00:01:42.040
Let's say, it's not true or false.

00:01:42.040 --> 00:01:43.980
It's true or false or maybe, right?

00:01:43.980 --> 00:01:47.640
And they proposed like this three-state type of thing.

00:01:47.640 --> 00:01:50.800
And somebody said, well, if you were using Rust, you could have enums.

00:01:50.800 --> 00:01:54.000
And he says, well, I'm using Python 3, so I have enums, right?

00:01:54.000 --> 00:01:54.980
That was pretty funny.

00:01:54.980 --> 00:01:55.620
Definitely.

00:01:55.620 --> 00:01:56.160
Okay.

00:01:56.620 --> 00:01:58.580
Oh, and yeah, the tail, it's nice.

00:01:58.580 --> 00:02:05.200
I only noticed this this morning is the tail end of this article references your talk Python, so that's cool.

00:02:05.200 --> 00:02:05.940
Yeah, oh, that's awesome.

00:02:05.940 --> 00:02:07.720
Yeah, thanks for referencing that.

00:02:07.720 --> 00:02:08.360
That's really cool.

00:02:08.360 --> 00:02:11.880
Yeah, so I think named tuples are so excellent.

00:02:11.880 --> 00:02:13.700
I've really started using named tuples a lot.

00:02:13.700 --> 00:02:14.680
I think they're great.

00:02:14.680 --> 00:02:16.180
Type hints?

00:02:16.180 --> 00:02:20.440
Yeah, named tuples I've been using a lot because they're very convenient.

00:02:20.440 --> 00:02:29.620
But the syntax is a little ugly, and the named tuple class actually makes the syntax a little bit cleaner, and I think that's cool.

00:02:29.620 --> 00:02:30.600
Yeah, very cool.

00:02:30.600 --> 00:02:37.180
And, of course, mypy, which is great for static type, well, type hinting, I guess, and type discovery.

00:02:37.180 --> 00:02:45.240
Yeah, and in the show notes, I'm also including a link to another article on mypy on type hints called Python type annotations,

00:02:45.240 --> 00:02:52.480
and that's from the cactus group, and it's another pretty good tutorial for type hints in mypy.

00:02:52.480 --> 00:02:53.800
Yeah, excellent, excellent.

00:02:53.800 --> 00:02:59.680
So the next one we're going to talk about, and this is sort of a sequence that I'm going to go through here.

00:02:59.680 --> 00:03:01.620
One leads to another in a very cool way.

00:03:01.620 --> 00:03:12.540
So mid-last year, mid-2016, Mozilla awarded a little over half a million dollars to nine open source projects just in Q2 2016.

00:03:12.540 --> 00:03:14.080
That's really cool, right?

00:03:14.080 --> 00:03:14.920
That's very cool.

00:03:14.980 --> 00:03:21.380
Yeah, so they have these things they call tracks, foundational technology tracks, and mission partner tracks.

00:03:21.380 --> 00:03:31.580
And so what they do is they go out and they find open source projects that somehow the success of that open source project furthers the goals of Mozilla,

00:03:31.580 --> 00:03:37.660
you know, an open source free web that Firefox and other things run well on, right?

00:03:37.660 --> 00:03:40.680
And so why is this on the Python thing?

00:03:40.680 --> 00:03:42.620
Well, they chose a really cool project.

00:03:42.940 --> 00:03:51.140
So they said that they've already funded eight projects for $385,000, and they're still considering more.

00:03:51.140 --> 00:03:55.960
And they have actually applications available for what's called a mission partner.

00:03:56.240 --> 00:04:03.060
So if you have an open source project and you think the mission of your project lines up well with Mozilla, maybe that could be your job, right?

00:04:03.100 --> 00:04:05.500
Like maybe Mozilla would pay you to work on your project.

00:04:05.500 --> 00:04:07.120
So first of all, just check this out.

00:04:07.120 --> 00:04:07.640
That's awesome.

00:04:07.640 --> 00:04:08.360
Yeah, definitely.

00:04:08.360 --> 00:04:08.880
That's cool.

00:04:08.880 --> 00:04:09.200
Yeah.

00:04:09.200 --> 00:04:16.760
They also have a track on secure open source for improving the security of open source software.

00:04:17.320 --> 00:04:22.680
And then the one that's really interesting to me and I think to the audience is the foundational technology track.

00:04:22.680 --> 00:04:31.860
And one of the things that was awarded there, one of the projects was PyPy, the alternate implementation that's a JIT for Python.

00:04:32.180 --> 00:04:36.840
And it's been working with Python 2.7, but not really great with Python 3.

00:04:36.840 --> 00:04:38.640
It's kind of sort of iffy.

00:04:38.640 --> 00:04:40.520
Some of the features are supported and so on.

00:04:40.520 --> 00:04:45.080
So they received $200,000 in donations to make that happen.

00:04:45.320 --> 00:04:46.420
That's really great.

00:04:46.420 --> 00:04:52.220
And that'll make PyPy a lot more compelling if we can get that updated to 3.

00:04:52.220 --> 00:04:53.000
Yeah, absolutely.

00:04:53.000 --> 00:04:56.980
I mean, it's one thing to say we're on 2.7 and then we'll move in a little bit.

00:04:56.980 --> 00:05:00.720
But it's another to say, and we're going to build on a technology that has no Python 3 story.

00:05:00.720 --> 00:05:02.680
Like that's a pretty serious blockade.

00:05:02.680 --> 00:05:08.200
But now they have an alpha version of PyPy 3.5 out and it's looking really good.

00:05:08.200 --> 00:05:10.180
So more on that in another section.

00:05:10.180 --> 00:05:11.020
Okay, cool.

00:05:11.020 --> 00:05:13.240
Speaking of announcements,

00:05:13.740 --> 00:05:16.920
I've just been sort of following what Intel's been doing.

00:05:16.920 --> 00:05:20.320
I think Talk Python had an Intel episode.

00:05:20.320 --> 00:05:26.820
Yeah, we had a great conversation about like how Intel's actually thinking about the architecture of their chips

00:05:26.820 --> 00:05:31.260
so that it lines up with the way that Python executes code.

00:05:31.260 --> 00:05:31.980
CPython.

00:05:31.980 --> 00:05:34.640
Yeah, and they're continuing working on this.

00:05:34.640 --> 00:05:39.080
The announcement that we're linking to is an announcement from Intel that says,

00:05:39.200 --> 00:05:46.900
Intel distribution for Python 2017 update 2 accelerates five key areas for impressive performance gains.

00:05:47.660 --> 00:05:50.280
And so it looks like they're continuing on.

00:05:50.280 --> 00:06:02.000
And this version that they've got is both something that it's a special release of Python that's compiled for knowing that it's going to run on an Intel architecture.

00:06:02.280 --> 00:06:04.860
And it's a good thing.

00:06:04.860 --> 00:06:07.620
And it's got 2.7 and 3.5.

00:06:07.620 --> 00:06:09.080
Oddly 3.6 missing.

00:06:09.080 --> 00:06:10.000
What's going on, guys?

00:06:10.000 --> 00:06:12.360
But the improvements are pretty cool.

00:06:12.500 --> 00:06:26.820
There was a comment about widespread optimizations for NumPy and SciPy FFTs with stated sometimes could possibly improve 60x over update 1.

00:06:26.820 --> 00:06:34.140
And so they really are hammering into trying to make this fast for some intensive stuff.

00:06:34.360 --> 00:06:35.340
Yeah, that's really cool.

00:06:35.340 --> 00:06:43.200
You know, if you're doing any sort of computational stuff involving NumPy and SciPy, that's pretty amazing performance increase.

00:06:43.200 --> 00:06:50.340
And to make it basically as fast as Native C and the Intel high-performance C libraries, that's really something.

00:06:50.340 --> 00:06:53.880
They also touched on some improvements in memory management.

00:06:54.320 --> 00:07:00.880
What I thought was cool was arithmetic and transcendental expressions from NumPy are able to use multicores now.

00:07:00.880 --> 00:07:05.400
And I just like that because I don't know what a transcendental expression is.

00:07:05.400 --> 00:07:08.400
I think that's like what your face looks like when you're meditating, maybe.

00:07:08.400 --> 00:07:10.980
Yeah, that sounds awesome.

00:07:10.980 --> 00:07:12.180
It already sounds intriguing.

00:07:12.180 --> 00:07:14.580
What good naming in nomenclature.

00:07:14.580 --> 00:07:22.360
Yeah, but anyway, I think it's neat that they're both working on it and also that there is a – it's not just for paid people.

00:07:22.360 --> 00:07:23.720
There is a free standalone version.

00:07:23.720 --> 00:07:24.360
That's cool.

00:07:24.360 --> 00:07:25.500
Yeah, yeah.

00:07:25.500 --> 00:07:26.440
That's very cool.

00:07:26.440 --> 00:07:27.480
Okay.

00:07:27.480 --> 00:07:30.480
The next one I want to talk about is also about performance.

00:07:30.480 --> 00:07:32.380
But before we do, I want to talk about errors.

00:07:32.380 --> 00:07:34.420
We don't like errors in our web apps, do we?

00:07:34.420 --> 00:07:35.300
Definitely not.

00:07:35.300 --> 00:07:35.780
No.

00:07:35.780 --> 00:07:41.540
So our sponsor this week, Rollbar, will totally help you take the pain out of errors and solve that problem.

00:07:41.540 --> 00:07:43.380
So I use them on my own sites.

00:07:43.380 --> 00:07:45.420
I know many people out there do as well.

00:07:45.420 --> 00:07:54.080
So what you do is you basically install with just a few lines of code, Rollbar into your Flask, Django, Pyramid web apps.

00:07:54.080 --> 00:07:56.980
And if there's ever an error, you'll get a notification.

00:07:56.980 --> 00:08:00.340
You'll get a report containing all the details that you need.

00:08:00.340 --> 00:08:03.000
So here's some kind of crash.

00:08:03.000 --> 00:08:04.580
Here is the traceback.

00:08:04.580 --> 00:08:11.000
Here's the browser and the platform and everything that was possibly passed in the whole web request right there for you.

00:08:11.000 --> 00:08:15.380
So you'll get notified straight away of any errors and you won't even probably have to debug it.

00:08:15.380 --> 00:08:17.720
You'll just have to look and go, oh, dear, we have to go fix this.

00:08:17.720 --> 00:08:20.860
So definitely check them out at Rollbar.com.

00:08:20.860 --> 00:08:22.340
And I use them.

00:08:22.340 --> 00:08:23.080
I think they're great.

00:08:23.080 --> 00:08:23.940
Wonderful.

00:08:23.940 --> 00:08:25.320
Yeah, absolutely.

00:08:25.320 --> 00:08:26.460
And thanks for sponsoring the show, guys.

00:08:26.460 --> 00:08:27.320
All right.

00:08:27.320 --> 00:08:28.740
So let's talk about performance.

00:08:28.740 --> 00:08:32.800
And this is follow on from the Mozilla one.

00:08:32.800 --> 00:08:41.820
So the guys at PyPy released some performance graphs and stuff from their work on implementing Python 3.5.

00:08:41.820 --> 00:08:49.740
And they said, look, the core new thing that we need to work on is this whole asyncio story.

00:08:49.740 --> 00:08:50.040
Right.

00:08:50.040 --> 00:08:52.600
That's sort of the kernel of the new stuff in Python 3.5.

00:08:53.080 --> 00:08:58.180
And so what they did is they said, well, let's put out some numbers on how we're doing in that area.

00:08:58.180 --> 00:09:03.940
I want to say thanks to Guy Fichel, who actually sent this over to us to say, hey, you should talk about this.

00:09:03.940 --> 00:09:11.100
They said, look, we're going to take things like Tornado, Async IO, Curio, G-Event, and Twisted,

00:09:11.100 --> 00:09:14.940
and we're going to run them on PyPy 3.5 and see how they do.

00:09:15.660 --> 00:09:17.880
And they did pretty well, actually.

00:09:17.880 --> 00:09:24.520
They have a bunch of graphs, and they're basically five to ten times faster than CPython for all of those workloads.

00:09:24.520 --> 00:09:25.100
Wow.

00:09:25.100 --> 00:09:26.000
Yeah.

00:09:26.000 --> 00:09:35.100
So if you could run five times fewer servers because you don't need them with pretty much the same code, that would be pretty handy, right?

00:09:35.100 --> 00:09:35.600
Definitely.

00:09:35.600 --> 00:09:36.040
Yeah.

00:09:36.040 --> 00:09:36.680
That's cool.

00:09:36.680 --> 00:09:36.960
Yeah.

00:09:36.960 --> 00:09:39.340
So there's a lot of interesting things.

00:09:39.480 --> 00:09:47.320
I feel like this whole let's leverage Async IO plus something else is really blowing up these days.

00:09:47.320 --> 00:09:56.500
We've had a lot of stuff happening in the web frameworks with Jepronto, with Async, AIo HTTP, with Sanic, with this.

00:09:56.500 --> 00:10:03.500
There's a lot of stuff going on right now trying to do something with Async and Async and Away and Async IO to make things faster.

00:10:03.500 --> 00:10:06.180
So I think we'll continue to hear good stories around this.

00:10:06.180 --> 00:10:06.580
Yeah.

00:10:06.580 --> 00:10:08.560
It's cool that it keeps progressing.

00:10:08.960 --> 00:10:09.660
Yeah, absolutely.

00:10:09.660 --> 00:10:10.420
Definitely.

00:10:10.420 --> 00:10:14.400
What's unclear is which one of these is going to be the path, right?

00:10:14.400 --> 00:10:16.200
Is Jepronto going to be the way to go?

00:10:16.200 --> 00:10:17.960
Is AIo HTTP the way to go?

00:10:17.960 --> 00:10:20.920
Sanic, there's so many sort of flowers blooming.

00:10:20.920 --> 00:10:26.060
It's kind of tough to pick the right one because they all seem so promising in slightly different ways.

00:10:26.060 --> 00:10:26.460
Yeah.

00:10:26.460 --> 00:10:35.300
And from somebody that's trying to maybe set up a project and trying to pick, that needs to pick one right now, I can see that that might be a little confusing.

00:10:36.220 --> 00:10:40.720
But I don't think these are terribly different things.

00:10:40.720 --> 00:10:41.600
I don't know.

00:10:41.600 --> 00:10:42.200
Maybe it is.

00:10:42.200 --> 00:10:49.460
I have no idea what it would be like if you went with, I don't know, Sanic or something and then Sanic disappeared for some reason.

00:10:49.460 --> 00:10:50.400
You needed to switch.

00:10:50.400 --> 00:10:51.800
How difficult that would be.

00:10:52.080 --> 00:10:57.240
At the very least, having a lot of people look at it and try to make things faster is a good thing.

00:10:57.240 --> 00:10:57.780
Yeah, absolutely.

00:10:58.540 --> 00:11:11.120
Ned Batchelder is the guy that supports coverage.py and to measure that most people use for coverage of looking at coverage of their code.

00:11:11.120 --> 00:11:15.320
And he wrote a couple articles called A Tale of Two Exceptions.

00:11:15.320 --> 00:11:16.940
And he's got two parts.

00:11:17.820 --> 00:11:23.600
And there's a, what was going on was he was trying to get all of his test suite to run on Jython.

00:11:23.940 --> 00:11:34.960
And there was some, I don't know the details of the problem, but there was an issue with the Jython that made it so that, like, the reporting mechanism doesn't quite work or doesn't work.

00:11:34.960 --> 00:11:38.000
So it's not a crucial part of the system of coverage.

00:11:38.000 --> 00:11:39.460
But they didn't work.

00:11:39.540 --> 00:11:44.040
So he wanted to skip the tests that depended on that while running on Jython.

00:11:44.040 --> 00:11:46.760
And, wow, it's an interesting tale.

00:11:46.760 --> 00:12:01.820
He kind of walks through the entire thought process of why he chose different attempts and maybe inheriting from the exception class and picking another base for the exceptions that the coverage exceptions use.

00:12:02.180 --> 00:12:07.460
And ends up kind of leaving it not quite wrapped up at the end of the first post.

00:12:07.460 --> 00:12:21.580
And then with some feedback from one of the readers on the first post, came up with a way to use decorators and meta classes to apply the decorators to be able to skip those more effectively.

00:12:21.580 --> 00:12:24.620
And it's a couple pretty cool articles.

00:12:24.620 --> 00:12:26.340
Yeah, nice work, Ned.

00:12:26.340 --> 00:12:27.720
That's a nice write-up.

00:12:27.720 --> 00:12:30.840
So what do you have to do if you want to do coverage on Jython?

00:12:30.840 --> 00:12:33.800
You basically run it and collect the report.

00:12:33.800 --> 00:12:39.000
And then you have to, like, actually somehow process it with CPython?

00:12:39.000 --> 00:12:44.800
Well, I'm not exactly sure what the – I'm sure that there's enough support to understand your coverage.

00:12:44.800 --> 00:12:53.740
But the coverage package has, like, a whole bunch of cool stuff like generating HTML reports and a lot of other type of reports.

00:12:53.740 --> 00:12:57.340
And it's possible that those are the parts that are missing.

00:12:57.340 --> 00:12:58.020
Yeah, yeah.

00:12:58.020 --> 00:13:00.900
Yeah, these are – this is definitely an interesting use of meta classes.

00:13:00.900 --> 00:13:03.540
There's some multiple inheritance thrown in there.

00:13:03.540 --> 00:13:05.120
There's a lot of stuff in this, actually.

00:13:05.120 --> 00:13:05.460
Yeah.

00:13:05.460 --> 00:13:16.180
And one of the things that I wanted to point out was I've – it's refreshing to – I've seen a lot of articles with people saying, look, I've got this cool solution I came up with for this particular problem.

00:13:16.580 --> 00:13:22.660
And it's very refreshing to see somebody say, I've got a sticky problem with a solution that I'm still not quite happy with.

00:13:22.660 --> 00:13:23.760
And here it is.

00:13:23.760 --> 00:13:26.160
And it's nice.

00:13:26.160 --> 00:13:33.340
And another thing, a good takeaway from it is he didn't present all of the code that he could have.

00:13:33.520 --> 00:13:37.560
He boiled the code that he puts in the articles.

00:13:37.560 --> 00:13:42.080
He boiled those down so that you could understand the problem, but they're not huge.

00:13:42.080 --> 00:13:46.080
That's extra work on his part, but it makes it for a nice quick read.

00:13:46.080 --> 00:13:46.800
Yeah.

00:13:46.800 --> 00:13:50.600
It's – a lot of people ask me, like, how did you come up with this type of problem?

00:13:50.600 --> 00:13:52.600
Or, like, could you explain the thinking that got you here?

00:13:52.600 --> 00:13:54.360
Because I don't see how you got from A to B.

00:13:54.360 --> 00:13:56.480
And, like, this is a good example of, like, laying that out.

00:13:56.480 --> 00:13:57.060
I think it's nice.

00:13:57.060 --> 00:13:57.500
Yeah.

00:13:57.500 --> 00:14:01.780
And also to kind of prevent people from saying, well, why didn't you try X?

00:14:01.780 --> 00:14:04.280
Because he already did and he's showing it.

00:14:04.280 --> 00:14:05.480
So it's nice.

00:14:05.480 --> 00:14:05.820
Yeah, nice.

00:14:05.820 --> 00:14:06.040
All right.

00:14:06.040 --> 00:14:06.620
Check that one out.

00:14:06.620 --> 00:14:07.160
That's very cool.

00:14:07.160 --> 00:14:11.300
The last one is also about async and OA and is also about performance.

00:14:11.300 --> 00:14:14.180
So – but this is a totally different story.

00:14:14.180 --> 00:14:21.920
So all the stuff that we've been talking about, the Mozilla thing, the PyPy, the PyPy tests that they ran, the majority of those were testing web frameworks.

00:14:22.020 --> 00:14:23.120
So I want to write a web server.

00:14:23.120 --> 00:14:24.640
It's going to process some requests.

00:14:24.640 --> 00:14:25.360
Let's do it faster.

00:14:25.360 --> 00:14:27.480
This is totally different.

00:14:27.480 --> 00:14:31.840
This is about I want to consume services really quickly.

00:14:31.840 --> 00:14:38.100
And the AIO HTTP library actually has some really cool stuff to do this that I just learned about.

00:14:38.100 --> 00:14:39.480
So I thought I'd share it with you guys.

00:14:39.480 --> 00:14:39.780
Wow.

00:14:39.780 --> 00:14:40.680
That's great.

00:14:40.680 --> 00:14:40.860
Yeah.

00:14:40.860 --> 00:14:42.500
So you've heard of requests, right?

00:14:42.500 --> 00:14:45.300
Like, the most downloaded package ever.

00:14:45.300 --> 00:14:45.860
Well, definitely.

00:14:45.860 --> 00:14:46.260
Yeah.

00:14:46.260 --> 00:14:46.860
Yeah.

00:14:46.860 --> 00:14:48.040
So we all know about requests, right?

00:14:48.040 --> 00:14:50.420
It's downloaded, like, 7 million times a month or something insane.

00:14:51.020 --> 00:14:55.340
Well, AIO HTTP has a similar library as requests.

00:14:55.340 --> 00:14:59.720
It's actually very, very similar in the way that you use it and its features and so on.

00:14:59.720 --> 00:15:06.920
However, requests itself is not – you can't await it in async and await, right?

00:15:06.960 --> 00:15:13.000
So it doesn't, like, use some sort of deferred I.O. callback in order to complete your request.

00:15:13.000 --> 00:15:13.840
It just blocks.

00:15:13.840 --> 00:15:20.200
So the big difference with AIO HTTP is you can await the responses at different levels.

00:15:20.200 --> 00:15:22.500
You can do it on the network calls.

00:15:22.500 --> 00:15:23.620
You can do it on the parsing.

00:15:23.620 --> 00:15:24.640
You can actually do it.

00:15:24.640 --> 00:15:26.600
It even has, like, a file-based thing.

00:15:26.600 --> 00:15:28.160
So you can await writing to files.

00:15:28.640 --> 00:15:33.360
And so this person wrote up a cool little example, putting those both side by side.

00:15:33.360 --> 00:15:34.960
And the code is quite similar.

00:15:34.960 --> 00:15:37.840
If you didn't have async and await, it would be not so similar.

00:15:37.840 --> 00:15:39.360
It would be really nasty looking.

00:15:39.360 --> 00:15:41.420
But because you do, it becomes real similar.

00:15:41.420 --> 00:15:45.940
So what we're going to do is I want to get a bunch of stats about basketball players in the NBA.

00:15:45.940 --> 00:15:47.560
There's an API for that, apparently.

00:15:48.140 --> 00:15:51.140
So it's going to run some code, and it's going to go collect all the stats.

00:15:51.140 --> 00:15:53.040
And it took 12 minutes on requests.

00:15:53.040 --> 00:15:59.420
Using AIO HTTP and AIO files, it took 22 seconds.

00:15:59.420 --> 00:16:00.960
Wow.

00:16:00.960 --> 00:16:01.840
That's really awesome, right?

00:16:01.840 --> 00:16:03.340
That's 33 times faster.

00:16:03.340 --> 00:16:03.960
Definitely.

00:16:03.960 --> 00:16:04.980
Wow.

00:16:04.980 --> 00:16:06.400
And the code is virtually identical.

00:16:06.400 --> 00:16:07.380
That's pretty cool.

00:16:07.380 --> 00:16:13.840
So the difference is, like, basically, you begin a request to the API, and normally you're just waiting on the network, right?

00:16:13.840 --> 00:16:15.020
You're waiting for a response, right?

00:16:15.100 --> 00:16:21.780
But you should be able to kick off a whole bunch more of those requests until one of them comes back and you have to process them.

00:16:21.780 --> 00:16:24.840
So it doesn't even use threads to pull this off.

00:16:24.840 --> 00:16:27.320
It just uses IOCallback type things.

00:16:27.320 --> 00:16:27.740
Really?

00:16:27.740 --> 00:16:28.520
Okay.

00:16:28.520 --> 00:16:28.820
Yeah.

00:16:28.820 --> 00:16:30.500
Yeah, pretty awesome.

00:16:30.500 --> 00:16:34.480
So this is definitely one of those things that shows the power of Python 3.5.

00:16:34.480 --> 00:16:38.220
Yeah, and it's nice to have it on the client side, too.

00:16:38.220 --> 00:16:43.400
We've got a lot of examples recently of async and await on the server side.

00:16:43.400 --> 00:16:44.500
Yeah, absolutely, absolutely.

00:16:45.240 --> 00:16:47.240
So I want to squeeze one more piece of news in here.

00:16:47.240 --> 00:16:47.700
Okay.

00:16:47.700 --> 00:16:50.020
Yeah, before we wrap it up.

00:16:50.020 --> 00:16:53.300
So I talk about PyPI a lot on Talk Python.

00:16:53.300 --> 00:16:58.200
We grab a lot of packages out of there and talk about them here on Python Bytes.

00:16:58.200 --> 00:17:02.880
There's quite a milestone that just passed there two days ago, three days ago, something like that.

00:17:02.880 --> 00:17:03.660
Very cool milestone.

00:17:03.660 --> 00:17:04.720
A very cool milestone.

00:17:04.900 --> 00:17:08.500
So there are now over 100,000 packages on PyPI.

00:17:08.500 --> 00:17:09.780
How cool is that?

00:17:09.780 --> 00:17:10.400
It's very cool.

00:17:10.400 --> 00:17:18.160
I wonder if the guy that, or the, I shouldn't say guy, the person that got the 100,000th one in there, if they know about it.

00:17:18.160 --> 00:17:20.560
If they know that they are the one that put it over the top?

00:17:20.560 --> 00:17:22.380
Yeah, we need to find out.

00:17:22.420 --> 00:17:26.020
We need to contact like Donald Stuffed and see if he knows, if he can find out.

00:17:26.020 --> 00:17:28.800
I bet there's some sort of query that can be done that will answer that question.

00:17:28.800 --> 00:17:29.680
Yeah, that'd be cool.

00:17:29.680 --> 00:17:30.400
That'd be very cool.

00:17:30.400 --> 00:17:30.700
Okay.

00:17:30.700 --> 00:17:31.580
All right.

00:17:31.580 --> 00:17:32.860
That's it for me.

00:17:32.860 --> 00:17:34.100
Got any news to share with anyone?

00:17:34.280 --> 00:17:37.480
Just that I've been in the throes of trying to switch over.

00:17:37.480 --> 00:17:44.940
I switched over the Test and Code podcast to a new domain name at testandcode.com.

00:17:44.940 --> 00:17:50.180
And that all, hopefully that should be seamless to anybody that's already subscribed.

00:17:50.180 --> 00:17:55.080
But there, yeah, just if you see anything, that'll be, that's going on.

00:17:55.080 --> 00:17:55.840
We should let you know.

00:17:55.840 --> 00:17:56.480
Okay, awesome.

00:17:56.480 --> 00:17:57.260
Test and Code.

00:17:57.260 --> 00:17:57.780
Very cool.

00:17:57.780 --> 00:17:59.080
So congrats.

00:17:59.080 --> 00:18:01.440
You have a whole new system driving and everything, right?

00:18:01.440 --> 00:18:02.420
Like a whole new website.

00:18:02.420 --> 00:18:04.380
It's basically hands-off for me.

00:18:04.380 --> 00:18:07.960
I'm letting software as a service do most of the work for me.

00:18:07.960 --> 00:18:09.140
That sounds very relaxing.

00:18:09.140 --> 00:18:17.160
Now, I was going to switch the, I have Test Podcast as the Twitter thing with a bunch of

00:18:17.160 --> 00:18:17.560
followers.

00:18:17.560 --> 00:18:23.080
And I also have Test and Code as a Twitter, but there's only like four people following.

00:18:23.080 --> 00:18:24.680
So I have no idea what to do with that.

00:18:24.680 --> 00:18:25.460
How about you?

00:18:25.460 --> 00:18:26.920
Got anything you want to announce?

00:18:26.920 --> 00:18:28.480
No, not too much.

00:18:28.480 --> 00:18:32.260
I'm just continuing to work on classes, creating more online classes.

00:18:32.360 --> 00:18:37.260
So I actually have a surprise one coming that nobody is, I'm sure will be unexpected, but

00:18:37.260 --> 00:18:37.980
I think it'll be fun.

00:18:37.980 --> 00:18:39.580
And maybe next week I can talk about it.

00:18:39.580 --> 00:18:41.640
I'll practice my surprised voice.

00:18:41.640 --> 00:18:42.320
Ah!

00:18:42.320 --> 00:18:43.040
Yeah.

00:18:43.040 --> 00:18:45.160
All right.

00:18:45.160 --> 00:18:46.360
Well, thank you everyone for listening.

00:18:46.360 --> 00:18:48.120
Brian, great to talk to you as always.

00:18:48.120 --> 00:18:48.900
As always.

00:18:48.900 --> 00:18:49.240
See you.

00:18:50.240 --> 00:18:52.040
Thank you for listening to Python Bytes.

00:18:52.040 --> 00:18:54.600
Follow the show on Twitter via at Python Bytes.

00:18:54.600 --> 00:18:57.500
That's Python Bytes as in B-Y-T-E-S.

00:18:57.500 --> 00:19:00.940
And get the full show notes at Pythonbytes.fm.

00:19:00.940 --> 00:19:05.260
If you have a news item you want featured, just visit Pythonbytes.fm and send it our way.

00:19:05.260 --> 00:19:07.960
We're always on the lookout for sharing something cool.

00:19:07.960 --> 00:19:11.360
On behalf of myself and Brian Okken, this is Michael Kennedy.

00:19:11.360 --> 00:19:14.980
Thank you for listening and sharing this podcast with your friends and colleagues.

